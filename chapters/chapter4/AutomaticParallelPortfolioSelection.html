<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Automatic Parallel Portfolio Selection – Dynamic Selection of Parallel Portfolio of Algorithms for Solving Combinatorial Problems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html" rel="next">
<link href="../../chapters/chapter3/IsAlgorithmSelectionWorthItComparingSelectingSingleAlgorithmsandParallelExecution.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-8eef5ae80df721a84869b784b4d5419f.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-812d013f591176c02f613616752f8d70.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter4/AutomaticParallelPortfolioSelection.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic Parallel Portfolio Selection</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Dynamic Selection of Parallel Portfolio of Algorithms for Solving Combinatorial Problems</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/haniyeka/dissertation-website" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../Dynamic-Selection-of-Parallel-Portfolio-of-Algorithms-for-Solving-Combinatorial-Problems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Abstract</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/Background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Background</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/IsAlgorithmSelectionWorthItComparingSelectingSingleAlgorithmsandParallelExecution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter4/AutomaticParallelPortfolioSelection.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic Parallel Portfolio Selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Revisiting Parallel Portfolio Selection with KL Divergence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter6/ParallelPortfolioSelectionwithParallelDataTraining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Parallel Portfolio Selection with Parallel Data Training</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter7/DiscussionandConclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Discussion and Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/appendixA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Appendix</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract"><span class="header-section-number">5.1</span> Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">5.2</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#algorithm-selection" id="toc-algorithm-selection" class="nav-link" data-scroll-target="#algorithm-selection"><span class="header-section-number">5.2.1</span> Algorithm Selection</a></li>
  <li><a href="#portfolio-scheduling" id="toc-portfolio-scheduling" class="nav-link" data-scroll-target="#portfolio-scheduling"><span class="header-section-number">5.2.2</span> Portfolio Scheduling</a></li>
  </ul></li>
  <li><a href="#parallel-portfolio-selection" id="toc-parallel-portfolio-selection" class="nav-link" data-scroll-target="#parallel-portfolio-selection"><span class="header-section-number">5.3</span> Parallel Portfolio Selection</a></li>
  <li><a href="#experimental-setup" id="toc-experimental-setup" class="nav-link" data-scroll-target="#experimental-setup"><span class="header-section-number">5.4</span> Experimental Setup</a>
  <ul class="collapse">
  <li><a href="#data-collection" id="toc-data-collection" class="nav-link" data-scroll-target="#data-collection"><span class="header-section-number">5.4.1</span> Data Collection</a></li>
  <li><a href="#training-and-tuning" id="toc-training-and-tuning" class="nav-link" data-scroll-target="#training-and-tuning"><span class="header-section-number">5.4.2</span> Training and Tuning</a></li>
  <li><a href="#baselines" id="toc-baselines" class="nav-link" data-scroll-target="#baselines"><span class="header-section-number">5.4.3</span> Baselines</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">5.5</span> Results</a>
  <ul class="collapse">
  <li><a href="#tuning-of-p_cap" id="toc-tuning-of-p_cap" class="nav-link" data-scroll-target="#tuning-of-p_cap"><span class="header-section-number">5.5.1</span> Tuning of <span class="math inline">\(p_{\cap}\)</span></a></li>
  <li><a href="#algorithm-selection-results" id="toc-algorithm-selection-results" class="nav-link" data-scroll-target="#algorithm-selection-results"><span class="header-section-number">5.5.2</span> Algorithm Selection Results</a></li>
  <li><a href="#number-of-selected-solvers" id="toc-number-of-selected-solvers" class="nav-link" data-scroll-target="#number-of-selected-solvers"><span class="header-section-number">5.5.3</span> Number of Selected Solvers</a></li>
  <li><a href="#ranger-vs-randomforest-results" id="toc-ranger-vs-randomforest-results" class="nav-link" data-scroll-target="#ranger-vs-randomforest-results"><span class="header-section-number">5.5.4</span> Ranger vs RandomForest Results</a></li>
  </ul></li>
  <li><a href="#conclusions-and-future-work" id="toc-conclusions-and-future-work" class="nav-link" data-scroll-target="#conclusions-and-future-work"><span class="header-section-number">5.6</span> Conclusions and Future Work</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic Parallel Portfolio Selection</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>A portion of this chapter has been published as: H. Kashgarani, L. Kotthoff, “Automatic Parallel Portfolio Selection,” in <em>ECAI 2023</em>, pp. 1215-1222, IOS Press, 2023.</p>
<p>This chapter introduces a hybrid formulation for dynamic algorithm portfolio selection, which is instance-based and aims to mitigate the risk of selecting a single algorithm or running too many solvers in parallel. The published ECAI paper investigates the results for a random forest regression model trained using the MLR package. Here, in addition to presenting those results, we also expand upon them to explore the transition of regression random forests from the MLR package to its updated version, MLR3, in R.</p>
<section id="abstract" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="abstract"><span class="header-section-number">5.1</span> Abstract</h2>
<p>Algorithms to solve hard combinatorial problems often exhibit complementary performance, i.e.&nbsp;where one algorithm fails, another shines. Algorithm portfolios and algorithm selection take advantage of this by running all algorithms in parallel or choosing the best one to run on a problem instance. In this chapter, we show that neither of these approaches gives the best possible performance and propose the happy medium of running a subset of all algorithms in parallel. We propose a method to choose this subset automatically for each problem instance, and demonstrate empirical improvements of up to 23% in terms of runtime, 83% in terms of misclassification penalty, and 32% in terms of penalized averaged runtime on scenarios from the ASlib benchmark library. Unlike all other algorithm selection and scheduling approaches in the literature, our performance measures are based on the actual performance for algorithms running in parallel rather than assuming overhead-free parallelization based on sequential performance. Our approach is easy to apply in practice and does not require to solve hard problems to obtain a schedule, unlike other techniques in the literature, while still delivering superior performance.</p>
</section>
<section id="introduction" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="introduction"><span class="header-section-number">5.2</span> Introduction</h2>
<p>For many types of hard combinatorial problems, different algorithms that exhibit complementary performance are available. In these cases, a portfolio of algorithms often achieves better performance than a single one <span class="citation" data-cites="Huberman1997 GOMES200143">(<a href="#ref-Huberman1997" role="doc-biblioref">Huberman, Lukose, and Hogg 1997</a>; <a href="#ref-GOMES200143" role="doc-biblioref">Gomes and Selman 2001</a>)</span>. The algorithms can be run in parallel, or a single one selected for each problem instance to solve. The so-called Algorithm Selection Problem <span class="citation" data-cites="Rice1976">(<a href="#ref-Rice1976" role="doc-biblioref">Rice 1976</a>)</span> is often solved using machine learning models which, given characteristics of the problem instance to solve, decide which algorithm should be chosen <span class="citation" data-cites="Kotthoff2014 10.1162/evco_a_00242">(<a href="#ref-Kotthoff2014" role="doc-biblioref">Kotthoff 2014</a>; <a href="#ref-10.1162/evco_a_00242" role="doc-biblioref">Kerschke et al. 2019</a>)</span>. The machine learning models built for per-instance algorithm selection are not perfect, like most models. In some cases, they lead to choosing an algorithm that does not provide the best overall performance, resulting in wasted resources.</p>
<p>Running all algorithms in parallel avoids this issue, but again wastes resources. Even if the user is only interested in optimizing the elapsed time, i.e.&nbsp;it does not matter how many things are run in parallel, results are sub-optimal as parallel executions compete for shared resources such as caches. With more solvers running in parallel, more runs time out, which results in a large overhead. Even for a relatively small number of parallel runs, this overhead becomes prohibitive, resulting in overall performance worse than using imperfect machine learning models to choose a single algorithm <span class="citation" data-cites="pmlr-v140-kashgarani21a">(<a href="#ref-pmlr-v140-kashgarani21a" role="doc-biblioref">Kashgarani and Kotthoff 2021</a>)</span>.</p>
<p>In this chapter, we propose a middle path – select the most promising subset of algorithms to be run in parallel on a single non-distributed computing machine. This mitigates the impact of both imperfect machine learning models and overhead from parallel runs. We formalize the problem of choosing a subset of algorithms from a portfolio, unifying approaches from the literature. We propose a solution to this problem based on the predictions of algorithm performance models and their uncertainties and compare empirically to other approaches from the literature. We trained three algorithm selection performance models and applied the proposed formulation and could demonstrate improvements of up to 83% in terms of misclassification penalty, establishing a new state of the art in per-instance algorithm selection with multiple algorithms. We assume that the algorithms to run are not parallelized themselves, i.e.&nbsp;each algorithm consumes the same computational resources, and we run on a single machine. We do not consider the case of running algorithms in a distributed setting on multiple machines.</p>
<section id="algorithm-selection" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="algorithm-selection"><span class="header-section-number">5.2.1</span> Algorithm Selection</h3>
<p>The performance of algorithms designed to solve NP-complete problems, such as Boolean Satisfiability and the Traveling Salesman Problem, can vary significantly depending on the specific problem being addressed. There is no one algorithm that performs optimally in all circumstances. However, we can take advantage of these performance disparities by creating algorithm portfolios that incorporate the complementing strengths of several algorithms <span class="citation" data-cites="GOMES200143 Huberman1997">(<a href="#ref-GOMES200143" role="doc-biblioref">Gomes and Selman 2001</a>; <a href="#ref-Huberman1997" role="doc-biblioref">Huberman, Lukose, and Hogg 1997</a>)</span>.</p>
<p>The algorithm portfolios proposed in <span class="citation" data-cites="GOMES200143 Huberman1997">(<a href="#ref-GOMES200143" role="doc-biblioref">Gomes and Selman 2001</a>; <a href="#ref-Huberman1997" role="doc-biblioref">Huberman, Lukose, and Hogg 1997</a>)</span> run multiple algorithms in parallel, however, they do not measure the actual execution time when running in parallel but simulate parallel execution based on sequential performance. <span class="citation" data-cites="pmlr-v140-kashgarani21a">(<a href="#ref-pmlr-v140-kashgarani21a" role="doc-biblioref">Kashgarani and Kotthoff 2021</a>)</span> found that the performance of the portfolio can deteriorate substantially when algorithms are executed in parallel, in particular for more than 10 algorithms. <span class="citation" data-cites="LINDAUER2017272">(<a href="#ref-LINDAUER2017272" role="doc-biblioref">Lindauer et al. 2017</a>)</span> has also determined that running various configurations of an algorithm in parallel can introduce overhead, and this factor should be considered when designing portfolios. Alternatively, we can choose a subset of the best algorithms from the portfolio for a given problem instance to avoid the overhead of running a large number of solvers in parallel. In the case where we choose only a single algorithm, this is known as the algorithm selection problem&nbsp;<span class="citation" data-cites="Rice1976">(<a href="#ref-Rice1976" role="doc-biblioref">Rice 1976</a>)</span>. Typically, this is accomplished through the use of machine learning techniques and features derived from the instances&nbsp;<span class="citation" data-cites="Kotthoff2014 10.1162/evco_a_00242">(<a href="#ref-Kotthoff2014" role="doc-biblioref">Kotthoff 2014</a>; <a href="#ref-10.1162/evco_a_00242" role="doc-biblioref">Kerschke et al. 2019</a>)</span> and algorithms&nbsp;<span class="citation" data-cites="pmlr-v188-pulatov22a">(<a href="#ref-pmlr-v188-pulatov22a" role="doc-biblioref">Pulatov et al. 2022</a>)</span>. However, choosing only a single algorithm to run often achieves suboptimal performance because of incorrect choices. This can be addressed through better algorithm selection models; in this chapter, we explore the alternative of choosing more than one algorithm to run in parallel on a single node.</p>
<p>Algorithm selection has been applied successfully in many problem domains. Some of the most prominent systems are SATzilla, Hydra, and Autofolio &nbsp;<span class="citation" data-cites="satzilla lindauer2015autofolio 10.5555/2898607.2898641">(<a href="#ref-satzilla" role="doc-biblioref">Xu et al. 2008</a>; <a href="#ref-lindauer2015autofolio" role="doc-biblioref">Lindauer et al. 2015</a>; <a href="#ref-10.5555/2898607.2898641" role="doc-biblioref">Xu, Hoos, and Leyton-Brown 2010</a>)</span>. While these systems focus on SAT, algorithm selection also has been used in the constraint programming and mixed integer programming domains, where it has been shown to achieve good performance <span class="citation" data-cites="cphydra XuEtAl11">(<a href="#ref-cphydra" role="doc-biblioref">O’Mahony et al. 2008</a>; <a href="#ref-XuEtAl11" role="doc-biblioref">Xu et al. 2011</a>)</span>. AutoFolio has been applied in additional areas, e.g.&nbsp;ASP, MAXSAT, and QBF. <span class="citation" data-cites="10.1162/evco_a_00215">(<a href="#ref-10.1162/evco_a_00215" role="doc-biblioref">Kerschke et al. 2018</a>)</span> apply algorithm selection for the TSP, and ME-ASP <span class="citation" data-cites="maratea2014multi">(<a href="#ref-maratea2014multi" role="doc-biblioref">Maratea, Pulina, and Ricca 2014</a>)</span> apply algorithm selection for answer set programming to create a multi-engine solver. Algorithm selection has also been used to choose between evolutionary algorithms <span class="citation" data-cites="HU201268 yuen2019selecting Maturana2012 9ae8443ad82b4056bccf7102c0056152">(<a href="#ref-HU201268" role="doc-biblioref">Hu, Wu, and Weir 2012</a>; <a href="#ref-yuen2019selecting" role="doc-biblioref">Yuen, Lou, and Zhang 2019</a>; <a href="#ref-Maturana2012" role="doc-biblioref">Maturana et al. 2012</a>; <a href="#ref-9ae8443ad82b4056bccf7102c0056152" role="doc-biblioref">Yuen, Chow, and Zhang 2013</a>)</span>. The ASlib benchmarking library&nbsp;<span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span> collects benchmarks from many different problem domains and is the de facto standard library for evaluating algorithm selection approaches.</p>
<p><strong>Notation.</strong> We follow&nbsp;<span class="citation" data-cites="pmlr-v79-lindauer17a">(<a href="#ref-pmlr-v79-lindauer17a" role="doc-biblioref">Lindauer, Rijn, and Kotthoff 2017</a>)</span> in the notation we use in this chapter. Given a portfolio of algorithms (solvers) <span class="math inline">\(S\)</span>, a set of instances <span class="math inline">\(I\)</span>, and a performance metric $ m: S I <span class="math inline">\(, we aim to find a mapping\)</span> s: I S $ from instances <span class="math inline">\(I\)</span> to algorithms <span class="math inline">\(S\)</span> such that the performance across all instances is optimized. This performance metric can be for example the time needed to solve the instance and we assume w.l.o.g.&nbsp;that the performance metric should be minimized. In practice, we estimate the value of the performance metric based on the predictions of machine learning models for new problem instances; we denote this estimate <span class="math inline">\(\hat{m}\)</span>. We want to select the solver with the best-predicted performance for each instance:</p>
<p><span class="math display">\[\label{eq:1}
    min \frac{1}{|I|} \sum\limits_{i\in I} \hat{m}(s(i),i)\]</span></p>
</section>
<section id="portfolio-scheduling" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="portfolio-scheduling"><span class="header-section-number">5.2.2</span> Portfolio Scheduling</h3>
<p>Different approaches have been proposed for sub-portfolio selection. Some approaches choose a number of suitable solvers for sequential execution and assign time slices that sum to the total available time to each algorithm. Others have implemented parallel execution of the selected solvers, while a few have combined these two methods, utilizing parallelization across computing processors and splitting the available time of each processor across different algorithms.</p>
<section id="time-slice-allocation-on-single-processor" class="level4" data-number="5.2.2.1">
<h4 data-number="5.2.2.1" class="anchored" data-anchor-id="time-slice-allocation-on-single-processor"><span class="header-section-number">5.2.2.1</span> Time slice allocation on single processor</h4>
<p>Typically, sub-portfolio selection strategies are built for sequential solver runs, e.g.&nbsp;Sunny&nbsp;<span class="citation" data-cites="sunny">(<a href="#ref-sunny" role="doc-biblioref">Amadini, Gabbrielli, and Mauro 2014</a>)</span> creates a sub-portfolio of solvers using k-nearest neighbor (kNN) models and builds a sequential schedule for the selected solvers by allocating time slices based on the predicted performance. CPHydra&nbsp;<span class="citation" data-cites="cphydra">(<a href="#ref-cphydra" role="doc-biblioref">O’Mahony et al. 2008</a>)</span> also employs case-based reasoning and allocates time slices for the selected CSP solvers to run sequentially. 3S&nbsp;<span class="citation" data-cites="3s">(<a href="#ref-3s" role="doc-biblioref">Kadioglu et al. 2011</a>)</span> dynamically selects and sequentially schedules solvers for a given SAT instance using integer programming. ASPEED&nbsp;<span class="citation" data-cites="aspeed">(<a href="#ref-aspeed" role="doc-biblioref">Hoos et al. 2015</a>)</span> creates static sequential schedules through answer set programming that optimizes a static sequential time budget allocation for solvers. Depending on the number of algorithms, solving the scheduling problem can take substantial time. Building on the methodologies of 3S&nbsp;<span class="citation" data-cites="3s">(<a href="#ref-3s" role="doc-biblioref">Kadioglu et al. 2011</a>)</span> and ASPEED&nbsp;<span class="citation" data-cites="aspeed">(<a href="#ref-aspeed" role="doc-biblioref">Hoos et al. 2015</a>)</span>, ISA (Instance-Specific ASPEED)&nbsp;<span class="citation" data-cites="flexfolio">(<a href="#ref-flexfolio" role="doc-biblioref">Lindauer, Bergdoll, and Hutter 2016</a>)</span> uses kNN to identify the closest training problem instances to a given problem instance to solve. It then employs ASPEED to determine a schedule that minimizes the number of timeouts across these instances. <span class="citation" data-cites="flexfolio">(<a href="#ref-flexfolio" role="doc-biblioref">Lindauer, Bergdoll, and Hutter 2016</a>)</span> also introduced TSunny which is a modified version of Sunny that limits the number of solvers to run, thus increasing the chance of success by allocating larger time slices to each algorithm.</p>
</section>
<section id="time-slice-allocation-on-multiple-processors" class="level4" data-number="5.2.2.2">
<h4 data-number="5.2.2.2" class="anchored" data-anchor-id="time-slice-allocation-on-multiple-processors"><span class="header-section-number">5.2.2.2</span> Time slice allocation on multiple processors</h4>
<p>Other portfolio techniques have focused on scheduling solvers to run in parallel and allocating time slots on different processors. P3S&nbsp;<span class="citation" data-cites="p3s">(<a href="#ref-p3s" role="doc-biblioref">Malitsky et al. 2012</a>)</span> is a parallel version of 3S and uses the kNN algorithm for selecting solvers and scheduling them using integer programming with a specific runtime allocation strategy, where it runs a static set of solvers for the first 10% of the available runtime and solvers selected for the instance for the remaining 90%. ASPEED&nbsp;<span class="citation" data-cites="aspeed">(<a href="#ref-aspeed" role="doc-biblioref">Hoos et al. 2015</a>)</span> can also define a fixed schedule for running solvers on multiple processors, which is chosen based on the average solver performance across a set of instances. Flexfolio <span class="citation" data-cites="flexfolio">(<a href="#ref-flexfolio" role="doc-biblioref">Lindauer, Bergdoll, and Hutter 2016</a>)</span> incorporates a reimplementation of the P3S approach utilizing the same 10-90 strategy. However, rather than employing integer programming to address the scheduling problem, Flexfolio makes use of ASPEED and solves it through answer set programming. Sunny-cp&nbsp;<span class="citation" data-cites="sunnycp2">(<a href="#ref-sunnycp2" role="doc-biblioref">Amadini, Gabbrielli, and Mauro 2015</a>)</span> can simultaneously execute multiple CSP and COP solvers. First, a portion of the total available time is allocated to a pre-solving phase that follows a fixed schedule. The remaining time is then distributed amongst the other selected solvers dynamically, based on the predictions of kNN performance models. As there are often more solvers than processors, all processors except one are assigned to the corresponding number of top-ranked solvers, while the time on the final processors is split among the remaining solvers.</p>
</section>
<section id="running-algorithms-in-parallel" class="level4" data-number="5.2.2.3">
<h4 data-number="5.2.2.3" class="anchored" data-anchor-id="running-algorithms-in-parallel"><span class="header-section-number">5.2.2.3</span> Running algorithms in parallel</h4>
<p>One of the first parallel SAT solvers is ppfolio&nbsp;<span class="citation" data-cites="ppfolio">(<a href="#ref-ppfolio" role="doc-biblioref">Roussel 2012</a>)</span>. It selects solver portfolios to solve sets of problem instances optimally, but does this only for entire sets of instances, not on a per-instance basis as we do here. The success of ppfolio has inspired many other researchers to create sub-portfolios of solvers to run in parallel. For example, <span class="citation" data-cites="Marius2015">(<a href="#ref-Marius2015" role="doc-biblioref">Lindauer, Hoos, and Hutter 2015</a>)</span> extended existing algorithm selectors like 3S, SATzilla, and ME-ASP to greedily choose the top <span class="math inline">\(n\)</span> solvers to run in parallel by producing a ranking of candidate algorithms; however, the number of solvers has to be specified by the user and the actual runtime of parallel runs is not considered – the same runtime as for sequential execution is assumed. Running algorithms in parallel on the same machine is slower than running sequentially in practice due to the overhead incurred because of shared caches and shared memory. This has been shown in experiments&nbsp;<span class="citation" data-cites="pmlr-v140-kashgarani21a">(<a href="#ref-pmlr-v140-kashgarani21a" role="doc-biblioref">Kashgarani and Kotthoff 2021</a>)</span>, simulations&nbsp;<span class="citation" data-cites="Yun jtom1286288">(<a href="#ref-Yun" role="doc-biblioref">Yun and Epstein 2012</a>; <a href="#ref-jtom1286288" role="doc-biblioref">Torağay and Pouya 2023</a>)</span>, and analyses&nbsp;<span class="citation" data-cites="biere">(<a href="#ref-biere" role="doc-biblioref">Aigner et al. 2013</a>)</span> for the parallel executions of solvers – in practice, ignoring the overhead that parallel execution introduces reduces overall performance.</p>
<p>In this chapter, we consider the problem of selecting the optimal subset of algorithms to run in parallel on a single machine. This is computationally much easier to solve on a per-instance basis than more complex scheduling approaches, e.g.&nbsp;the ones used by ASPEED and 3S, which means that our method is easier to deploy and introduces less overhead. As long as the best solver is part of the selected portfolio, we will achieve optimal performance or close to it, whereas approaches that allocate time slices may choose the best solver, but fail to achieve optimal performance if too little time is allocated to it. We leverage more information from algorithm selection models than most approaches in the literature, in particular the uncertainty of performance prediction. This allows us to trade off the number of algorithms to choose with the chance of success in a principled way. Our approach is designed to optimize the usage of parallel computational resources when solving combinatorial problems while taking into account the overhead that arises from parallel runs. To the best of our knowledge, there are no other approaches that solve parallel algorithm selection this way.</p>
</section>
</section>
</section>
<section id="parallel-portfolio-selection" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="parallel-portfolio-selection"><span class="header-section-number">5.3</span> Parallel Portfolio Selection</h2>
<p>We aim to choose a sub-portfolio of solvers $ P_i S $ for a given instance <span class="math inline">\(i \in I\)</span> that includes the algorithms with the best performance on <span class="math inline">\(i\)</span> ($ A S $ and $ A P_i $) to run in parallel, based on the predicted performance of each solver. Given the predicted performance metric <span class="math inline">\(\hat{m}\)</span>, we can define a total order of the algorithms in the portfolio <span class="math inline">\(S\)</span> for a given instance <span class="math inline">\(i\)</span>. This total order is induced by the ranking of the algorithms based on their predicted performance for instance <span class="math inline">\(i\)</span>. Formally, the total order can be defined as: <span class="math display">\[\label{eq:3}
A &lt; B \quad \text{if} \quad \hat{m}(A,i) &lt; \hat{m}(B,i); A,B \in S\]</span></p>
<p>Given the total order, the rank of each algorithm <span class="math inline">\(A\)</span> on each instance <span class="math inline">\(i\)</span> can be defined as the number of algorithms that are predicted to be strictly better than <span class="math inline">\(A\)</span> for the instance and denoted <span class="math inline">\(r_{A,i}\)</span>. Ties are broken arbitrarily. A portfolio of a specified size <span class="math inline">\(n\)</span> is then defined as the top <span class="math inline">\(n\)</span> algorithms according to rank for that particular instance. The portfolio of size <span class="math inline">\(n\)</span> for instance <span class="math inline">\(i\)</span> can be expressed mathematically as: <span class="math display">\[\label{eq:4}
P_i = \{A \in S \: | \: r_{A,i} \leq n\}\]</span></p>
<p>In a slight abuse of notation, we will denote the rank of an algorithm as a subscript, i.e.&nbsp;<span class="math inline">\(r_{A,i}\)</span> is the rank of algorithm <span class="math inline">\(A\)</span> on instance <span class="math inline">\(i\)</span> and <span class="math inline">\(A_{1,i}\)</span> is the algorithm of rank <span class="math inline">\(1\)</span> (the best performing algorithm) on instance <span class="math inline">\(i\)</span>.</p>
<p>This allows to choose a subset of algorithms with the best predicted performance for a given instance, which can then be executed in parallel. However, determining the portfolio size <span class="math inline">\(n\)</span> for a given problem instance is the key challenge for parallel portfolios. As discussed above, choosing only a single algorithm or all algorithms is unlikely to give optimal performance in practice. The larger the number of algorithms we include, the larger the chance that the best algorithm is in the chosen portfolio, but also the larger the overhead from running many algorithms in parallel.</p>
<p>Here, we want to include the algorithms that, according to their predicted performance on a new problem instance, have the highest chances of achieving optimal performance, while also taking into account the computational overhead of running multiple solvers in parallel. We leverage the uncertainty of the predictions of the performance models to gauge the likelihood that a given algorithm would be competitive. To the best of our knowledge, there are no algorithm selection approaches that do this.</p>
<p>Instead of considering only a point prediction, we consider the predicted distribution of performance metric values, characterized by its mean and standard deviation. Formally, we denote the standard deviation of the prediction <span class="math inline">\(\hat{m}(A, i)\)</span> as <span class="math inline">\(\sigma_{A, i}\)</span> for each solver <span class="math inline">\(A\)</span> and instance <span class="math inline">\(i\)</span>. We assume that the predictions of our performance models follow a normal distribution, i.e.&nbsp;the predicted value is the mean of that distribution and allows to characterize it completely together with the standard deviation. We assess the likelihood of two algorithms performing equally well by computing the overlap between their distributions. If two algorithms are predicted to perform very similarly, then the overlap between the distributions will be very large.</p>
<p>We are in particular interested in the predicted performance distribution of the best-predicted algorithm <span class="math inline">\(A_{1,i}\)</span> (no algorithms are predicted to perform better than it), and how the predictions for the other algorithms compare to it. Formally, for the best predicted solver <span class="math inline">\(A_{1,i}\)</span> on instance <span class="math inline">\(i\)</span> the distribution of predictions is $ (A_{1,i}, i) (<em>{A</em>{1,i},i}, ^2_{A_{1,i},i}) $ with probability density function $ f_{A_{1,i},i}$ and cumulative distribution function <span class="math inline">\(F_{A_{1,i},i}\)</span>. The performance distributions for other algorithms are defined similarly.</p>
<p>For the distributions of the predicted performance of two algorithms <span class="math inline">\(A_x\)</span> and <span class="math inline">\(A_y\)</span> on instance <span class="math inline">\(i\)</span>, the point of intersection <span class="math inline">\(c\)</span> can be computed as <span class="math inline">\(f_{A_x,i}(c) =  f_{A_y,i}(c)\)</span>. That is, the predicted probability of achieving this particular performance is equal for both distributions (illustrated in Figure&nbsp;<a href="#fig:overlappingarea" data-reference-type="ref" data-reference="fig:overlappingarea">1.1</a>). For <span class="math inline">\(\mu_{A_x,i} &lt; \mu_{A_y,i}\)</span>, <span class="math inline">\(c\)</span> is defined as (we omit the index <span class="math inline">\(i\)</span> for the sake of brevity here):</p>
<p><span class="math display">\[\label{eq:5}
{c = \frac{\mu _{A_y} \sigma _{A_x}^2-\sigma _{A_y} \left(\mu _{A_x} \sigma _{A_y}+\sigma _{A_x} \sqrt{\left(\mu _{A_x}-\mu _{A_y}\right){}^2+2 \left(\sigma _{A_x}^2-\sigma _{A_y}^2\right) \log \left(\frac{\sigma _{A_x}}{\sigma _{A_y}}\right)}\right)}{\sigma _{A_x}^2-\sigma _{A_y}^2}}\]</span></p>
<p>Given <span class="math inline">\(c\)</span>, the overlap between the distributions is defined as the joint probability of <span class="math inline">\(A_x\)</span> performing worse than <span class="math inline">\(c\)</span> and <span class="math inline">\(A_y\)</span> performing better than <span class="math inline">\(c\)</span>:</p>
<p><span class="math display">\[\label{eq:6}
    p(\hat{m}({A_{x,i}}, i) \geq c) \cdot p(\hat{m}({A_{y,i}}, i) \leq c) = 1 - F_{A_{x,i},i}(c) +  F_{A_{y,i},i}(c)\]</span></p>
<p>We define <span class="math inline">\(p_{\cap} \in [0,1]\)</span> as a threshold for the computed joint probability to include a given algorithm:</p>
<p><span class="math display">\[\label{eq:7}
P_i = \{A \:| \: \left(p(\hat{m}({A_{1,i},i)} \geq c) \: \cdot \: p(\hat{m}({A_{x,i}}, i) \leq c)\right) \geq \:p_{\cap}\:\}\]</span></p>
<p><span class="math inline">\(p_{\cap}\)</span> is 1 for the best predicted algorithm, and 0 for algorithms whose distribution does not have any overlap with that of the best predicted algorithm, i.e.&nbsp;the probability of performing at least as good as the best predicted algorithm is 0.</p>
<p>We can control the size of the parallel portfolio by adjusting the value of <span class="math inline">\(p_{\cap}\)</span>. If <span class="math inline">\(p_{\cap}\)</span> is set to 1, only the best predicted algorithm and ones that are predicted to perform exactly like it are included. On the other hand, if <span class="math inline">\(p_{\cap}\)</span> is set to 0, all algorithms will be included. This allows us to tune our approach to a given algorithm selection scenario and choose the algorithms to run in parallel very flexibly, also accommodating potentially inaccurate performance predictions.</p>
<figure id="fig:overlappingarea" class="figure">
<embed src="plots/ovelappingarea.svg" style="width:80.0%">
<figcaption>
Overlapping area of two normal distributions. The point <span class="math inline">(c)</span> is the performance both distributions are equally likely to achieve. The shaded area denotes the probability of overlap between the two distributions; in our case, the probability that the candidate solver will perform as least as well as the best predicted solver.
</figcaption>
</figure>
</section>
<section id="experimental-setup" class="level2 page-columns page-full" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="experimental-setup"><span class="header-section-number">5.4</span> Experimental Setup</h2>
<section id="data-collection" class="level3 page-columns page-full" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="data-collection"><span class="header-section-number">5.4.1</span> Data Collection</h3>
<p>We used three scenarios from the ASlib benchmark repository &nbsp;<span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>: MAXSAT19-UCMS, SAT11-INDU, and SAT18-EXP. Additionally, we created two new scenarios: SAT16-MAIN, which utilizes solvers and instances from the SAT Competition 2016, and IPC2018, which incorporates solvers and instances from the International Planning Competition 2018. As ASlib only offers algorithm performance data for single runs, we conducted our own measurements for parallel runs on individual machines. We also measured the performance for single runs again and repeated the instance feature extraction steps to ensure that all experiments were performed on the same hardware. For MAXSAT19-UCMS, SAT11-INDU<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, SAT16-MAIN, and SAT18-EXP, we used SATZilla’s feature computation code&nbsp;<span class="citation" data-cites="satzilla">(<a href="#ref-satzilla" role="doc-biblioref">Xu et al. 2008</a>)</span>, and extracted 54 different features. For IPC2018 we used the feature extraction code by&nbsp;<span class="citation" data-cites="Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014">(<a href="#ref-Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014" role="doc-biblioref">Fawcett et al. 2014</a>)</span> which extracts 305 features for planning problems in PDDL format. We excluded 26 instances of SAT Competition 2016 from the SAT16-MAIN scenario because we were unable to extract features within two hours of computational time. We also omitted two solvers, glocusePLE and Scavel_SAT, from SAT16-MAIN because of frequent out-of-memory errors on multiple instances. From IPC2018, we omitted three solvers, MSP, maplan-1, and maplan-2, because they require an unavailable version of CPLEX. Table&nbsp;<a href="#tab:scenarios" data-reference-type="ref" data-reference="tab:scenarios">1.1</a> gives an overview of the scenarios, algorithms, instances, and features we use in our evaluation.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;For SAT11-INDU, the ASlib benchmark repository contains 115 extracted features, including those from SATZilla. However, we were unable to find the feature extraction for this scenario and used the same 54 instance features extracted by SATZilla.</p></div></div><div id="tab:scenarios">
<table class="caption-top table">
<caption>Number of Algorithms, Instances, and Features Across All Scenarios.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Scenario</th>
<th style="text-align: center;">Algorithms</th>
<th style="text-align: center;">Instances</th>
<th style="text-align: center;">Instance Features</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">IPC2018</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">240</td>
<td style="text-align: center;">305</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">MAXSAT19-UCMS</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">572</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT11-INDU</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">300</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">SAT16-MAIN</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">274</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT18-EXP</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">353</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>We ran all solvers on all instances on compute nodes with 32 processors and 40 MB cache size (Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz), 128 GB memory, and Red Hat Linux version 8.6. We use the same time limits as in the ASlib scenarios; 5000 CPU seconds for SAT18-EXP and SAT11-INDU, and 3600 CPU seconds for MAXSAT19-UCMS. For the new scenarios, we use the same time limits as the respective competitions; 5000 CPU seconds for SAT16-MAIN and 1800 CPU seconds for IPC2018. We ran each algorithm individually with 2-10 parallel runs. For all experiments, we ensured that only the given number of parallel runs were executed on a single machine. As our previous work showed that performance becomes worse than algorithm selection of a single solver for more than 10 parallel runs&nbsp;<span class="citation" data-cites="pmlr-v140-kashgarani21a">(<a href="#ref-pmlr-v140-kashgarani21a" role="doc-biblioref">Kashgarani and Kotthoff 2021</a>)</span>, we did not evaluate more than 10 parallel runs.</p>
</section>
<section id="training-and-tuning" class="level3 page-columns page-full" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="training-and-tuning"><span class="header-section-number">5.4.2</span> Training and Tuning</h3>
<p>In the paper &nbsp;<span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>, we first built random forest regression models to predict the performance of an algorithm on an instance using LLAMA&nbsp;<span class="citation" data-cites="LLAMA">(<a href="#ref-LLAMA" role="doc-biblioref">Kotthoff 2013</a>)</span> and MLR&nbsp;<span class="citation" data-cites="mlr">(<a href="#ref-mlr" role="doc-biblioref">Bischl, Lang, et al. 2016</a>)</span>. To expand on the results of the paper, in addition to the initial performance model, we trained two additional algorithm selection performance models using the random forest implementation in the MLR3 package. We compared these with the previous randomForest model trained with the MLR package in R.</p>
<p>MLR is an R package that unifies the available implementations of machine learning algorithms in R <span class="citation" data-cites="mlr">(<a href="#ref-mlr" role="doc-biblioref">Bischl, Lang, et al. 2016</a>)</span>. In MLR, the Random Forests learner uses the randomForest package in R <span class="citation" data-cites="randomforest">(<a href="#ref-randomforest" role="doc-biblioref">Breiman 2001</a>)</span> as a dependency. The MLR package extends this algorithm by providing one method to estimate the uncertainties of the predictions, which is the Jackknife <span class="citation" data-cites="wager2014confidence">(<a href="#ref-wager2014confidence" role="doc-biblioref">Wager, Hastie, and Efron 2014</a>)</span> technique. MLR3 <span class="citation" data-cites="Bischl2024">(<a href="#ref-Bischl2024" role="doc-biblioref">Bischl et al. 2024</a>)</span>, on the other hand, is the latest version of the MLR release, offering enhanced features. Some learners differ between MLR and MLR3. In MLR, training random forests uses the implementation of the randomForest R package, while MLR3 replaces this with the Ranger R package. According to its documentation, Ranger is designed to be a fast implementation of random forests, particularly for high-dimensional data <span class="citation" data-cites="ranger">(<a href="#ref-ranger" role="doc-biblioref">Wright and Ziegler 2017</a>)</span>. In Ranger’s paper <span class="citation" data-cites="ranger">(<a href="#ref-ranger" role="doc-biblioref">Wright and Ziegler 2017</a>)</span> it outperforms other implementations, including randomForest, in terms of runtime and memory usage, especially as the number of trees, features, and sample sizes increases, and Ranger scaled almost linearly with the number of samples, while randomForest scaled superlinearly <span class="citation" data-cites="ranger">(<a href="#ref-ranger" role="doc-biblioref">Wright and Ziegler 2017</a>)</span>.</p>
<p>Our MLR regression random forest models predict the runtime for each solver as the mean of the underlying distribution, and estimate the standard deviation using the Jackknife method&nbsp;<span class="citation" data-cites="wager2014confidence mlr">(<a href="#ref-wager2014confidence" role="doc-biblioref">Wager, Hastie, and Efron 2014</a>; <a href="#ref-mlr" role="doc-biblioref">Bischl, Lang, et al. 2016</a>)</span>, which calculates the standard deviation of the mean predictions over all observations used to train the random forest. The random forest is trained on <span class="math inline">\(n-1\)</span> observations and makes a prediction for the remaining observation. This process is repeated for all observations. The mean prediction for each tree is determined by averaging its predictions for the left-out observations. The Jackknife method assumes that the distribution of the predictions is normal, and their standard deviation is the uncertainty of the overall prediction.</p>
<p>Ranger allows two different methods to estimate prediction uncertainties <span class="citation" data-cites="wager2014confidence">(<a href="#ref-wager2014confidence" role="doc-biblioref">Wager, Hastie, and Efron 2014</a>)</span>: the Jackknife (also known as the jackknife-after-bootstrap) and the infinitesimal Jackknife (also known as the infinitesimal-jackknife-for-bagging). We built random forest regression models using the Ranger package twice: one model with the Jackknife method (RJ) to estimate prediction uncertainty and the other with the Infinitesimal Jackknife method (RI).</p>
<p>The Jackknife and infinitesimal Jackknife methods both estimate the standard deviation, but differ in approach and efficiency according to <span class="citation" data-cites="wager2014confidence">(<a href="#ref-wager2014confidence" role="doc-biblioref">Wager, Hastie, and Efron 2014</a>)</span>. The jackknife removes one observation at a time to assess the impact, while the infinitesimal jackknife downweights each observation by an infinitesimal amount. So, the infinitesimal Jackknife method downweights each observation by a very small amount. This approach often leads to more stable predictions and is more computationally efficient, as it requires fewer bootstrap replicates for similar accuracy <span class="citation" data-cites="wager2014confidence">(<a href="#ref-wager2014confidence" role="doc-biblioref">Wager, Hastie, and Efron 2014</a>)</span>.</p>
<p>Random forests usually result in the best algorithm selection performance and performance predictions&nbsp;<span class="citation" data-cites="BISCHL201641 HUTTER201479">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>; <a href="#ref-HUTTER201479" role="doc-biblioref">Hutter et al. 2014</a>)</span>. Our setup mirrors that of&nbsp;<span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>: we removed constant-valued instance features and imputed missing feature values with the mean of all non-missing values for that feature. The hyperparameters of the random forest models were tuned using random search with 250 iterations, with <span class="math inline">\(ntree\)</span> ranging from 10 to 200 and <span class="math inline">\(mtry\)</span> from 1 to 30 in a nested cross-validation with three inner folds and 10 outer folds&nbsp;<span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>.</p>
<p>Since the available version of LLAMA <span class="citation" data-cites="LLAMA">(<a href="#ref-LLAMA" role="doc-biblioref">Kotthoff 2013</a>)</span> was only adapted to MLR, we ported the LLAMA package to MLR3 to conduct experiments and compare different implementations<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. This update will be available to the community in the near future as CRAN R package.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;https://github.com/uwyo-mallet/llama-mlr3</p></div></div><p>To determine the optimal value of <span class="math inline">\(p_{\cap}\)</span> in Equation&nbsp;<a href="#eq:6" data-reference-type="ref" data-reference="eq:6">[eq:6]</a> for each scenario, we perform a grid search in the <span class="math inline">\([0, 1)\)</span> interval with a resolution of <span class="math inline">\(0.01\)</span> for a total of 100 values. Additionally, we determine the overall optimal value of <span class="math inline">\(p_{\cap}\)</span> across all five scenarios.</p>
<p>We evaluate the proposed approach using penalized average runtime with a factor of 10 (PAR10), misclassification penalty (MCP), runtime. The PAR10 score is equal to the actual runtime when the algorithm succeeds in solving the instance within the timeout, otherwise, it is the timeout times 10. The misclassification penalty is the difference between the performance of the selected algorithm and the performance of the optimal algorithm. We report the mean and standard deviation of these values in Tables&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a>,&nbsp;<a href="#tab:summary2" data-reference-type="ref" data-reference="tab:summary2">1.4</a>, and&nbsp;<a href="#tab:summary2" data-reference-type="ref" data-reference="tab:summary2">1.4</a>.</p>
<p>We also measure the PAR10 score normalized gap closed between the sequential single best solver and the sequential virtual best solver. In Tables&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a>,&nbsp;<a href="#tab:summary2" data-reference-type="ref" data-reference="tab:summary2">1.4</a>, and&nbsp;<a href="#tab:summary2" data-reference-type="ref" data-reference="tab:summary2">1.4</a>, we report the mean and standard deviation of the normalized gap closed across the 10 folds of data used to train the performance models. In contrast to the reported runtime, MCP and PAR10 scores, in these tables, we do not report the mean and standard deviation in the distribution of all instances. Instead, we use folds because, based on the normalized gap closed formula <span class="math inline">\(\frac{\text{sbs} - \text{approach}}{\text{sbs} - \text{vbs}}\)</span>, we aimed to avoid zero denominators in cases where the single best solver is the actual best solver for an instance. The plots&nbsp;<a href="#fig:all_results" data-reference-type="ref" data-reference="fig:all_results">1.3</a>, show the PAR10 score normalized gap closed over the entire distribution of instances.</p>
</section>
<section id="baselines" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="baselines"><span class="header-section-number">5.4.3</span> Baselines</h3>
<p>We compare the performance of our approach to several baseline methods, in particular the sequential virtual best solver (VBS), which is the optimal algorithm from the portfolio per problem instance (with a cumulative misclassification penalty of zero) and the sequential single best solver (SBS), which is the algorithm from the portfolio with the best average performance across all problem instances. The VBS for parallel runs is the best solver for each instance, but including the overhead for <span class="math inline">\(n\)</span> parallel runs. The parallel SBS is computed similarly, with the best solvers on average instead of the best on each instance. We run multiple solvers in parallel to measure the actual runtime of the best solver in this case, rather than assuming the sequential runtime.</p>
<p>We further compare to per-instance algorithm selection that simply runs the top <span class="math inline">\(n\)</span> predicted algorithms in parallel without considering the overlap of the distributions of the performance predictions, with the same performance models we use for our approach. In the notation we introduced above, we set <span class="math inline">\(p_{\cap}=0\)</span> and cap the number of runs at the number of available processors. We use a simple scheduling method as a further baseline, where algorithms are scheduled according to their predicted rank and allocated a time slice equal to the predicted performance plus the standard deviation. This allows to run more than one algorithm per processor. This approach prioritizes the best-predicted algorithms but also potentially allows other algorithms to run.</p>
<p>ASPEED&nbsp;<span class="citation" data-cites="aspeed">(<a href="#ref-aspeed" role="doc-biblioref">Hoos et al. 2015</a>)</span> provides a general schedule for all instances in a given scenario, rather than a schedule for each instance individually. Therefore, we do not include ASPEED in our experimental evaluation – static schedules across large sets of problem instances do not achieve competitive performance, as shown in&nbsp;<span class="citation" data-cites="flexfolio">(<a href="#ref-flexfolio" role="doc-biblioref">Lindauer, Bergdoll, and Hutter 2016</a>)</span>. The Flexfolio paper&nbsp;<span class="citation" data-cites="flexfolio">(<a href="#ref-flexfolio" role="doc-biblioref">Lindauer, Bergdoll, and Hutter 2016</a>)</span> shows experiments for Instance-Specific ASPEED and TSunny, but the available source code does not contain these algorithm selection methods and we are unable to compare to them.</p>
<p>Finally, we compare our approach to 3S as implemented in Flexfolio&nbsp;<span class="citation" data-cites="flexfolio">(<a href="#ref-flexfolio" role="doc-biblioref">Lindauer, Bergdoll, and Hutter 2016</a>)</span>, as the original 3S implementation is unavailable. In this implementation, the number of neighbors for the kNN models was set to 32, and ASPEED&nbsp;<span class="citation" data-cites="aspeed">(<a href="#ref-aspeed" role="doc-biblioref">Hoos et al. 2015</a>)</span> is used to schedule the chosen solvers instead of the original integer programming scheduler.</p>
<p>We normalize all performances across scenarios by the performances of the VBS and SBS and report the fraction of the gap between them that was closed by a particular approach. On this normalized scale, 0 corresponds to the performance of the SBS and 1 to the performance of the VBS. All code and data are available at <a href="https://github.com/uwyo-mallet/auto-parallel-portfolio-selection" class="uri">https://github.com/uwyo-mallet/auto-parallel-portfolio-selection</a>.</p>
</section>
</section>
<section id="results" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="results"><span class="header-section-number">5.5</span> Results</h2>
<section id="tuning-of-p_cap" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="tuning-of-p_cap"><span class="header-section-number">5.5.1</span> Tuning of <span class="math inline">\(p_{\cap}\)</span></h3>
<figure id="fig:sensitivity" class="figure">
<p>
<embed src="plots/Theta_sensitivity_x_theta_y_runtime_facet.svg" style="width:48.0%">
<embed src="plots/pcap_ri_sensitivity_x_theta_y_runtime_facet.svg" style="width:48.0%">
<embed src="plots/pcap_rj_sensitivity_x_theta_y_runtime_facet.svg" style="width:48.0%">
</p>
<figcaption>
Sensitivity of portfolio performance to <span class="math inline">(p_{})</span>. The top-left plot refers to the RFJ model—Regression Random Forest model using MLR with the Jackknife uncertainty estimation method. The top-right plot refers to the RI model—Regression Ranger model with the Infinitesimal Jackknife uncertainty estimation method. The bottom plot refers to the RJ model—Regression Ranger model with the Jackknife uncertainty estimation method. The plot illustrates the mean, Q1 (25th percentile), Q2 (50th percentile), and Q3 (75th percentile) runtime performance of each scenario for various values of <span class="math inline">(p_{})</span> as defined in Equation&nbsp;<a href="#eq:7" data-reference-type="ref" data-reference="eq:7">[eq:7]</a>. Note the log scale for the normalized gap closed.
</figcaption>
</figure>
<p>The tuning of <span class="math inline">\(p_{\cap}\)</span> shows that the optimal value depends on the scenario. For the IPC2018 scenario, the ideal <span class="math inline">\(p_{\cap}\)</span> value is 0.59, for the MAXSAT19-UCMS scenario 0.55, for SAT11-INDU 0.63, for SAT16-MAIN 0.33, and for SAT18-EXP 0.81 for the random forest model trained using the MLR and Jackknife uncertainty estimation method (RFJ). The optimal <span class="math inline">\(p_{\cap}\)</span> values for the Ranger models, one with Jackknife (RJ) and the other with Infinitesimal Jackknife (RI), are provided in Table&nbsp;<a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">1.2</a>.</p>
<div id="tab:pcap">
<table class="caption-top table">
<caption>Optimum value of <span class="math inline">\(p_{\cap}\)</span> for each benchmark and model.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Scenario</th>
<th style="text-align: center;">RandomForest_Jackknife</th>
<th style="text-align: center;">Ranger_Jackknife</th>
<th style="text-align: center;">Ranger_Inifinitesimal</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">IPC2018</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.27</td>
<td style="text-align: center;">0.44</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">MAXSAT19-UCMS</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">0.03</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT11-INDU</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.01</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">SAT16-MAIN</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT18-EXP</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.55</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">Generic best</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.17</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>Figures&nbsp;<a href="#fig:sensitivity" data-reference-type="ref" data-reference="fig:sensitivity">1.2</a> shows the normalized gap closed for the mean, 25th percentile, 50th percentile, and 75th percentiles for each scenario depending on <span class="math inline">\(p_{\cap}\)</span>. While the optimal values are very different across different scenario and each algorithm selector, the differences in terms of gap closed are relatively small as long as <span class="math inline">\(p_{\cap}\)</span> is not too large. The best average value for <span class="math inline">\(p_{\cap}\)</span> across all scenarios for RFJ model, RI model, and RJ model are 0.82, 0.17, 0.31 respectively which yields performance improvements over the baselines in most cases (see Table&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a>). For the overall best performance, we recommend to tune <span class="math inline">\(p_{\cap}\)</span> for the particular scenario. However, using the generic best values of 0.82, 0.17, and 0.31 for RFJ, RI, and RJ, respectively, provides a reasonable starting point that yields good performance across the range of scenarios considered here.</p>
<p>The optimal value of <span class="math inline">\(p_{\cap}\)</span> allows us to draw conclusions with respect to the predictive accuracy of the performance models we are using. A small value would suggest that the predictions of the performance models are not very accurate, as we have to include even solvers whose predicted runtime distribution has a small overlap with the runtime distribution of the best predicted solver to include solvers that are actually good. If the optimal value of <span class="math inline">\(p_{\cap}\)</span> was 0, we would have to include all solvers, even the ones whose predicted distribution has no overlap with the best predicted solver – in other words, the predicted runtime distribution of the actual best solver has no overlap with the predicted runtime distribution of the best predicted solver.</p>
<p>Here, for the RFJ model, the optimal values for <span class="math inline">\(p_{\cap}\)</span> are relatively large in most cases, and even the smallest values are far greater than 0. For the RJ model, the values are lower than those for the RFJ model, except for SAT16-MAIN, where the values are equal. For the RI model, except for IPC2018, the values are even lower than those for the RJ model. This indicates that the predictions of the performance models for RFJ are quite good – while the best predicted solver is not always the actual best solver for a given problem instance, the predicted runtime distribution of the actual best solver has a large overlap with the predicted runtime distribution of the predicted best solver.</p>
<p>Based on the low values of the RI model, it appears that this model performs worse than the other two. This claim is also evident in Table&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a> where, for IPC2018, MAXSAT19-UCMS, and SAT11-INDU, the performance of the <span class="math inline">\(AS\)</span> (RI) model is worse than the other two in at least two of the performance measurements. For SAT16-MAIN, the <span class="math inline">\(AS\)</span> (RI) model performs worst only in terms of PAR10, indicating more timeouts; however, on average, it provides better runtime predictions, so the runtime and MCP measures are better than those of the RJ model. For SAT18-EXP, as shown in Table&nbsp;<a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">1.2</a>, the RI model has a slightly lower <span class="math inline">\(p_{\cap}\)</span> value than the RJ model; however, the difference is minimal, and the RI model performs better than the RJ model according to Table&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a>. Overall, according to Table&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a>, the RFJ model outperforms the other two models in at least two performance metrics in 4 out of 5 scenarios when performing single algorithm selection.</p>
</section>
<section id="algorithm-selection-results" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="algorithm-selection-results"><span class="header-section-number">5.5.2</span> Algorithm Selection Results</h3>
<figure id="fig:all_results" class="figure">
<embed src="plots/line_chart_parallel_NormalizedGap_2col.svg" style="width:95.0%">
<figcaption>
Summary of results. The plot shows the degree to which the gap between the SBS and VBS PAR10 scores is closed by each method. For the VBS and SBS, we choose the top <span class="math inline">(n)</span> solvers, where <span class="math inline">(n)</span> is the number of processors, for a given problem instance and across all instances, respectively. <span class="math inline">(AS_0)</span> chooses the top <span class="math inline">(n)</span> solvers predicted by algorithm selection, without regard for any overlap in their predicted runtime distributions. <span class="math inline">(AS_{p_{}})</span> represents the proposed formulation, with the number of processors restricted to at most the specific value indicated on the x axis – depending on the overlap of the predicted runtime distributions, fewer solvers than the maximum may be chosen. The <span class="math inline">(p_{})</span> values for IPC2018, MAXSAT19-UCMS, SAT11-INDU, SAT18-EXP, and SAT16-MAIN are 0.59, 0.55, 0.63, 0.81, and 0.33 and respectively. Time Splitting is the baseline approach that allocates time proportional to the predicted runtime and standard deviation for each solver, scheduling more than one solver to be run per processor.
</figcaption>
</figure>
<figure id="fig:x_Scenario_y_Solver" class="figure">
<p>
<embed src="plots/x_Scenario_y_Solver.svg" style="width:60.0%">
<embed src="plots/number_of_solvers_infjack_pcap.svg" style="width:60.0%">
<embed src="plots/number_of_solvers_jack_pcap.svg" style="width:60.0%">
</p>
<figcaption>
Violin plot of the distribution of the number of selected solvers to run in parallel across all problem instances for each scenario for the respective optimal <span class="math inline">(p_{})</span> and the maximum level of parallelism (seven processors for MAXSAT19-UCMS and 10 for all other scenarios). The diamond denotes the mean value. The top-left plot refers to the RFJ model, the top-right plot to the RI model, and the bottom plot to the RJ model.
</figcaption>
</figure>
<p>To evaluate the effectiveness of our approach, we carried out a series of experiments using the optimum and the average best value for <span class="math inline">\(p_{\cap}\)</span> for each scenario using the RFJ model where we varied the number of processors used for parallel execution from one to ten for the SAT18-EXP, SAT16-MAIN, SAT11-INDU, and IPC2018 scenarios. For the MAXSAT19-UCMS scenario, we used a maximum of seven processors as there are only seven algorithms. For RFJ model Figure&nbsp;<a href="#fig:all_results" data-reference-type="ref" data-reference="fig:all_results">1.3</a> shows the PAR10 score results in terms of the normalized performance gap between the sequential single best solver and sequential virtual best solver for all scenarios and numbers of processors.</p>
<p>The figure demonstrates the promise of the approach we propose here. In three out of five scenarios, we achieve the overall top performance with the maximum number of processors (even better than the parallel virtual best solver!) and for the remaining two scenarios only the parallel virtual best solver is better. We are able to achieve better performance than the parallel virtual best solver when running in parallel because our approach does not necessarily use all available processors, unlike the baseline approaches that we compare to. While the performance of the virtual best solver suffers for a large number of parallel runs, our approach keeps the overhead of running many things in parallel low and is thus better overall. We emphasize that the results we show here are actual measured values for running in parallel, rather than assuming overhead-free parallelization based on sequential runtimes, as is commonly done in the literature. Our results demonstrate that this common assumption is unrealistic except for a small number of parallel runs.</p>
<p>Even for a small number of processors, our approach yields better performance than others. Initially, the performance is similar to <span class="math inline">\(AS_0\)</span> (running the top <span class="math inline">\(n\)</span> solvers), but our approach quickly becomes better as the number of available processors increases. This is expected, as for a single processor the two methods run exactly the same solver, but for a larger number of processors our method may not run as many as <span class="math inline">\(AS_0\)</span>, thus decreasing overhead and overall solving performance.</p>
<p>For the IPC2018 scenario, we achieve the best overall results, improving performance substantially over all other approaches for 10 processors. The 3S approach is never close to the performance of our method and consistently yields worse results. The greedy time-splitting method also underperformed, often allocating time slices smaller than required to solve the instance and thus wasting resources. For more than seven parallel runs, the parallel virtual best solver, i.e.&nbsp;choosing the actual best solvers for each instance to run in parallel, starts to perform worse than our method, which does not use as many processors and incurs lower overhead.</p>
<p>The results for the other scenarios are qualitatively similar. While for a small number of processors, other methods perform similar to ours, the gap between them widens as the number of parallel runs increases. 3S consistently shows worse performance, whereas running the top <span class="math inline">\(n\)</span> solvers based on algorithm selection (without considering the predicted performance distributions) is usually competitive and in some cases gives the same performance as our method. The baseline of allocating a time to run proportional to the predicted runtime and standard deviation for each solver is not competitive, consistently showing bad performance – this baseline is worse than simply running the top <span class="math inline">\(n\)</span> single best solvers in parallel on three scenarios for large numbers of parallel runs. For the IPC2018 and MAXSAT19-UCMS scenarios, the performance of some methods becomes worse than the single best solver for large numbers of processors, showing the limitations of these approaches. For the SAT2016-MAIN scenario, our approach is performing so close to the naïve parallel algorithm selection (top <span class="math inline">\(n\)</span> solvers based on algorithm selection) because the standard error of the predictions was large and this resulted in large parallel portfolios for the majority of instances.</p>
<p>Table&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a> shows more detailed results. The normalized gap closed represented the mean and standard deviation of the normalized gap closed across the 10 folds, whereas the &nbsp;<a href="#fig:all_results" data-reference-type="ref" data-reference="fig:all_results">1.3</a> shows the mean of the normalized gap closed across all instances at once. We see that our method results in substantial savings in terms of all three measures across all scenarios – the proposed approach is always the best overall, regardless of the performance measure. Note that we never beat the sequential VBS, which represents the upper bound on the performance of any algorithm selection system – we cannot do better than only running the actual best solver. In many cases, the actual performance we achieve is close to the sequential VBS though. The results also show that using the “generic” best value for <span class="math inline">\(p_{\cap}\)</span> of 0.82 still gives substantial performance improvements over other approaches – usually it gives the second best performance. The only exception to this are the MAXSAT19-UCMS and SAT2016-MAIN scenarios, where running the top <span class="math inline">\(n\)</span> solvers predicted by algorithm selection does better. The gap is relatively small though, and we still beat most of the other baselines.</p>
<div class="center">
<div id="tab:summary">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for IPC2018, and 7 for MAXSAT19-UCMS) for our approach and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">508<span class="math inline">\(\pm\)</span><!-- -->697</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3478<span class="math inline">\(\pm\)</span><!-- -->6903</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">607<span class="math inline">\(\pm\)</span><!-- -->751</td>
<td style="text-align: center;">99<span class="math inline">\(\pm\)</span><!-- -->301</td>
<td style="text-align: center;">4657<span class="math inline">\(\pm\)</span><!-- -->7725</td>
<td style="text-align: center;">-0.44<span class="math inline">\(\pm\)</span><!-- -->2.84</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">608<span class="math inline">\(\pm\)</span><!-- -->751</td>
<td style="text-align: center;">100<span class="math inline">\(\pm\)</span><!-- -->293</td>
<td style="text-align: center;">4456<span class="math inline">\(\pm\)</span><!-- -->7583</td>
<td style="text-align: center;">-0.35<span class="math inline">\(\pm\)</span><!-- -->2.85</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">604<span class="math inline">\(\pm\)</span><!-- -->752</td>
<td style="text-align: center;">96<span class="math inline">\(\pm\)</span><!-- -->293</td>
<td style="text-align: center;">4519<span class="math inline">\(\pm\)</span><!-- -->7633</td>
<td style="text-align: center;">-0.39<span class="math inline">\(\pm\)</span><!-- -->2.84</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">734<span class="math inline">\(\pm\)</span><!-- -->770</td>
<td style="text-align: center;">226<span class="math inline">\(\pm\)</span><!-- -->414</td>
<td style="text-align: center;">5459<span class="math inline">\(\pm\)</span><!-- -->8072</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">3S</td>
<td style="text-align: center;">645<span class="math inline">\(\pm\)</span><!-- -->770</td>
<td style="text-align: center;">137<span class="math inline">\(\pm\)</span><!-- -->471</td>
<td style="text-align: center;">5235<span class="math inline">\(\pm\)</span><!-- -->8047</td>
<td style="text-align: center;">-0.76<span class="math inline">\(\pm\)</span><!-- -->2.7</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RFJ)</td>
<td style="text-align: center;">637<span class="math inline">\(\pm\)</span><!-- -->797</td>
<td style="text-align: center;">129<span class="math inline">\(\pm\)</span><!-- -->348</td>
<td style="text-align: center;">5565<span class="math inline">\(\pm\)</span><!-- -->8241</td>
<td style="text-align: center;">-0.84<span class="math inline">\(\pm\)</span><!-- -->2.5</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RI)</td>
<td style="text-align: center;">641<span class="math inline">\(\pm\)</span><!-- -->799</td>
<td style="text-align: center;">133<span class="math inline">\(\pm\)</span><!-- -->361</td>
<td style="text-align: center;">5636<span class="math inline">\(\pm\)</span><!-- -->8274</td>
<td style="text-align: center;">-0.99<span class="math inline">\(\pm\)</span><!-- -->2.52</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RJ)</td>
<td style="text-align: center;">636<span class="math inline">\(\pm\)</span><!-- -->794</td>
<td style="text-align: center;">128<span class="math inline">\(\pm\)</span><!-- -->353</td>
<td style="text-align: center;">5496<span class="math inline">\(\pm\)</span><!-- -->8206</td>
<td style="text-align: center;">-0.92<span class="math inline">\(\pm\)</span><!-- -->2.51</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RFJ)</td>
<td style="text-align: center;">612<span class="math inline">\(\pm\)</span><!-- -->779</td>
<td style="text-align: center;">104<span class="math inline">\(\pm\)</span><!-- -->307</td>
<td style="text-align: center;">5134<span class="math inline">\(\pm\)</span><!-- -->8027</td>
<td style="text-align: center;">-0.66<span class="math inline">\(\pm\)</span><!-- -->2.56</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;">616<span class="math inline">\(\pm\)</span><!-- -->783</td>
<td style="text-align: center;">107<span class="math inline">\(\pm\)</span><!-- -->312</td>
<td style="text-align: center;">5206<span class="math inline">\(\pm\)</span><!-- -->8065</td>
<td style="text-align: center;">-0.69<span class="math inline">\(\pm\)</span><!-- -->2.54</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">616<span class="math inline">\(\pm\)</span><!-- -->783</td>
<td style="text-align: center;">107<span class="math inline">\(\pm\)</span><!-- -->312</td>
<td style="text-align: center;">5206<span class="math inline">\(\pm\)</span><!-- -->8065</td>
<td style="text-align: center;">-0.69<span class="math inline">\(\pm\)</span><!-- -->2.54</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.59}\)</span> (RFJ)</td>
<td style="text-align: center;"><em>569<span class="math inline">\(\pm\)</span><!-- -->745</em></td>
<td style="text-align: center;"><em>61<span class="math inline">\(\pm\)</span><!-- -->223</em></td>
<td style="text-align: center;">4484<span class="math inline">\(\pm\)</span><!-- -->7651</td>
<td style="text-align: center;"><strong>-0.18<span class="math inline">\(\pm\)</span><!-- -->2.74</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.44}\)</span> (RI)</td>
<td style="text-align: center;"><strong>557<span class="math inline">\(\pm\)</span><!-- -->728</strong></td>
<td style="text-align: center;"><strong>49<span class="math inline">\(\pm\)</span><!-- -->190</strong></td>
<td style="text-align: center;"><strong>4135<span class="math inline">\(\pm\)</span><!-- -->7403</strong></td>
<td style="text-align: center;"><em>-0.19<span class="math inline">\(\pm\)</span><!-- -->2.89</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.27}\)</span> (RJ)</td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->744</td>
<td style="text-align: center;">62<span class="math inline">\(\pm\)</span><!-- -->229</td>
<td style="text-align: center;">4350<span class="math inline">\(\pm\)</span><!-- -->7552</td>
<td style="text-align: center;">-0.21<span class="math inline">\(\pm\)</span><!-- -->2.72</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">579<span class="math inline">\(\pm\)</span><!-- -->742</td>
<td style="text-align: center;">70<span class="math inline">\(\pm\)</span><!-- -->233</td>
<td style="text-align: center;">4359<span class="math inline">\(\pm\)</span><!-- -->7548</td>
<td style="text-align: center;">-0.26<span class="math inline">\(\pm\)</span><!-- -->2.88</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->739</td>
<td style="text-align: center;">62<span class="math inline">\(\pm\)</span><!-- -->230</td>
<td style="text-align: center;"><em>4283<span class="math inline">\(\pm\)</span><!-- -->7501</em></td>
<td style="text-align: center;">-0.24<span class="math inline">\(\pm\)</span><!-- -->2.87</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->743</td>
<td style="text-align: center;">62<span class="math inline">\(\pm\)</span><!-- -->229</td>
<td style="text-align: center;">4350<span class="math inline">\(\pm\)</span><!-- -->7552</td>
<td style="text-align: center;">-0.21<span class="math inline">\(\pm\)</span><!-- -->2.72</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">858<span class="math inline">\(\pm\)</span><!-- -->1476</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">7768<span class="math inline">\(\pm\)</span><!-- -->14717</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">1037<span class="math inline">\(\pm\)</span><!-- -->1555</td>
<td style="text-align: center;">179<span class="math inline">\(\pm\)</span><!-- -->641</td>
<td style="text-align: center;">9363<span class="math inline">\(\pm\)</span><!-- -->15684</td>
<td style="text-align: center;">0.55<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1076<span class="math inline">\(\pm\)</span><!-- -->1575</td>
<td style="text-align: center;">218<span class="math inline">\(\pm\)</span><!-- -->729</td>
<td style="text-align: center;">9686<span class="math inline">\(\pm\)</span><!-- -->15850</td>
<td style="text-align: center;">0.45<span class="math inline">\(\pm\)</span><!-- -->0.34</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1044<span class="math inline">\(\pm\)</span><!-- -->1565</td>
<td style="text-align: center;">186<span class="math inline">\(\pm\)</span><!-- -->666</td>
<td style="text-align: center;">9540<span class="math inline">\(\pm\)</span><!-- -->15793</td>
<td style="text-align: center;">0.49<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">1190<span class="math inline">\(\pm\)</span><!-- -->1657</td>
<td style="text-align: center;">332<span class="math inline">\(\pm\)</span><!-- -->940</td>
<td style="text-align: center;">11386<span class="math inline">\(\pm\)</span><!-- -->16696</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>7 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">3S</td>
<td style="text-align: center;">953<span class="math inline">\(\pm\)</span><!-- -->1480</td>
<td style="text-align: center;">95<span class="math inline">\(\pm\)</span><!-- -->437</td>
<td style="text-align: center;">8317<span class="math inline">\(\pm\)</span><!-- -->15031</td>
<td style="text-align: center;">0.83<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RFJ)</td>
<td style="text-align: center;">908<span class="math inline">\(\pm\)</span><!-- -->1523</td>
<td style="text-align: center;">51<span class="math inline">\(\pm\)</span><!-- -->308</td>
<td style="text-align: center;">8668<span class="math inline">\(\pm\)</span><!-- -->15353</td>
<td style="text-align: center;">0.75<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RI)</td>
<td style="text-align: center;">919<span class="math inline">\(\pm\)</span><!-- -->1535</td>
<td style="text-align: center;">61<span class="math inline">\(\pm\)</span><!-- -->356</td>
<td style="text-align: center;">8849<span class="math inline">\(\pm\)</span><!-- -->15470</td>
<td style="text-align: center;">0.7<span class="math inline">\(\pm\)</span><!-- -->0.2</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RJ)</td>
<td style="text-align: center;">917<span class="math inline">\(\pm\)</span><!-- -->1531</td>
<td style="text-align: center;">59<span class="math inline">\(\pm\)</span><!-- -->352</td>
<td style="text-align: center;">8790<span class="math inline">\(\pm\)</span><!-- -->15431</td>
<td style="text-align: center;">0.71<span class="math inline">\(\pm\)</span><!-- -->0.2</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RFJ)</td>
<td style="text-align: center;"><em>894<span class="math inline">\(\pm\)</span><!-- -->1506</em></td>
<td style="text-align: center;"><em>37<span class="math inline">\(\pm\)</span><!-- -->247</em></td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;"><em>894<span class="math inline">\(\pm\)</span><!-- -->1506</em></td>
<td style="text-align: center;"><em>37<span class="math inline">\(\pm\)</span><!-- -->247</em></td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;"><em>894<span class="math inline">\(\pm\)</span><!-- -->1506</em></td>
<td style="text-align: center;"><em>37<span class="math inline">\(\pm\)</span><!-- -->247</em></td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = {0.55}}\)</span> (RFJ)</td>
<td style="text-align: center;"><strong>891<span class="math inline">\(\pm\)</span><!-- -->1496</strong></td>
<td style="text-align: center;"><strong>33<span class="math inline">\(\pm\)</span><!-- -->215</strong></td>
<td style="text-align: center;"><strong>8141<span class="math inline">\(\pm\)</span><!-- -->14975</strong></td>
<td style="text-align: center;"><strong>0.88<span class="math inline">\(\pm\)</span><!-- -->0.17</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.03}\)</span> (RI)</td>
<td style="text-align: center;"><em>894<span class="math inline">\(\pm\)</span><!-- -->1506</em></td>
<td style="text-align: center;"><em>37<span class="math inline">\(\pm\)</span><!-- -->247</em></td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.14}\)</span> (RJ)</td>
<td style="text-align: center;">921<span class="math inline">\(\pm\)</span><!-- -->1521</td>
<td style="text-align: center;">63<span class="math inline">\(\pm\)</span><!-- -->369</td>
<td style="text-align: center;">8568<span class="math inline">\(\pm\)</span><!-- -->15263</td>
<td style="text-align: center;">0.76<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">928<span class="math inline">\(\pm\)</span><!-- -->1513</td>
<td style="text-align: center;">70<span class="math inline">\(\pm\)</span><!-- -->364</td>
<td style="text-align: center;">8461<span class="math inline">\(\pm\)</span><!-- -->15175</td>
<td style="text-align: center;">0.81<span class="math inline">\(\pm\)</span><!-- -->0.18</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">901<span class="math inline">\(\pm\)</span><!-- -->1502</td>
<td style="text-align: center;">43<span class="math inline">\(\pm\)</span><!-- -->275</td>
<td style="text-align: center;"><em>8208<span class="math inline">\(\pm\)</span><!-- -->15015</em></td>
<td style="text-align: center;"><strong>0.88<span class="math inline">\(\pm\)</span><!-- -->0.16</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">931<span class="math inline">\(\pm\)</span><!-- -->1525</td>
<td style="text-align: center;">73<span class="math inline">\(\pm\)</span><!-- -->402</td>
<td style="text-align: center;">8578<span class="math inline">\(\pm\)</span><!-- -->15259</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.21</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="center">
<div id="tab:summary2">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for SAT16-MAIN and SAT11-INDU) for our approach and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1140<span class="math inline">\(\pm\)</span><!-- -->1836</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">8040<span class="math inline">\(\pm\)</span><!-- -->17905</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">1535<span class="math inline">\(\pm\)</span><!-- -->2058</td>
<td style="text-align: center;">395<span class="math inline">\(\pm\)</span><!-- -->1037</td>
<td style="text-align: center;">11735<span class="math inline">\(\pm\)</span><!-- -->20768</td>
<td style="text-align: center;">0.16<span class="math inline">\(\pm\)</span><!-- -->0.79</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1610<span class="math inline">\(\pm\)</span><!-- -->2108</td>
<td style="text-align: center;">470<span class="math inline">\(\pm\)</span><!-- -->1145</td>
<td style="text-align: center;">12710<span class="math inline">\(\pm\)</span><!-- -->21389</td>
<td style="text-align: center;">-0.06<span class="math inline">\(\pm\)</span><!-- -->0.9</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1565<span class="math inline">\(\pm\)</span><!-- -->2049</td>
<td style="text-align: center;">425<span class="math inline">\(\pm\)</span><!-- -->1017</td>
<td style="text-align: center;">11315<span class="math inline">\(\pm\)</span><!-- -->20402</td>
<td style="text-align: center;">0.34<span class="math inline">\(\pm\)</span><!-- -->0.49</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">1818<span class="math inline">\(\pm\)</span><!-- -->2168</td>
<td style="text-align: center;">678<span class="math inline">\(\pm\)</span><!-- -->1340</td>
<td style="text-align: center;">14268<span class="math inline">\(\pm\)</span><!-- -->22154</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">3S</td>
<td style="text-align: center;">1298<span class="math inline">\(\pm\)</span><!-- -->1898</td>
<td style="text-align: center;">158<span class="math inline">\(\pm\)</span><!-- -->546</td>
<td style="text-align: center;">9098<span class="math inline">\(\pm\)</span><!-- -->18780</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.3</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RFJ)</td>
<td style="text-align: center;">1335<span class="math inline">\(\pm\)</span><!-- -->2009</td>
<td style="text-align: center;">225<span class="math inline">\(\pm\)</span><!-- -->708</td>
<td style="text-align: center;">10635<span class="math inline">\(\pm\)</span><!-- -->20138</td>
<td style="text-align: center;">0.49<span class="math inline">\(\pm\)</span><!-- -->0.61</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RI)</td>
<td style="text-align: center;">1429<span class="math inline">\(\pm\)</span><!-- -->2108</td>
<td style="text-align: center;">318<span class="math inline">\(\pm\)</span><!-- -->875</td>
<td style="text-align: center;">12379<span class="math inline">\(\pm\)</span><!-- -->21378</td>
<td style="text-align: center;">0.19<span class="math inline">\(\pm\)</span><!-- -->0.53</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RJ)</td>
<td style="text-align: center;">1334<span class="math inline">\(\pm\)</span><!-- -->1998</td>
<td style="text-align: center;">224<span class="math inline">\(\pm\)</span><!-- -->689</td>
<td style="text-align: center;">10634<span class="math inline">\(\pm\)</span><!-- -->20138</td>
<td style="text-align: center;">0.55<span class="math inline">\(\pm\)</span><!-- -->0.43</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RFJ)</td>
<td style="text-align: center;">1272<span class="math inline">\(\pm\)</span><!-- -->1927</td>
<td style="text-align: center;">161<span class="math inline">\(\pm\)</span><!-- -->548</td>
<td style="text-align: center;">8922<span class="math inline">\(\pm\)</span><!-- -->18645</td>
<td style="text-align: center;"><em>0.89<span class="math inline">\(\pm\)</span><!-- -->0.12</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;"><em>1238<span class="math inline">\(\pm\)</span><!-- -->1892</em></td>
<td style="text-align: center;">127<span class="math inline">\(\pm\)</span><!-- -->385</td>
<td style="text-align: center;"><em>8588<span class="math inline">\(\pm\)</span><!-- -->18350</em></td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">1262<span class="math inline">\(\pm\)</span><!-- -->1910</td>
<td style="text-align: center;">151<span class="math inline">\(\pm\)</span><!-- -->480</td>
<td style="text-align: center;">8612<span class="math inline">\(\pm\)</span><!-- -->18342</td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.63}\)</span> (RFJ)</td>
<td style="text-align: center;">1241<span class="math inline">\(\pm\)</span><!-- -->1901</td>
<td style="text-align: center;">131<span class="math inline">\(\pm\)</span><!-- -->451</td>
<td style="text-align: center;">8591<span class="math inline">\(\pm\)</span><!-- -->18349</td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.01}\)</span> (RI)</td>
<td style="text-align: center;"><strong>1236<span class="math inline">\(\pm\)</span><!-- -->1890</strong></td>
<td style="text-align: center;"><strong>121<span class="math inline">\(\pm\)</span><!-- -->379</strong></td>
<td style="text-align: center;"><strong>8586<span class="math inline">\(\pm\)</span><!-- -->18351</strong></td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">1289<span class="math inline">\(\pm\)</span><!-- -->1934</td>
<td style="text-align: center;">178<span class="math inline">\(\pm\)</span><!-- -->595</td>
<td style="text-align: center;">9089<span class="math inline">\(\pm\)</span><!-- -->18787</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">1247<span class="math inline">\(\pm\)</span><!-- -->1900</td>
<td style="text-align: center;"><em>123<span class="math inline">\(\pm\)</span><!-- -->431</em></td>
<td style="text-align: center;">8747<span class="math inline">\(\pm\)</span><!-- -->18501</td>
<td style="text-align: center;">0.83<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">1259<span class="math inline">\(\pm\)</span><!-- -->1912</td>
<td style="text-align: center;">139<span class="math inline">\(\pm\)</span><!-- -->477</td>
<td style="text-align: center;">8909<span class="math inline">\(\pm\)</span><!-- -->18649</td>
<td style="text-align: center;">0.74<span class="math inline">\(\pm\)</span><!-- -->0.36</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">1289<span class="math inline">\(\pm\)</span><!-- -->1934</td>
<td style="text-align: center;">178<span class="math inline">\(\pm\)</span><!-- -->595</td>
<td style="text-align: center;">9089<span class="math inline">\(\pm\)</span><!-- -->18787</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1867<span class="math inline">\(\pm\)</span><!-- -->2193</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">15005<span class="math inline">\(\pm\)</span><!-- -->22530</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">2315<span class="math inline">\(\pm\)</span><!-- -->2273</td>
<td style="text-align: center;">448<span class="math inline">\(\pm\)</span><!-- -->1109</td>
<td style="text-align: center;">19066<span class="math inline">\(\pm\)</span><!-- -->23883</td>
<td style="text-align: center;">0.33<span class="math inline">\(\pm\)</span><!-- -->0.56</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">2383<span class="math inline">\(\pm\)</span><!-- -->2294</td>
<td style="text-align: center;">516<span class="math inline">\(\pm\)</span><!-- -->1151</td>
<td style="text-align: center;">19956<span class="math inline">\(\pm\)</span><!-- -->24111</td>
<td style="text-align: center;">0.05<span class="math inline">\(\pm\)</span><!-- -->0.66</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">2400<span class="math inline">\(\pm\)</span><!-- -->2269</td>
<td style="text-align: center;">533<span class="math inline">\(\pm\)</span><!-- -->1177</td>
<td style="text-align: center;">19316<span class="math inline">\(\pm\)</span><!-- -->23880</td>
<td style="text-align: center;">0.3<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">2560<span class="math inline">\(\pm\)</span><!-- -->2294</td>
<td style="text-align: center;">693<span class="math inline">\(\pm\)</span><!-- -->1415</td>
<td style="text-align: center;">21940<span class="math inline">\(\pm\)</span><!-- -->24464</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">3S</td>
<td style="text-align: center;">2093<span class="math inline">\(\pm\)</span><!-- -->2228</td>
<td style="text-align: center;">226<span class="math inline">\(\pm\)</span><!-- -->547</td>
<td style="text-align: center;">16874<span class="math inline">\(\pm\)</span><!-- -->23228</td>
<td style="text-align: center;">0.59<span class="math inline">\(\pm\)</span><!-- -->0.59</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RFJ)</td>
<td style="text-align: center;">2101<span class="math inline">\(\pm\)</span><!-- -->2247</td>
<td style="text-align: center;">234<span class="math inline">\(\pm\)</span><!-- -->732</td>
<td style="text-align: center;">16717<span class="math inline">\(\pm\)</span><!-- -->23149</td>
<td style="text-align: center;"><strong>0.78<span class="math inline">\(\pm\)</span><!-- -->0.46</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RI)</td>
<td style="text-align: center;">2089<span class="math inline">\(\pm\)</span><!-- -->2256</td>
<td style="text-align: center;">222<span class="math inline">\(\pm\)</span><!-- -->642</td>
<td style="text-align: center;">17691<span class="math inline">\(\pm\)</span><!-- -->23593</td>
<td style="text-align: center;">0.37<span class="math inline">\(\pm\)</span><!-- -->0.85</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RJ)</td>
<td style="text-align: center;">2098<span class="math inline">\(\pm\)</span><!-- -->2254</td>
<td style="text-align: center;">231<span class="math inline">\(\pm\)</span><!-- -->674</td>
<td style="text-align: center;">17372<span class="math inline">\(\pm\)</span><!-- -->23447</td>
<td style="text-align: center;">0.56<span class="math inline">\(\pm\)</span><!-- -->0.39</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RFJ)</td>
<td style="text-align: center;">2065<span class="math inline">\(\pm\)</span><!-- -->2221</td>
<td style="text-align: center;">198<span class="math inline">\(\pm\)</span><!-- -->652</td>
<td style="text-align: center;"><strong>16189<span class="math inline">\(\pm\)</span><!-- -->22931</strong></td>
<td style="text-align: center;"><em>0.7<span class="math inline">\(\pm\)</span><!-- -->0.39</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;"><strong>2016<span class="math inline">\(\pm\)</span><!-- -->2225</strong></td>
<td style="text-align: center;"><strong>150<span class="math inline">\(\pm\)</span><!-- -->503</strong></td>
<td style="text-align: center;">16469<span class="math inline">\(\pm\)</span><!-- -->23122</td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.6</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">2048<span class="math inline">\(\pm\)</span><!-- -->2228</td>
<td style="text-align: center;">181<span class="math inline">\(\pm\)</span><!-- -->597</td>
<td style="text-align: center;"><em>16336<span class="math inline">\(\pm\)</span><!-- -->23023</em></td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.59</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.33}\)</span> (RFJ)</td>
<td style="text-align: center;">2065<span class="math inline">\(\pm\)</span><!-- -->2221</td>
<td style="text-align: center;">198<span class="math inline">\(\pm\)</span><!-- -->652</td>
<td style="text-align: center;"><strong>16189<span class="math inline">\(\pm\)</span><!-- -->22931</strong></td>
<td style="text-align: center;"><em>0.7<span class="math inline">\(\pm\)</span><!-- -->0.39</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;"><strong>2016<span class="math inline">\(\pm\)</span><!-- -->2225</strong></td>
<td style="text-align: center;"><strong>150<span class="math inline">\(\pm\)</span><!-- -->503</strong></td>
<td style="text-align: center;">16469<span class="math inline">\(\pm\)</span><!-- -->23122</td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.6</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.33}\)</span> (RJ)</td>
<td style="text-align: center;">2088<span class="math inline">\(\pm\)</span><!-- -->2239</td>
<td style="text-align: center;">222<span class="math inline">\(\pm\)</span><!-- -->704</td>
<td style="text-align: center;">16705<span class="math inline">\(\pm\)</span><!-- -->23156</td>
<td style="text-align: center;">0.64<span class="math inline">\(\pm\)</span><!-- -->0.37</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">2094<span class="math inline">\(\pm\)</span><!-- -->2222</td>
<td style="text-align: center;">228<span class="math inline">\(\pm\)</span><!-- -->730</td>
<td style="text-align: center;">16383<span class="math inline">\(\pm\)</span><!-- -->22993</td>
<td style="text-align: center;">0.69<span class="math inline">\(\pm\)</span><!-- -->0.41</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;"><em>2041<span class="math inline">\(\pm\)</span><!-- -->2230</em></td>
<td style="text-align: center;"><em>174<span class="math inline">\(\pm\)</span><!-- -->591</em></td>
<td style="text-align: center;">16822<span class="math inline">\(\pm\)</span><!-- -->23261</td>
<td style="text-align: center;">0.57<span class="math inline">\(\pm\)</span><!-- -->0.63</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">2096<span class="math inline">\(\pm\)</span><!-- -->2240</td>
<td style="text-align: center;">229<span class="math inline">\(\pm\)</span><!-- -->713</td>
<td style="text-align: center;">16877<span class="math inline">\(\pm\)</span><!-- -->23227</td>
<td style="text-align: center;">0.63<span class="math inline">\(\pm\)</span><!-- -->0.36</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="center">
<div id="tab:summary3">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for SAT18-EXP) for our approach and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1146<span class="math inline">\(\pm\)</span><!-- -->1945</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">9687<span class="math inline">\(\pm\)</span><!-- -->19547</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">1615<span class="math inline">\(\pm\)</span><!-- -->2138</td>
<td style="text-align: center;">468<span class="math inline">\(\pm\)</span><!-- -->1192</td>
<td style="text-align: center;">13470<span class="math inline">\(\pm\)</span><!-- -->21889</td>
<td style="text-align: center;">0.64<span class="math inline">\(\pm\)</span><!-- -->0.18</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1648<span class="math inline">\(\pm\)</span><!-- -->2151</td>
<td style="text-align: center;">502<span class="math inline">\(\pm\)</span><!-- -->1256</td>
<td style="text-align: center;">13758<span class="math inline">\(\pm\)</span><!-- -->22034</td>
<td style="text-align: center;">0.59<span class="math inline">\(\pm\)</span><!-- -->0.18</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1690<span class="math inline">\(\pm\)</span><!-- -->2170</td>
<td style="text-align: center;">543<span class="math inline">\(\pm\)</span><!-- -->1302</td>
<td style="text-align: center;">14183<span class="math inline">\(\pm\)</span><!-- -->22247</td>
<td style="text-align: center;">0.57<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">2400<span class="math inline">\(\pm\)</span><!-- -->2249</td>
<td style="text-align: center;">1254<span class="math inline">\(\pm\)</span><!-- -->1832</td>
<td style="text-align: center;">20629<span class="math inline">\(\pm\)</span><!-- -->24280</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">3S</td>
<td style="text-align: center;">1625<span class="math inline">\(\pm\)</span><!-- -->2228</td>
<td style="text-align: center;">479<span class="math inline">\(\pm\)</span><!-- -->1265</td>
<td style="text-align: center;">15010<span class="math inline">\(\pm\)</span><!-- -->22802</td>
<td style="text-align: center;">0.5<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RFJ)</td>
<td style="text-align: center;">1714<span class="math inline">\(\pm\)</span><!-- -->2292</td>
<td style="text-align: center;">571<span class="math inline">\(\pm\)</span><!-- -->1384</td>
<td style="text-align: center;">15992<span class="math inline">\(\pm\)</span><!-- -->23222</td>
<td style="text-align: center;">0.42<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RI)</td>
<td style="text-align: center;">1640<span class="math inline">\(\pm\)</span><!-- -->2266</td>
<td style="text-align: center;">497<span class="math inline">\(\pm\)</span><!-- -->1280</td>
<td style="text-align: center;">15408<span class="math inline">\(\pm\)</span><!-- -->23003</td>
<td style="text-align: center;">0.46<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Time Splitting (RJ)</td>
<td style="text-align: center;">1745<span class="math inline">\(\pm\)</span><!-- -->2308</td>
<td style="text-align: center;">602<span class="math inline">\(\pm\)</span><!-- -->1434</td>
<td style="text-align: center;">16151<span class="math inline">\(\pm\)</span><!-- -->23267</td>
<td style="text-align: center;">0.4<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RFJ)</td>
<td style="text-align: center;">1702<span class="math inline">\(\pm\)</span><!-- -->2301</td>
<td style="text-align: center;">559<span class="math inline">\(\pm\)</span><!-- -->1389</td>
<td style="text-align: center;">16235<span class="math inline">\(\pm\)</span><!-- -->23355</td>
<td style="text-align: center;">0.39<span class="math inline">\(\pm\)</span><!-- -->0.27</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;">1654<span class="math inline">\(\pm\)</span><!-- -->2285</td>
<td style="text-align: center;">511<span class="math inline">\(\pm\)</span><!-- -->1324</td>
<td style="text-align: center;">15804<span class="math inline">\(\pm\)</span><!-- -->23194</td>
<td style="text-align: center;">0.42<span class="math inline">\(\pm\)</span><!-- -->0.29</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">1678<span class="math inline">\(\pm\)</span><!-- -->2288</td>
<td style="text-align: center;">535<span class="math inline">\(\pm\)</span><!-- -->1351</td>
<td style="text-align: center;">15956<span class="math inline">\(\pm\)</span><!-- -->23243</td>
<td style="text-align: center;">0.4<span class="math inline">\(\pm\)</span><!-- -->0.3</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.81}\)</span> (RFJ)</td>
<td style="text-align: center;"><strong>1518<span class="math inline">\(\pm\)</span><!-- -->2172</strong></td>
<td style="text-align: center;"><strong>372<span class="math inline">\(\pm\)</span><!-- -->1124</strong></td>
<td style="text-align: center;"><strong>13884<span class="math inline">\(\pm\)</span><!-- -->22265</strong></td>
<td style="text-align: center;"><strong>0.62<span class="math inline">\(\pm\)</span><!-- -->0.22</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.55}\)</span> (RI)</td>
<td style="text-align: center;">1541<span class="math inline">\(\pm\)</span><!-- -->2191</td>
<td style="text-align: center;">397<span class="math inline">\(\pm\)</span><!-- -->1177</td>
<td style="text-align: center;">14034<span class="math inline">\(\pm\)</span><!-- -->22332</td>
<td style="text-align: center;"><em>0.6<span class="math inline">\(\pm\)</span><!-- -->0.21</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.58}\)</span> (RJ)</td>
<td style="text-align: center;">1622<span class="math inline">\(\pm\)</span><!-- -->2237</td>
<td style="text-align: center;">477<span class="math inline">\(\pm\)</span><!-- -->1268</td>
<td style="text-align: center;">15008<span class="math inline">\(\pm\)</span><!-- -->22805</td>
<td style="text-align: center;">0.5<span class="math inline">\(\pm\)</span><!-- -->0.25</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;"><em>1532<span class="math inline">\(\pm\)</span><!-- -->2178</em></td>
<td style="text-align: center;"><em>386<span class="math inline">\(\pm\)</span><!-- -->1146</em></td>
<td style="text-align: center;"><em>14025<span class="math inline">\(\pm\)</span><!-- -->22336</em></td>
<td style="text-align: center;"><em>0.6<span class="math inline">\(\pm\)</span><!-- -->0.23</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">1555<span class="math inline">\(\pm\)</span><!-- -->2221</td>
<td style="text-align: center;">410<span class="math inline">\(\pm\)</span><!-- -->1191</td>
<td style="text-align: center;">14558<span class="math inline">\(\pm\)</span><!-- -->22628</td>
<td style="text-align: center;">0.57<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">1649<span class="math inline">\(\pm\)</span><!-- -->2265</td>
<td style="text-align: center;">505<span class="math inline">\(\pm\)</span><!-- -->1319</td>
<td style="text-align: center;">15544<span class="math inline">\(\pm\)</span><!-- -->23064</td>
<td style="text-align: center;">0.46<span class="math inline">\(\pm\)</span><!-- -->0.26</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="number-of-selected-solvers" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="number-of-selected-solvers"><span class="header-section-number">5.5.3</span> Number of Selected Solvers</h3>
<p>As mentioned above, allowing our approach to use up to a certain number of processors does not mean that this exact number of parallel runs will be done. In practice, it is often much lower than that, as we see when comparing the performance of our approach to <span class="math inline">\(AS_0\)</span>, which runs the top <span class="math inline">\(n\)</span> predicted solvers in parallel. Figure&nbsp;<a href="#fig:x_Scenario_y_Solver" data-reference-type="ref" data-reference="fig:x_Scenario_y_Solver">1.4</a> shows the distribution of the number of selected solvers for each scenario and each algorithm selector. For RFJ, the mean number of solvers chosen for IPC2018 is around 6.5, for MAXSAT19-UCMS around 6 (out of 7), for SAT11-INDU around 9, for SAT16-MAIN around 10, and for SAT18-EXP around 5.5. For RI, the mean number of solvers chosen for IPC2018 is around 4.5, for MAXSAT19-UCMS around 7 (out of 7), for SAT11-INDU around 9.5, for SAT16-MAIN around 10, and for SAT18-EXP around 6.5. Similarly, for RJ, the mean number of solvers chosen for IPC2018 is around 6, for MAXSAT19-UCMS around 6 (out of 7), for SAT11-INDU around 8, for SAT16-MAIN around 8, and for SAT18-EXP around 6.</p>
<p>For RFJ, we see that the largest difference to the maximum number of parallel runs occurs for the two scenarios where we observe the largest performance improvements of our approach, IPC2018 and SAT18-EXP. Similarly, the scenario with the highest number of solvers chosen on average (SAT16-MAIN) is where we see the smallest performance improvement. For RI and RJ the same comparison also exists. This clearly shows again that the advantage of our approach is that it does not simply use as many parallel processors as are available, which increases overhead, but intelligently chooses how many of the available processors to use for best performance. In at least some cases, more is less, and we show how to leverage this.</p>
<p>Figure&nbsp;<a href="#fig:x_Scenario_y_Solver" data-reference-type="ref" data-reference="fig:x_Scenario_y_Solver">1.4</a> also shows that our approach uses the full range of available parallel runs in most cases, from running only a single solver to as many parallel runs as there are processors. Our approach is not simply a one-size-fits all that usually uses a similar number of runs, but varies the size of the selected parallel portfolio dynamically, based on the instance to be solved.</p>
</section>
<section id="ranger-vs-randomforest-results" class="level3" data-number="5.5.4">
<h3 data-number="5.5.4" class="anchored" data-anchor-id="ranger-vs-randomforest-results"><span class="header-section-number">5.5.4</span> Ranger vs RandomForest Results</h3>
<p>Figure&nbsp;<a href="#fig:rangervsrf" data-reference-type="ref" data-reference="fig:rangervsrf">1.5</a> presents a comparison between the random forest implementation and the ranger implementations. When comparing the naive algorithm selection methods <span class="math inline">\(AS (RFJ)\)</span>, <span class="math inline">\(AS (RJ)\)</span> and <span class="math inline">\(AS (RI)\)</span>, which select the best predicted algorithm, based on Tables&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a>,&nbsp;<a href="#tab:summary2" data-reference-type="ref" data-reference="tab:summary2">1.4</a> and&nbsp;<a href="#tab:summary3" data-reference-type="ref" data-reference="tab:summary3">1.5</a>, the RFJ model emerges as a more promising algorithm selector in all scenarios except IPC2018, where the RJ model performs slightly better in terms of runtime and MCP. For SAT11-INDU, the <span class="math inline">\(AS (RFJ)\)</span> method is superior in terms of runtime and MCP, but performs slightly worse than the RI model in terms of PAR10.</p>
<p>When we compare <span class="math inline">\(AS_{0} (RFJ)\)</span>, <span class="math inline">\(AS_{0} (RJ)\)</span>, and <span class="math inline">\(AS_{0} (RI)\)</span>, which select the top predicted algorithms to run in parallel, the performance of these methods is very competitive. In some cases, the RI model performs better, such as in SAT18-EXP and SAT11-INDU, across all metrics, and is superior only in terms of runtime and MCP in SAT16-MAIN. In other cases, the RFJ model performs better, as seen in IPC2018. For MAXSAT19-UCMS, all algorithm selectors perform equally, as with <span class="math inline">\(p_{\cap} = 0\)</span>, all 7 available solvers are selected.</p>
<p>When comparing the methods using a tuned value of <span class="math inline">\(p_{\cap}\)</span>, denoted as <span class="math inline">\(AS_{p_{\cap}}\)</span>, the RI model outperformed the others in most cases. In IPC2018 and SAT11-INDU, it was superior in terms of runtime, MCP, and PAR10. For SAT16-MAIN, it outperformed the other two in terms of MCP and runtime, although the PAR10 of RFJ was slightly better. For MAXSAT19-UCMS and SAT18-EXP, the RFJ model performed better than the others across all performance metrics. It is worth mentioning that the RJ model could not beat other models in the <span class="math inline">\(AS_{p_{\cap}}\)</span> method.</p>
<p>These comparisons is based on the runtime, MCP, and PAR10 scores listed in Tables&nbsp;<a href="#tab:summary" data-reference-type="ref" data-reference="tab:summary">1.3</a>, <a href="#tab:summary2" data-reference-type="ref" data-reference="tab:summary2">1.4</a>, and <a href="#tab:summary3" data-reference-type="ref" data-reference="tab:summary3">1.5</a>. As shown in Figure&nbsp;<a href="#fig:rangervsrf" data-reference-type="ref" data-reference="fig:rangervsrf">1.5</a>, a similar comparison exists, with the values representing the PAR10 score normalized gap closed between SBS and VBS. In this context, <span class="math inline">\(AS_{p_{\cap}} (RI)\)</span> is superior in three out of five scenarios, while <span class="math inline">\(AS_{p_{\cap}} (RFJ)\)</span> performs best in the remaining two scenarios. Although using RI for single algorithm selection performed the worst, it appears to be a better model for applying the portfolio selection approach.</p>
<figure id="fig:rangervsrf" class="figure">
<embed src="plots/learner_comparison_line_chart_parallel_NormalizedGap.svg" style="width:95.0%">
<figcaption>
Results Overview. The plot illustrates the extent to which each method narrows the gap between the PAR10 scores of the Single Best Solver (SBS) and the Virtual Best Solver (VBS). For VBS and SBS, the top <span class="math inline">(n)</span> solvers are selected, where <span class="math inline">(n)</span> matches the number of processors available for each problem instance and across all instances, respectively. <span class="math inline">(AS_0)</span> selects the top <span class="math inline">(n)</span> solvers as predicted by algorithm selection, disregarding any overlap in their predicted runtime distributions. <span class="math inline">(AS_{p_{}})</span> follows the approach proposed in <span class="citation" data-cites="kashgarani2023automatic"></span>, with the number of processors capped at the specific value on the x-axis — fewer solvers than this maximum may be selected based on the overlap in runtime predictions. The RFJ model is trained with the randomForest and Jackknife method, RI uses the Ranger model with the Infinitesimal Jackknife method, and RJ applies the Ranger model with the Jackknife method. The optimal <span class="math inline">(p_{})</span> values for each scenario and each model are listed in Table&nbsp;<a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">1.2</a>.
</figcaption>
</figure>
</section>
</section>
<section id="conclusions-and-future-work" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="conclusions-and-future-work"><span class="header-section-number">5.6</span> Conclusions and Future Work</h2>
<p>In this study, we proposed a general method for selecting solvers from a portfolio of solvers and scheduling them in parallel, taking into account the predicted runtime distribution to intelligently choose not only which solvers to run, but also how many. This is in contrast to most other approaches in the literature, which either choose a constant number or use all available processors. Further, we measured the actual runtime when running more than one algorithm in parallel, rather than assuming the sequential runtime. We demonstrated substantial performance improvements across a wide range of scenarios, handily beating baseline methods and other approaches from the literature. The proposed method establishes a new state of the art in parallel algorithm selection and is simple to apply in practice – we are only using information that is readily available in common algorithm selection methods, and while for the best performance the parameter <span class="math inline">\(p_{\cap}\)</span> of our method should be tuned, a reasonable default already shows good performance. This parameter allows our method to be tailored to specific application domains and scenarios. We also compared three different algorithm performance models, specifically three variations of the regression random forest, and applied the method to evaluate their effectiveness.</p>
<p>While we do show substantial performance improvements, there is room for further advances. We have focused our investigation on state-of-the-art random forest performance models, the jackknife and infinitesimal jackknife method for estimating uncertainties. It is possible that other types of models may perform better in this context if the uncertainty estimates of their predictions are better. It is also possible to combine different types of performance models for different algorithms, allowing much more flexibility and potentially greater performance improvements. While our baseline method that allocates resources to each algorithm did not perform well, investigating more sophisticated approaches for this would also be interesting.</p>
<p>Furthermore, the optimal values of <span class="math inline">\(p_{\cap}\)</span> varied significantly between different scenarios and performance models, requiring tuning for each. This can increase the complexity of the algorithm selection process, as well as the computational effort and time required for method configuration, since each scenario needs specific adjustments to achieve optimal performance.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-biere" class="csl-entry" role="listitem">
Aigner, Martin, Armin Biere, Christoph M Kirsch, Aina Niemetz, and Mathias Preiner. 2013. <span>“<span class="nocase">Analysis of Portfolio-Style Parallel SAT Solving on Current Multi-Core Architectures</span>.”</span> <em>POS@ SAT</em> 29: 28–40.
</div>
<div id="ref-sunny" class="csl-entry" role="listitem">
Amadini, Roberto, Maurizio Gabbrielli, and Jacopo Mauro. 2014. <span>“<span>SUNNY:</span> A Lazy Portfolio Approach for Constraint Solving.”</span> <em>Theory Pract. Log. Program.</em> 14 (4-5): 509–24. <a href="https://doi.org/10.1017/S1471068414000179">https://doi.org/10.1017/S1471068414000179</a>.
</div>
<div id="ref-sunnycp2" class="csl-entry" role="listitem">
———. 2015. <span>“<span class="nocase">A Multicore Tool for Constraint Solving</span>.”</span> In <em>Proceedings of the 24th International Conference on Artificial Intelligence</em>, 232–38.
</div>
<div id="ref-BISCHL201641" class="csl-entry" role="listitem">
Bischl, Bernd, Pascal Kerschke, Lars Kotthoff, Marius Lindauer, Yuri Malitsky, Alexandre Fréchette, Holger Hoos, et al. 2016. <span>“<span>ASlib</span>: A Benchmark Library for Algorithm Selection.”</span> <em>Artificial Intelligence</em> 237: 41–58.
</div>
<div id="ref-mlr" class="csl-entry" role="listitem">
Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2016. <span>“<span class="nocase">mlr: Machine Learning in R</span>.”</span> <em>Journal of Machine Learning Research</em> 17 (170): 1–5. <a href="https://jmlr.org/papers/v17/15-066.html">https://jmlr.org/papers/v17/15-066.html</a>.
</div>
<div id="ref-Bischl2024" class="csl-entry" role="listitem">
Bischl, Bernd, Raphael Sonabend, Lars Kotthoff, and Michel Lang, eds. 2024. <em><span class="nocase">Applied Machine Learning Using <span class="nocase">m</span>lr3 in <span>R</span></span></em>. CRC Press. <a href="https://mlr3book.mlr-org.com">https://mlr3book.mlr-org.com</a>.
</div>
<div id="ref-randomforest" class="csl-entry" role="listitem">
Breiman, Leo. 2001. <span>“Random Forests.”</span> <em>Machine Learning</em> 45: 5–32.
</div>
<div id="ref-Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014" class="csl-entry" role="listitem">
Fawcett, Chris, Mauro Vallati, Frank Hutter, Jörg Hoffmann, Holger Hoos, and Kevin Leyton-Brown. 2014. <span>“<span class="nocase">Improved Features for Runtime Prediction of Domain-Independent Planners</span>.”</span> <em>Proceedings of the International Conference on Automated Planning and Scheduling</em> 24 (1): 355–59. <a href="https://doi.org/10.1609/icaps.v24i1.13680">https://doi.org/10.1609/icaps.v24i1.13680</a>.
</div>
<div id="ref-GOMES200143" class="csl-entry" role="listitem">
Gomes, Carla, and Bart Selman. 2001. <span>“Algorithm Portfolios.”</span> <em>Artificial Intelligence</em> 126: 43–62.
</div>
<div id="ref-aspeed" class="csl-entry" role="listitem">
Hoos, Holger H., Roland Kaminski, Marius Thomas Lindauer, and Torsten Schaub. 2015. <span>“<span class="nocase">aspeed: Solver scheduling via answer set programming</span>.”</span> <em><span>TPLP</span></em> 15 (1): 117–42.
</div>
<div id="ref-HU201268" class="csl-entry" role="listitem">
Hu, Mengqi, Teresa Wu, and Jeffery D. Weir. 2012. <span>“An Intelligent Augmentation of Particle Swarm Optimization with Multiple Adaptive Methods.”</span> <em>Information Sciences</em> 213: 68–83. https://doi.org/<a href="https://doi.org/10.1016/j.ins.2012.05.020">https://doi.org/10.1016/j.ins.2012.05.020</a>.
</div>
<div id="ref-Huberman1997" class="csl-entry" role="listitem">
Huberman, Bernardo A., Rajan M. Lukose, and Tad Hogg. 1997. <span>“<span class="nocase">An economics approach to hard computational problems</span>.”</span> <em>Science</em> 275 (5296): 51–54. <a href="https://doi.org/10.1126/science.275.5296.51">https://doi.org/10.1126/science.275.5296.51</a>.
</div>
<div id="ref-HUTTER201479" class="csl-entry" role="listitem">
Hutter, Frank, Lin Xu, Holger H. Hoos, and Kevin Leyton-Brown. 2014. <span>“Algorithm Runtime Prediction: Methods &amp; Evaluation.”</span> <em>Artificial Intelligence</em> 206: 79–111. https://doi.org/<a href="https://doi.org/10.1016/j.artint.2013.10.003">https://doi.org/10.1016/j.artint.2013.10.003</a>.
</div>
<div id="ref-3s" class="csl-entry" role="listitem">
Kadioglu, Serdar, Yuri Malitsky, Ashish Sabharwal, Horst Samulowitz, and Meinolf Sellmann. 2011. <span>“<span class="nocase">Algorithm selection and scheduling</span>.”</span> <em>Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em> 6876 LNCS: 454–69. <a href="https://doi.org/10.1007/978-3-642-23786-7_35">https://doi.org/10.1007/978-3-642-23786-7_35</a>.
</div>
<div id="ref-pmlr-v140-kashgarani21a" class="csl-entry" role="listitem">
Kashgarani, Haniye, and Lars Kotthoff. 2021. <span>“<span class="nocase">Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution</span>.”</span> In <em>AAAI Workshop on Meta-Learning and MetaDL Challenge</em>, 140:58–64. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v140/kashgarani21a.html">https://proceedings.mlr.press/v140/kashgarani21a.html</a>.
</div>
<div id="ref-kashgarani2023automatic" class="csl-entry" role="listitem">
———. 2023. <span>“<span>Automatic Parallel Portfolio Selection</span>.”</span> In <em>ECAI 2023</em>, 1215–22. IOS Press.
</div>
<div id="ref-10.1162/evco_a_00242" class="csl-entry" role="listitem">
Kerschke, Pascal, Holger H. Hoos, Frank Neumann, and Heike Trautmann. 2019. <span>“<span class="nocase">Automated Algorithm Selection: Survey and Perspectives</span>.”</span> <em>Evolutionary Computation</em> 27 (1): 3–45. <a href="https://doi.org/10.1162/evco_a_00242">https://doi.org/10.1162/evco_a_00242</a>.
</div>
<div id="ref-10.1162/evco_a_00215" class="csl-entry" role="listitem">
Kerschke, Pascal, Lars Kotthoff, Jakob Bossek, Holger H. Hoos, and Heike Trautmann. 2018. <span>“<span class="nocase">Leveraging TSP Solver Complementarity through Machine Learning</span>.”</span> <em>Evolutionary Computation</em> 26 (4): 597–620. <a href="https://doi.org/10.1162/evco_a_00215">https://doi.org/10.1162/evco_a_00215</a>.
</div>
<div id="ref-LLAMA" class="csl-entry" role="listitem">
Kotthoff, Lars. 2013. <span>“<span class="nocase">LLAMA: Leveraging Learning to Automatically Manage Algorithms</span>.”</span> <em>CoRR</em> abs/1306.1031. <a href="http://arxiv.org/abs/1306.1031">http://arxiv.org/abs/1306.1031</a>.
</div>
<div id="ref-Kotthoff2014" class="csl-entry" role="listitem">
———. 2014. <span>“<span class="nocase">Algorithm selection for combinatorial search problems: A survey</span>.”</span> <em>AI Magazine</em> 35 (3): 48–69.
</div>
<div id="ref-flexfolio" class="csl-entry" role="listitem">
Lindauer, Marius, Rolf-David Bergdoll, and Frank Hutter. 2016. <span>“An Empirical Study of Per-Instance Algorithm Scheduling.”</span> In <em>Proceedings of the Tenth International Conference on Learning and Intelligent Optimization, LION’16, in: Lecture Notes in Computer Science</em>, 253–59. Springer; Springer.
</div>
<div id="ref-lindauer2015autofolio" class="csl-entry" role="listitem">
Lindauer, Marius, Holger H Hoos, Frank Hutter, and Torsten Schaub. 2015. <span>“Autofolio: An Automatically Configured Algorithm Selector.”</span> <em>Journal of Artificial Intelligence Research</em> 53: 745–78.
</div>
<div id="ref-Marius2015" class="csl-entry" role="listitem">
Lindauer, Marius, Holger Hoos, and Frank Hutter. 2015. <span>“<span class="nocase">From sequential algorithm selection to parallel portfolio selection</span>.”</span> In <em>International Conference on Learning and Intelligent Optimization</em>, 1–16. Springer.
</div>
<div id="ref-LINDAUER2017272" class="csl-entry" role="listitem">
Lindauer, Marius, Holger Hoos, Kevin Leyton-Brown, and Torsten Schaub. 2017. <span>“Automatic Construction of Parallel Portfolios via Algorithm Configuration.”</span> <em>Artificial Intelligence</em> 244: 272–90. https://doi.org/<a href="https://doi.org/10.1016/j.artint.2016.05.004">https://doi.org/10.1016/j.artint.2016.05.004</a>.
</div>
<div id="ref-pmlr-v79-lindauer17a" class="csl-entry" role="listitem">
Lindauer, Marius, Jan N. van Rijn, and Lars Kotthoff. 2017. <span>“Open Algorithm Selection Challenge 2017: Setup and Scenarios.”</span> In <em>Proceedings of the Open Algorithm Selection Challenge</em>, 79:1–7. PMLR. <a href="https://proceedings.mlr.press/v79/lindauer17a.html">https://proceedings.mlr.press/v79/lindauer17a.html</a>.
</div>
<div id="ref-p3s" class="csl-entry" role="listitem">
Malitsky, Yuri, Ashish Sabharwal, Horst Samulowitz, and Meinolf Sellmann. 2012. <span>“<span class="nocase">Parallel SAT Solver Selection and Scheduling</span>.”</span> In <em>Proceedings of the 18th International Conference on Principles and Practice of Constraint Programming - Volume 7514</em>, 512–26. Springer-Verlag.
</div>
<div id="ref-maratea2014multi" class="csl-entry" role="listitem">
Maratea, Marco, Luca Pulina, and Francesco Ricca. 2014. <span>“A Multi-Engine Approach to Answer-Set Programming.”</span> <em>Theory and Practice of Logic Programming</em> 14 (6): 841–68.
</div>
<div id="ref-Maturana2012" class="csl-entry" role="listitem">
Maturana, Jorge, Álvaro Fialho, Frédéric Saubion, Marc Schoenauer, Frédéric Lardeux, and Michèle Sebag. 2012. <span>“Adaptive Operator Selection and Management in Evolutionary Algorithms.”</span> In <em>Autonomous Search</em>, 161–89. Springer. <a href="https://doi.org/10.1007/978-3-642-21434-9_7">https://doi.org/10.1007/978-3-642-21434-9_7</a>.
</div>
<div id="ref-cphydra" class="csl-entry" role="listitem">
O’Mahony, Eoin, Emmanuel Hebrard, Alan Holland, Conor Nugent, and Barry O’Sullivan. 2008. <span>“Using Case-Based Reasoning in an Algorithm Portfolio for Constraint Solving.”</span> In <em>Irish Conference on Artificial Intelligence and Cognitive Science</em>, 210–16. Proceedings of the 19th Irish Conference on Artificial Intelligence; Cognitive Science.
</div>
<div id="ref-pmlr-v188-pulatov22a" class="csl-entry" role="listitem">
Pulatov, Damir, Marie Anastacio, Lars Kotthoff, and Holger Hoos. 2022. <span>“<span class="nocase">Opening the Black Box: Automated Software Analysis for Algorithm Selection</span>.”</span> In <em>Proceedings of the First International Conference on Automated Machine Learning</em>, 188:6/1–18. PMLR. <a href="https://proceedings.mlr.press/v188/pulatov22a.html">https://proceedings.mlr.press/v188/pulatov22a.html</a>.
</div>
<div id="ref-Rice1976" class="csl-entry" role="listitem">
Rice, John R. 1976. <span>“<span>The Algorithm Selection Problem</span>.”</span> <em>Advances in Computers</em>. <a href="https://doi.org/10.1016/S0065-2458(08)60520-3">https://doi.org/10.1016/S0065-2458(08)60520-3</a>.
</div>
<div id="ref-ppfolio" class="csl-entry" role="listitem">
Roussel, Olivier. 2012. <span>“Description of Ppfolio (2011).”</span> <em>Proc. SAT Challenge</em>, 46.
</div>
<div id="ref-jtom1286288" class="csl-entry" role="listitem">
Torağay, Oğuz, and Shaheen Pouya. 2023. <span>“<span class="nocase">A Monte Carlo simulation approach to the gap-time relationship in solving scheduling problem</span>.”</span> <em>Journal of Turkish Operations Management</em> 7 (1): 1579–90. <a href="https://doi.org/10.56554/jtom.1286288">https://doi.org/10.56554/jtom.1286288</a>.
</div>
<div id="ref-wager2014confidence" class="csl-entry" role="listitem">
Wager, Stefan, Trevor Hastie, and Bradley Efron. 2014. <span>“<span class="nocase">Confidence intervals for random forests: The jackknife and the infinitesimal jackknife</span>.”</span> <em>The Journal of Machine Learning Research</em> 15 (1): 1625–51.
</div>
<div id="ref-ranger" class="csl-entry" role="listitem">
Wright, Marvin N., and Andreas Ziegler. 2017. <span>“<span class="nocase">ranger</span>: A Fast Implementation of Random Forests for High Dimensional Data in <span>C++</span> and <span>R</span>.”</span> <em>Journal of Statistical Software</em> 77 (1): 1–17. <a href="https://doi.org/10.18637/jss.v077.i01">https://doi.org/10.18637/jss.v077.i01</a>.
</div>
<div id="ref-10.5555/2898607.2898641" class="csl-entry" role="listitem">
Xu, Lin, Holger H. Hoos, and Kevin Leyton-Brown. 2010. <span>“<span class="nocase">Hydra: Automatically Configuring Algorithms for Portfolio-Based Selection</span>.”</span> In <em>Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence</em>, 210–16. AAAI’10 1. AAAI Press.
</div>
<div id="ref-satzilla" class="csl-entry" role="listitem">
Xu, Lin, Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. 2008. <span>“<span>SATzilla</span>: Portfolio-Based Algorithm Selection for <span>SAT</span>.”</span> <em>J. Artif. Int. Res.</em> 32 (1): 565–606.
</div>
<div id="ref-XuEtAl11" class="csl-entry" role="listitem">
Xu, Lin, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. 2011. <span>“<span class="nocase">Hydra-MIP: Automated algorithm configuration and selection for mixed integer programming</span>.”</span> In <em>Proceedings of the 18th RCRA Workshop</em>, 16–30.
</div>
<div id="ref-9ae8443ad82b4056bccf7102c0056152" class="csl-entry" role="listitem">
Yuen, Shiu Yin, Chi Kin Chow, and Xin Zhang. 2013. <span>“<span class="nocase">Which algorithm should I choose at any point of the search: An evolutionary portfolio approach</span>.”</span> In <em>GECCO 2013 - Proceedings of the 2013 Genetic and Evolutionary Computation Conference</em>, 567–74. <a href="https://doi.org/10.1145/2463372.2463435">https://doi.org/10.1145/2463372.2463435</a>.
</div>
<div id="ref-yuen2019selecting" class="csl-entry" role="listitem">
Yuen, Shiu Yin, Yang Lou, and Xin Zhang. 2019. <span>“Selecting Evolutionary Algorithms for Black Box Design Optimization Problems.”</span> <em>Soft Computing</em> 23 (15): 6511–31.
</div>
<div id="ref-Yun" class="csl-entry" role="listitem">
Yun, Xi, and Susan L. Epstein. 2012. <span>“Learning Algorithm Portfolios for Parallel Execution.”</span> In <em>Revised Selected Papers of the 6th International Conference on Learning and Intelligent Optimization - Volume 7219</em>, 323–38. LION 6. Paris, France: Springer-Verlag.
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter3/IsAlgorithmSelectionWorthItComparingSelectingSingleAlgorithmsandParallelExecution.html" class="pagination-link" aria-label="Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html" class="pagination-link" aria-label="Revisiting Parallel Portfolio Selection with KL Divergence">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Revisiting Parallel Portfolio Selection with KL Divergence</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Automatic Parallel Portfolio Selection</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>A portion of this chapter has been published as: H. Kashgarani, L.</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>Kotthoff, "Automatic Parallel Portfolio Selection," in *ECAI 2023*, pp.</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>1215-1222, IOS Press, 2023.</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>This chapter introduces a hybrid formulation for dynamic algorithm</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>portfolio selection, which is instance-based and aims to mitigate the</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>risk of selecting a single algorithm or running too many solvers in</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>parallel. The published ECAI paper investigates the results for a random</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>forest regression model trained using the MLR package. Here, in addition</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>to presenting those results, we also expand upon them to explore the</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>transition of regression random forests from the MLR package to its</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>updated version, MLR3, in R.</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## Abstract</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>Algorithms to solve hard combinatorial problems often exhibit</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>complementary performance, i.e.&nbsp;where one algorithm fails, another</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>shines. Algorithm portfolios and algorithm selection take advantage of</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>this by running all algorithms in parallel or choosing the best one to</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>run on a problem instance. In this chapter, we show that neither of</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>these approaches gives the best possible performance and propose the</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>happy medium of running a subset of all algorithms in parallel. We</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>propose a method to choose this subset automatically for each problem</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>instance, and demonstrate empirical improvements of up to 23% in terms</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>of runtime, 83% in terms of misclassification penalty, and 32% in terms</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>of penalized averaged runtime on scenarios from the ASlib benchmark</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>library. Unlike all other algorithm selection and scheduling approaches</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>in the literature, our performance measures are based on the actual</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>performance for algorithms running in parallel rather than assuming</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>overhead-free parallelization based on sequential performance. Our</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>approach is easy to apply in practice and does not require to solve hard</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>problems to obtain a schedule, unlike other techniques in the</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>literature, while still delivering superior performance.</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>For many types of hard combinatorial problems, different algorithms that</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>exhibit complementary performance are available. In these cases, a</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>portfolio of algorithms often achieves better performance than a single</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>one <span class="co">[</span><span class="ot">@Huberman1997; @GOMES200143</span><span class="co">]</span>. The algorithms can be run in</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>parallel, or a single one selected for each problem instance to solve.</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>The so-called Algorithm Selection Problem <span class="co">[</span><span class="ot">@Rice1976</span><span class="co">]</span> is often solved</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>using machine learning models which, given characteristics of the</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>problem instance to solve, decide which algorithm should be chosen</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@Kotthoff2014; @10.1162/evco_a_00242</span><span class="co">]</span>. The machine learning models</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>built for per-instance algorithm selection are not perfect, like most</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>models. In some cases, they lead to choosing an algorithm that does not</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>provide the best overall performance, resulting in wasted resources.</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>Running all algorithms in parallel avoids this issue, but again wastes</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>resources. Even if the user is only interested in optimizing the elapsed</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>time, i.e.&nbsp;it does not matter how many things are run in parallel,</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>results are sub-optimal as parallel executions compete for shared</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>resources such as caches. With more solvers running in parallel, more</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>runs time out, which results in a large overhead. Even for a relatively</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>small number of parallel runs, this overhead becomes prohibitive,</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>resulting in overall performance worse than using imperfect machine</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>learning models to choose a single algorithm <span class="co">[</span><span class="ot">@pmlr-v140-kashgarani21a</span><span class="co">]</span>.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>In this chapter, we propose a middle path -- select the most promising</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>subset of algorithms to be run in parallel on a single non-distributed</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>computing machine. This mitigates the impact of both imperfect machine</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>learning models and overhead from parallel runs. We formalize the</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>problem of choosing a subset of algorithms from a portfolio, unifying</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>approaches from the literature. We propose a solution to this problem</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>based on the predictions of algorithm performance models and their</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>uncertainties and compare empirically to other approaches from the</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>literature. We trained three algorithm selection performance models and</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>applied the proposed formulation and could demonstrate improvements of</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>up to 83% in terms of misclassification penalty, establishing a new</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>state of the art in per-instance algorithm selection with multiple</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>algorithms. We assume that the algorithms to run are not parallelized</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>themselves, i.e.&nbsp;each algorithm consumes the same computational</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>resources, and we run on a single machine. We do not consider the case</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>of running algorithms in a distributed setting on multiple machines.</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### Algorithm Selection</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>The performance of algorithms designed to solve NP-complete problems,</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>such as Boolean Satisfiability and the Traveling Salesman Problem, can</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>vary significantly depending on the specific problem being addressed.</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>There is no one algorithm that performs optimally in all circumstances.</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>However, we can take advantage of these performance disparities by</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>creating algorithm portfolios that incorporate the complementing</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>strengths of several algorithms <span class="co">[</span><span class="ot">@GOMES200143; @Huberman1997</span><span class="co">]</span>.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>The algorithm portfolios proposed in <span class="co">[</span><span class="ot">@GOMES200143; @Huberman1997</span><span class="co">]</span> run</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>multiple algorithms in parallel, however, they do not measure the actual</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>execution time when running in parallel but simulate parallel execution</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>based on sequential performance. <span class="co">[</span><span class="ot">@pmlr-v140-kashgarani21a</span><span class="co">]</span> found that</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>the performance of the portfolio can deteriorate substantially when</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>algorithms are executed in parallel, in particular for more than 10</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>algorithms. <span class="co">[</span><span class="ot">@LINDAUER2017272</span><span class="co">]</span> has also determined that running various</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>configurations of an algorithm in parallel can introduce overhead, and</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>this factor should be considered when designing portfolios.</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>Alternatively, we can choose a subset of the best algorithms from the</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>portfolio for a given problem instance to avoid the overhead of running</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>a large number of solvers in parallel. In the case where we choose only</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>a single algorithm, this is known as the algorithm selection</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>problem&nbsp;<span class="co">[</span><span class="ot">@Rice1976</span><span class="co">]</span>. Typically, this is accomplished through the use of</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>machine learning techniques and features derived from the</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>instances&nbsp;<span class="co">[</span><span class="ot">@Kotthoff2014; @10.1162/evco_a_00242</span><span class="co">]</span> and</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>algorithms&nbsp;<span class="co">[</span><span class="ot">@pmlr-v188-pulatov22a</span><span class="co">]</span>. However, choosing only a single</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>algorithm to run often achieves suboptimal performance because of</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>incorrect choices. This can be addressed through better algorithm</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>selection models; in this chapter, we explore the alternative of</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>choosing more than one algorithm to run in parallel on a single node.</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>Algorithm selection has been applied successfully in many problem</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>domains. Some of the most prominent systems are SATzilla, Hydra, and</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>Autofolio</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>&nbsp;<span class="co">[</span><span class="ot">@satzilla; @lindauer2015autofolio; @10.5555/2898607.2898641</span><span class="co">]</span>. While</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>these systems focus on SAT, algorithm selection also has been used in</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>the constraint programming and mixed integer programming domains, where</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>it has been shown to achieve good performance <span class="co">[</span><span class="ot">@cphydra; @XuEtAl11</span><span class="co">]</span>.</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>AutoFolio has been applied in additional areas, e.g.&nbsp;ASP, MAXSAT, and</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>QBF. <span class="co">[</span><span class="ot">@10.1162/evco_a_00215</span><span class="co">]</span> apply algorithm selection for the TSP, and</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>ME-ASP <span class="co">[</span><span class="ot">@maratea2014multi</span><span class="co">]</span> apply algorithm selection for answer set</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>programming to create a multi-engine solver. Algorithm selection has</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>also been used to choose between evolutionary algorithms</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@HU201268; @yuen2019selecting; @Maturana2012; @9ae8443ad82b4056bccf7102c0056152</span><span class="co">]</span>.</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>The ASlib benchmarking library&nbsp;<span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span> collects benchmarks from</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>many different problem domains and is the de facto standard library for</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>evaluating algorithm selection approaches.</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>**Notation.** We follow&nbsp;<span class="co">[</span><span class="ot">@pmlr-v79-lindauer17a</span><span class="co">]</span> in the notation we use</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>in this chapter. Given a portfolio of algorithms (solvers) $S$, a set of</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>instances $I$, and a performance metric</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>$ m: S \times I \to \mathbb {R^+} $, we aim to find a mapping</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>$ s: I \to S $ from instances $I$ to algorithms $S$ such that the</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>performance across all instances is optimized. This performance metric</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>can be for example the time needed to solve the instance and we assume</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>w.l.o.g.&nbsp;that the performance metric should be minimized. In practice,</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>we estimate the value of the performance metric based on the predictions</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>of machine learning models for new problem instances; we denote this</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>estimate $\hat{m}$. We want to select the solver with the best-predicted</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>performance for each instance:</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>$$\label{eq:1}</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>    min \frac{1}{|I|} \sum\limits_{i\in I} \hat{m}(s(i),i)$$</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="fu">### Portfolio Scheduling</span></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>Different approaches have been proposed for sub-portfolio selection.</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>Some approaches choose a number of suitable solvers for sequential</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>execution and assign time slices that sum to the total available time to</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>each algorithm. Others have implemented parallel execution of the</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>selected solvers, while a few have combined these two methods, utilizing</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>parallelization across computing processors and splitting the available</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>time of each processor across different algorithms.</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Time slice allocation on single processor</span></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>Typically, sub-portfolio selection strategies are built for sequential</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>solver runs, e.g.&nbsp;Sunny&nbsp;<span class="co">[</span><span class="ot">@sunny</span><span class="co">]</span> creates a sub-portfolio of solvers</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>using k-nearest neighbor (kNN) models and builds a sequential schedule</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>for the selected solvers by allocating time slices based on the</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>predicted performance. CPHydra&nbsp;<span class="co">[</span><span class="ot">@cphydra</span><span class="co">]</span> also employs case-based</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>reasoning and allocates time slices for the selected CSP solvers to run</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>sequentially. 3S&nbsp;<span class="co">[</span><span class="ot">@3s</span><span class="co">]</span> dynamically selects and sequentially schedules</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>solvers for a given SAT instance using integer programming.</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>ASPEED&nbsp;<span class="co">[</span><span class="ot">@aspeed</span><span class="co">]</span> creates static sequential schedules through answer set</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>programming that optimizes a static sequential time budget allocation</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>for solvers. Depending on the number of algorithms, solving the</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>scheduling problem can take substantial time. Building on the</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>methodologies of 3S&nbsp;<span class="co">[</span><span class="ot">@3s</span><span class="co">]</span> and ASPEED&nbsp;<span class="co">[</span><span class="ot">@aspeed</span><span class="co">]</span>, ISA (Instance-Specific</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>ASPEED)&nbsp;<span class="co">[</span><span class="ot">@flexfolio</span><span class="co">]</span> uses kNN to identify the closest training problem</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>instances to a given problem instance to solve. It then employs ASPEED</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>to determine a schedule that minimizes the number of timeouts across</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>these instances. <span class="co">[</span><span class="ot">@flexfolio</span><span class="co">]</span> also introduced TSunny which is a modified</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>version of Sunny that limits the number of solvers to run, thus</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>increasing the chance of success by allocating larger time slices to</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>each algorithm.</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Time slice allocation on multiple processors</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>Other portfolio techniques have focused on scheduling solvers to run in</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>parallel and allocating time slots on different processors. P3S&nbsp;<span class="co">[</span><span class="ot">@p3s</span><span class="co">]</span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>is a parallel version of 3S and uses the kNN algorithm for selecting</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>solvers and scheduling them using integer programming with a specific</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>runtime allocation strategy, where it runs a static set of solvers for</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>the first 10% of the available runtime and solvers selected for the</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>instance for the remaining 90%. ASPEED&nbsp;<span class="co">[</span><span class="ot">@aspeed</span><span class="co">]</span> can also define a fixed</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>schedule for running solvers on multiple processors, which is chosen</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>based on the average solver performance across a set of instances.</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>Flexfolio <span class="co">[</span><span class="ot">@flexfolio</span><span class="co">]</span> incorporates a reimplementation of the P3S</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>approach utilizing the same 10-90 strategy. However, rather than</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>employing integer programming to address the scheduling problem,</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>Flexfolio makes use of ASPEED and solves it through answer set</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>programming. Sunny-cp&nbsp;<span class="co">[</span><span class="ot">@sunnycp2</span><span class="co">]</span> can simultaneously execute multiple</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>CSP and COP solvers. First, a portion of the total available time is</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>allocated to a pre-solving phase that follows a fixed schedule. The</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>remaining time is then distributed amongst the other selected solvers</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>dynamically, based on the predictions of kNN performance models. As</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>there are often more solvers than processors, all processors except one</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>are assigned to the corresponding number of top-ranked solvers, while</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>the time on the final processors is split among the remaining solvers.</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Running algorithms in parallel</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>One of the first parallel SAT solvers is ppfolio&nbsp;<span class="co">[</span><span class="ot">@ppfolio</span><span class="co">]</span>. It selects</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>solver portfolios to solve sets of problem instances optimally, but does</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>this only for entire sets of instances, not on a per-instance basis as</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>we do here. The success of ppfolio has inspired many other researchers</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>to create sub-portfolios of solvers to run in parallel. For example,</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@Marius2015</span><span class="co">]</span> extended existing algorithm selectors like 3S, SATzilla,</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>and ME-ASP to greedily choose the top $n$ solvers to run in parallel by</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>producing a ranking of candidate algorithms; however, the number of</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>solvers has to be specified by the user and the actual runtime of</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>parallel runs is not considered -- the same runtime as for sequential</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>execution is assumed. Running algorithms in parallel on the same machine</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>is slower than running sequentially in practice due to the overhead</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>incurred because of shared caches and shared memory. This has been shown</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>in experiments&nbsp;<span class="co">[</span><span class="ot">@pmlr-v140-kashgarani21a</span><span class="co">]</span>,</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>simulations&nbsp;<span class="co">[</span><span class="ot">@Yun; @jtom1286288</span><span class="co">]</span>, and analyses&nbsp;<span class="co">[</span><span class="ot">@biere</span><span class="co">]</span> for the parallel</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>executions of solvers -- in practice, ignoring the overhead that</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>parallel execution introduces reduces overall performance.</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>In this chapter, we consider the problem of selecting the optimal subset</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>of algorithms to run in parallel on a single machine. This is</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>computationally much easier to solve on a per-instance basis than more</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>complex scheduling approaches, e.g.&nbsp;the ones used by ASPEED and 3S,</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>which means that our method is easier to deploy and introduces less</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>overhead. As long as the best solver is part of the selected portfolio,</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>we will achieve optimal performance or close to it, whereas approaches</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>that allocate time slices may choose the best solver, but fail to</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>achieve optimal performance if too little time is allocated to it. We</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>leverage more information from algorithm selection models than most</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>approaches in the literature, in particular the uncertainty of</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>performance prediction. This allows us to trade off the number of</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>algorithms to choose with the chance of success in a principled way. Our</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>approach is designed to optimize the usage of parallel computational</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>resources when solving combinatorial problems while taking into account</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>the overhead that arises from parallel runs. To the best of our</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>knowledge, there are no other approaches that solve parallel algorithm</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>selection this way.</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="fu">## Parallel Portfolio Selection</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>We aim to choose a sub-portfolio of solvers $ P_i \subseteq S $ for a</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>given instance $i \in I$ that includes the algorithms with the best</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>performance on $i$ ($ A \in S $ and $ A \in P_i $) to run in parallel,</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>based on the predicted performance of each solver. Given the predicted</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>performance metric $\hat{m}$, we can define a total order of the</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>algorithms in the portfolio $S$ for a given instance $i$. This total</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>order is induced by the ranking of the algorithms based on their</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>predicted performance for instance $i$. Formally, the total order can be</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>defined as: $$\label{eq:3}</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>A &lt; B \quad \text{if} \quad \hat{m}(A,i) &lt; \hat{m}(B,i); A,B \in S$$</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>Given the total order, the rank of each algorithm $A$ on each instance</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>$i$ can be defined as the number of algorithms that are predicted to be</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>strictly better than $A$ for the instance and denoted $r_{A,i}$. Ties</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>are broken arbitrarily. A portfolio of a specified size $n$ is then</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>defined as the top $n$ algorithms according to rank for that particular</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>instance. The portfolio of size $n$ for instance $i$ can be expressed</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>mathematically as: $$\label{eq:4}</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>P_i = <span class="sc">\{</span>A \in S \: | \: r_{A,i} \leq n<span class="sc">\}</span>$$</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>In a slight abuse of notation, we will denote the rank of an algorithm</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>as a subscript, i.e.&nbsp;$r_{A,i}$ is the rank of algorithm $A$ on instance</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>$i$ and $A_{1,i}$ is the algorithm of rank $1$ (the best performing</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>algorithm) on instance $i$.</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>This allows to choose a subset of algorithms with the best predicted</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>performance for a given instance, which can then be executed in</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>parallel. However, determining the portfolio size $n$ for a given</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>problem instance is the key challenge for parallel portfolios. As</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>discussed above, choosing only a single algorithm or all algorithms is</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>unlikely to give optimal performance in practice. The larger the number</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>of algorithms we include, the larger the chance that the best algorithm</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>is in the chosen portfolio, but also the larger the overhead from</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>running many algorithms in parallel.</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>Here, we want to include the algorithms that, according to their</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>predicted performance on a new problem instance, have the highest</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>chances of achieving optimal performance, while also taking into account</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>the computational overhead of running multiple solvers in parallel. We</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>leverage the uncertainty of the predictions of the performance models to</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>gauge the likelihood that a given algorithm would be competitive. To the</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>best of our knowledge, there are no algorithm selection approaches that</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>do this.</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>Instead of considering only a point prediction, we consider the</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>predicted distribution of performance metric values, characterized by</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a>its mean and standard deviation. Formally, we denote the standard</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>deviation of the prediction $\hat{m}(A, i)$ as $\sigma_{A, i}$ for each</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>solver $A$ and instance $i$. We assume that the predictions of our</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>performance models follow a normal distribution, i.e.&nbsp;the predicted</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>value is the mean of that distribution and allows to characterize it</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>completely together with the standard deviation. We assess the</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>likelihood of two algorithms performing equally well by computing the</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>overlap between their distributions. If two algorithms are predicted to</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>perform very similarly, then the overlap between the distributions will</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>be very large.</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>We are in particular interested in the predicted performance</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>distribution of the best-predicted algorithm $A_{1,i}$ (no algorithms</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>are predicted to perform better than it), and how the predictions for</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>the other algorithms compare to it. Formally, for the best predicted</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>solver $A_{1,i}$ on instance $i$ the distribution of predictions is</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>$ \hat{m}(A_{1,i}, i) \sim \hat{M}(\mu_{A_{1,i},i}, \sigma^2_{A_{1,i},i}) $</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>with probability density function $ f_{A_{1,i},i}$ and cumulative</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>distribution function $F_{A_{1,i},i}$. The performance distributions</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>for other algorithms are defined similarly.</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>For the distributions of the predicted performance of two algorithms</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>$A_x$ and $A_y$ on instance $i$, the point of intersection $c$ can be</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>computed as $f_{A_x,i}(c) =  f_{A_y,i}(c)$. That is, the predicted</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>probability of achieving this particular performance is equal for both</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>distributions (illustrated in</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#fig:overlappingarea)</span>{reference-type="ref"</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>reference="fig:overlappingarea"}). For $\mu_{A_x,i} &lt; \mu_{A_y,i}$,</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>$c$ is defined as (we omit the index $i$ for the sake of brevity here):</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>$$\label{eq:5}</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>{c = \frac{\mu _{A_y} \sigma _{A_x}^2-\sigma _{A_y} \left(\mu _{A_x} \sigma _{A_y}+\sigma _{A_x} \sqrt{\left(\mu _{A_x}-\mu _{A_y}\right){}^2+2 \left(\sigma _{A_x}^2-\sigma _{A_y}^2\right) \log \left(\frac{\sigma _{A_x}}{\sigma _{A_y}}\right)}\right)}{\sigma _{A_x}^2-\sigma _{A_y}^2}}$$</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>Given $c$, the overlap between the distributions is defined as the joint</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>probability of $A_x$ performing worse than $c$ and $A_y$ performing</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>better than $c$:</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>$$\label{eq:6}</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>    p(\hat{m}({A_{x,i}}, i) \geq c) \cdot p(\hat{m}({A_{y,i}}, i) \leq c) = 1 - F_{A_{x,i},i}(c) +  F_{A_{y,i},i}(c)$$</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a>We define $p_{\cap} \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ as a threshold for the computed joint</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a>probability to include a given algorithm:</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>$$\label{eq:7}</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a> P_i = <span class="sc">\{</span>A \:| \: \left(p(\hat{m}({A_{1,i},i)} \geq c) \: \cdot \: p(\hat{m}({A_{x,i}}, i) \leq c)\right) \geq \:p_{\cap}\:<span class="sc">\}</span>$$</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>$p_{\cap}$ is 1 for the best predicted algorithm, and 0 for algorithms</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>whose distribution does not have any overlap with that of the best</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>predicted algorithm, i.e.&nbsp;the probability of performing at least as good</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>as the best predicted algorithm is 0.</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>We can control the size of the parallel portfolio by adjusting the value</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a>of $p_{\cap}$. If $p_{\cap}$ is set to 1, only the best predicted</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>algorithm and ones that are predicted to perform exactly like it are</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>included. On the other hand, if $p_{\cap}$ is set to 0, all algorithms</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>will be included. This allows us to tune our approach to a given</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>algorithm selection scenario and choose the algorithms to run in</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>parallel very flexibly, also accommodating potentially inaccurate</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>performance predictions.</span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:overlappingarea"&gt;</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>&lt;embed src="plots/ovelappingarea.svg" style="width:80.0%" /&gt;</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt;Overlapping area of two normal distributions. The point</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>&lt;span class="math inline"&gt;<span class="sc">\(</span>c<span class="sc">\)</span>&lt;/span&gt; is the performance both</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>distributions are equally likely to achieve. The shaded area denotes the</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>probability of overlap between the two distributions; in our case, the</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>probability that the candidate solver will perform as least as well as</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>the best predicted solver.&lt;/figcaption&gt;</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experimental Setup</span></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Collection</span></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>We used three scenarios from the ASlib benchmark repository</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>&nbsp;<span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>: MAXSAT19-UCMS, SAT11-INDU, and SAT18-EXP.</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>Additionally, we created two new scenarios: SAT16-MAIN, which utilizes</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a>solvers and instances from the SAT Competition 2016, and IPC2018, which</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>incorporates solvers and instances from the International Planning</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>Competition 2018. As ASlib only offers algorithm performance data for</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>single runs, we conducted our own measurements for parallel runs on</span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>individual machines. We also measured the performance for single runs</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>again and repeated the instance feature extraction steps to ensure that</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>all experiments were performed on the same hardware. For MAXSAT19-UCMS,</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a>SAT11-INDU<span class="ot">[^1]</span>, SAT16-MAIN, and SAT18-EXP, we used SATZilla's feature</span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>computation code&nbsp;<span class="co">[</span><span class="ot">@satzilla</span><span class="co">]</span>, and extracted 54 different features. For</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>IPC2018 we used the feature extraction code</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>by&nbsp;<span class="co">[</span><span class="ot">@Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014</span><span class="co">]</span> which</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>extracts 305 features for planning problems in PDDL format. We excluded</span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>26 instances of SAT Competition 2016 from the SAT16-MAIN scenario</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a>because we were unable to extract features within two hours of</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a>computational time. We also omitted two solvers, glocusePLE and</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a>Scavel_SAT, from SAT16-MAIN because of frequent out-of-memory errors on</span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>multiple instances. From IPC2018, we omitted three solvers, MSP,</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a>maplan-1, and maplan-2, because they require an unavailable version of</span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a>CPLEX. Table&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#tab:scenarios)</span>{reference-type="ref"</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a>reference="tab:scenarios"} gives an overview of the scenarios,</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a>algorithms, instances, and features we use in our evaluation.</span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a>::: {#tab:scenarios}</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a>  Scenario         Algorithms   Instances   Instance Features  </span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>  --------------- ------------ ----------- ------------------- --</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a>  IPC2018              15          240             305         </span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>  MAXSAT19-UCMS        7           572             54          </span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a>  SAT11-INDU           14          300             54          </span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>  SAT16-MAIN           25          274             54          </span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>  SAT18-EXP            37          353             54          </span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>  : Number of Algorithms, Instances, and Features Across All Scenarios.</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>We ran all solvers on all instances on compute nodes with 32 processors</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a>and 40 MB cache size (Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz), 128 GB</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>memory, and Red Hat Linux version 8.6. We use the same time limits as in</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>the ASlib scenarios; 5000 CPU seconds for SAT18-EXP and SAT11-INDU, and</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a>3600 CPU seconds for MAXSAT19-UCMS. For the new scenarios, we use the</span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a>same time limits as the respective competitions; 5000 CPU seconds for</span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN and 1800 CPU seconds for IPC2018. We ran each algorithm</span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>individually with 2-10 parallel runs. For all experiments, we ensured</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>that only the given number of parallel runs were executed on a single</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a>machine. As our previous work showed that performance becomes worse than</span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a>algorithm selection of a single solver for more than 10 parallel</span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a>runs&nbsp;<span class="co">[</span><span class="ot">@pmlr-v140-kashgarani21a</span><span class="co">]</span>, we did not evaluate more than 10</span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a>parallel runs.</span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training and Tuning</span></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a>In the paper &nbsp;<span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>, we first built random forest</span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>regression models to predict the performance of an algorithm on an</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a>instance using LLAMA&nbsp;<span class="co">[</span><span class="ot">@LLAMA</span><span class="co">]</span> and MLR&nbsp;<span class="co">[</span><span class="ot">@mlr</span><span class="co">]</span>. To expand on the results</span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a>of the paper, in addition to the initial performance model, we trained</span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a>two additional algorithm selection performance models using the random</span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>forest implementation in the MLR3 package. We compared these with the</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a>previous randomForest model trained with the MLR package in R.</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a>MLR is an R package that unifies the available implementations of</span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>machine learning algorithms in R <span class="co">[</span><span class="ot">@mlr</span><span class="co">]</span>. In MLR, the Random Forests</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a>learner uses the randomForest package in R <span class="co">[</span><span class="ot">@randomforest</span><span class="co">]</span> as a</span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>dependency. The MLR package extends this algorithm by providing one</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a>method to estimate the uncertainties of the predictions, which is the</span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a>Jackknife <span class="co">[</span><span class="ot">@wager2014confidence</span><span class="co">]</span> technique. MLR3 <span class="co">[</span><span class="ot">@Bischl2024</span><span class="co">]</span>, on the</span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a>other hand, is the latest version of the MLR release, offering enhanced</span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>features. Some learners differ between MLR and MLR3. In MLR, training</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>random forests uses the implementation of the randomForest R package,</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a>while MLR3 replaces this with the Ranger R package. According to its</span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a>documentation, Ranger is designed to be a fast implementation of random</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a>forests, particularly for high-dimensional data <span class="co">[</span><span class="ot">@ranger</span><span class="co">]</span>. In Ranger's</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a>paper <span class="co">[</span><span class="ot">@ranger</span><span class="co">]</span> it outperforms other implementations, including</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>randomForest, in terms of runtime and memory usage, especially as the</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a>number of trees, features, and sample sizes increases, and Ranger scaled</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a>almost linearly with the number of samples, while randomForest scaled</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a>superlinearly <span class="co">[</span><span class="ot">@ranger</span><span class="co">]</span>.</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a>Our MLR regression random forest models predict the runtime for each</span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>solver as the mean of the underlying distribution, and estimate the</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a>standard deviation using the Jackknife</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a>method&nbsp;<span class="co">[</span><span class="ot">@wager2014confidence; @mlr</span><span class="co">]</span>, which calculates the standard</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a>deviation of the mean predictions over all observations used to train</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a>the random forest. The random forest is trained on $n-1$ observations</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>and makes a prediction for the remaining observation. This process is</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a>repeated for all observations. The mean prediction for each tree is</span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>determined by averaging its predictions for the left-out observations.</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a>The Jackknife method assumes that the distribution of the predictions is</span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>normal, and their standard deviation is the uncertainty of the overall</span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>prediction.</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a>Ranger allows two different methods to estimate prediction uncertainties</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a><span class="ot">[@wager2014confidence]: </span>the Jackknife (also known as the</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a>jackknife-after-bootstrap) and the infinitesimal Jackknife (also known</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>as the infinitesimal-jackknife-for-bagging). We built random forest</span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a>regression models using the Ranger package twice: one model with the</span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a>Jackknife method (RJ) to estimate prediction uncertainty and the other</span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a>with the Infinitesimal Jackknife method (RI).</span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a>The Jackknife and infinitesimal Jackknife methods both estimate the</span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>standard deviation, but differ in approach and efficiency according to</span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@wager2014confidence</span><span class="co">]</span>. The jackknife removes one observation at a time</span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a>to assess the impact, while the infinitesimal jackknife downweights each</span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a>observation by an infinitesimal amount. So, the infinitesimal Jackknife</span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>method downweights each observation by a very small amount. This</span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>approach often leads to more stable predictions and is more</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>computationally efficient, as it requires fewer bootstrap replicates for</span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>similar accuracy <span class="co">[</span><span class="ot">@wager2014confidence</span><span class="co">]</span>.</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>Random forests usually result in the best algorithm selection</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>performance and performance predictions&nbsp;<span class="co">[</span><span class="ot">@BISCHL201641; @HUTTER201479</span><span class="co">]</span>.</span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a>Our setup mirrors that of&nbsp;<span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>: we removed constant-valued</span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>instance features and imputed missing feature values with the mean of</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a>all non-missing values for that feature. The hyperparameters of the</span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>random forest models were tuned using random search with 250 iterations,</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>with $ntree$ ranging from 10 to 200 and $mtry$ from 1 to 30 in a nested</span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>cross-validation with three inner folds and 10 outer</span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>folds&nbsp;<span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>.</span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>Since the available version of LLAMA <span class="co">[</span><span class="ot">@LLAMA</span><span class="co">]</span> was only adapted to MLR,</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a>we ported the LLAMA package to MLR3 to conduct experiments and compare</span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a>different implementations<span class="ot">[^2]</span>. This update will be available to the</span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>community in the near future as CRAN R package.</span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>To determine the optimal value of $p_{\cap}$ in</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a>Equation&nbsp;<span class="co">[</span><span class="ot">\[eq:6\]</span><span class="co">](#eq:6)</span>{reference-type="ref" reference="eq:6"} for</span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a>each scenario, we perform a grid search in the $[0, 1)$ interval with a</span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>resolution of $0.01$ for a total of 100 values. Additionally, we</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>determine the overall optimal value of $p_{\cap}$ across all five</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a>scenarios.</span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>We evaluate the proposed approach using penalized average runtime with a</span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>factor of 10 (PAR10), misclassification penalty (MCP), runtime. The</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a>PAR10 score is equal to the actual runtime when the algorithm succeeds</span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>in solving the instance within the timeout, otherwise, it is the timeout</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a>times 10. The misclassification penalty is the difference between the</span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>performance of the selected algorithm and the performance of the optimal</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>algorithm. We report the mean and standard deviation of these values in</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref"</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>reference="tab:summary"},&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary2)</span>{reference-type="ref"</span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>reference="tab:summary2"}, and&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary2)</span>{reference-type="ref"</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>reference="tab:summary2"}.</span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a>We also measure the PAR10 score normalized gap closed between the</span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>sequential single best solver and the sequential virtual best solver. In</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref"</span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>reference="tab:summary"},&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary2)</span>{reference-type="ref"</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a>reference="tab:summary2"}, and&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary2)</span>{reference-type="ref"</span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>reference="tab:summary2"}, we report the mean and standard deviation of</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a>the normalized gap closed across the 10 folds of data used to train the</span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a>performance models. In contrast to the reported runtime, MCP and PAR10</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>scores, in these tables, we do not report the mean and standard</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>deviation in the distribution of all instances. Instead, we use folds</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a>because, based on the normalized gap closed formula</span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>$\frac{\text{sbs} - \text{approach}}{\text{sbs} - \text{vbs}}$, we aimed</span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a>to avoid zero denominators in cases where the single best solver is the</span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>actual best solver for an instance. The</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>plots&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#fig:all_results)</span>{reference-type="ref"</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>reference="fig:all_results"}, show the PAR10 score normalized gap closed</span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>over the entire distribution of instances.</span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a><span class="fu">### Baselines</span></span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a>We compare the performance of our approach to several baseline methods,</span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>in particular the sequential virtual best solver (VBS), which is the</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a>optimal algorithm from the portfolio per problem instance (with a</span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>cumulative misclassification penalty of zero) and the sequential single</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a>best solver (SBS), which is the algorithm from the portfolio with the</span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>best average performance across all problem instances. The VBS for</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a>parallel runs is the best solver for each instance, but including the</span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a>overhead for $n$ parallel runs. The parallel SBS is computed similarly,</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a>with the best solvers on average instead of the best on each instance.</span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a>We run multiple solvers in parallel to measure the actual runtime of the</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a>best solver in this case, rather than assuming the sequential runtime.</span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a>We further compare to per-instance algorithm selection that simply runs</span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a>the top $n$ predicted algorithms in parallel without considering the</span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a>overlap of the distributions of the performance predictions, with the</span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a>same performance models we use for our approach. In the notation we</span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a>introduced above, we set $p_{\cap}=0$ and cap the number of runs at the</span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a>number of available processors. We use a simple scheduling method as a</span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a>further baseline, where algorithms are scheduled according to their</span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a>predicted rank and allocated a time slice equal to the predicted</span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a>performance plus the standard deviation. This allows to run more than</span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>one algorithm per processor. This approach prioritizes the</span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a>best-predicted algorithms but also potentially allows other algorithms</span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a>to run.</span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a>ASPEED&nbsp;<span class="co">[</span><span class="ot">@aspeed</span><span class="co">]</span> provides a general schedule for all instances in a</span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a>given scenario, rather than a schedule for each instance individually.</span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a>Therefore, we do not include ASPEED in our experimental evaluation --</span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a>static schedules across large sets of problem instances do not achieve</span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a>competitive performance, as shown in&nbsp;<span class="co">[</span><span class="ot">@flexfolio</span><span class="co">]</span>. The Flexfolio</span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a>paper&nbsp;<span class="co">[</span><span class="ot">@flexfolio</span><span class="co">]</span> shows experiments for Instance-Specific ASPEED and</span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a>TSunny, but the available source code does not contain these algorithm</span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a>selection methods and we are unable to compare to them.</span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a>Finally, we compare our approach to 3S as implemented in</span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a>Flexfolio&nbsp;<span class="co">[</span><span class="ot">@flexfolio</span><span class="co">]</span>, as the original 3S implementation is</span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a>unavailable. In this implementation, the number of neighbors for the kNN</span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a>models was set to 32, and ASPEED&nbsp;<span class="co">[</span><span class="ot">@aspeed</span><span class="co">]</span> is used to schedule the</span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a>chosen solvers instead of the original integer programming scheduler.</span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a>We normalize all performances across scenarios by the performances of</span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a>the VBS and SBS and report the fraction of the gap between them that was</span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a>closed by a particular approach. On this normalized scale, 0 corresponds</span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a>to the performance of the SBS and 1 to the performance of the VBS. All</span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a>code and data are available at</span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/uwyo-mallet/auto-parallel-portfolio-selection&gt;</span>.</span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a><span class="fu">## Results</span></span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning of $p_{\cap}$</span></span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:sensitivity"&gt;</span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;embed src="plots/Theta_sensitivity_x_theta_y_runtime_facet.svg"</span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>style="width:48.0%" /&gt; &lt;embed</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a>src="plots/pcap_ri_sensitivity_x_theta_y_runtime_facet.svg" style="width:48.0%"/&gt; &lt;embed</span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a>src="plots/pcap_rj_sensitivity_x_theta_y_runtime_facet.svg" style="width:48.0%"/&gt;&lt;/p&gt;</span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt;Sensitivity of portfolio performance to &lt;span</span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>p_{\cap}<span class="sc">\)</span>&lt;/span&gt;. The top-left plot refers to the</span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a>RFJ model—Regression Random Forest model using MLR with the Jackknife</span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a>uncertainty estimation method. The top-right plot refers to the RI</span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a>model—Regression Ranger model with the Infinitesimal Jackknife</span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a>uncertainty estimation method. The bottom plot refers to the RJ</span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a>model—Regression Ranger model with the Jackknife uncertainty estimation</span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a>method. The plot illustrates the mean, Q1 (25th percentile), Q2 (50th</span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a>percentile), and Q3 (75th percentile) runtime performance of each</span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a>scenario for various values of &lt;span</span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>p_{\cap}<span class="sc">\)</span>&lt;/span&gt; as defined in Equation&nbsp;&lt;a</span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a>href="#eq:7" data-reference-type="ref" data-reference="eq:7"&gt;<span class="co">[</span><span class="ot">eq:7</span><span class="co">]</span>&lt;/a&gt;.</span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a>Note the log scale for the normalized gap closed.&lt;/figcaption&gt;</span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a>The tuning of $p_{\cap}$ shows that the optimal value depends on the</span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a>scenario. For the IPC2018 scenario, the ideal $p_{\cap}$ value is 0.59,</span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a>for the MAXSAT19-UCMS scenario 0.55, for SAT11-INDU 0.63, for SAT16-MAIN</span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a>0.33, and for SAT18-EXP 0.81 for the random forest model trained using</span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a>the MLR and Jackknife uncertainty estimation method (RFJ). The optimal</span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a>$p_{\cap}$ values for the Ranger models, one with Jackknife (RJ) and the</span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a>other with Infinitesimal Jackknife (RI), are provided in</span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#tab:pcap)</span>{reference-type="ref" reference="tab:pcap"}.</span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a>::: {#tab:pcap}</span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a>  Scenario         RandomForest_Jackknife   Ranger_Jackknife   Ranger_Inifinitesimal  </span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a>  --------------- ------------------------ ------------------ ----------------------- --</span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a>  IPC2018                   0.59                  0.27                 0.44           </span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a>  MAXSAT19-UCMS             0.55                  0.14                 0.03           </span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a>  SAT11-INDU                0.63                  0.31                 0.01           </span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a>  SAT16-MAIN                0.33                  0.33                   0            </span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a>  SAT18-EXP                 0.81                  0.58                 0.55           </span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a>  Generic best              0.82                  0.31                 0.17           </span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a>  : Optimum value of $p_{\cap}$ for each benchmark and model.</span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a>Figures&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#fig:sensitivity)</span>{reference-type="ref"</span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a>reference="fig:sensitivity"} shows the normalized gap closed for the</span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a>mean, 25th percentile, 50th percentile, and 75th percentiles for each</span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a>scenario depending on $p_{\cap}$. While the optimal values are very</span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a>different across different scenario and each algorithm selector, the</span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a>differences in terms of gap closed are relatively small as long as</span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a>$p_{\cap}$ is not too large. The best average value for $p_{\cap}$</span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a>across all scenarios for RFJ model, RI model, and RJ model are 0.82,</span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a>0.17, 0.31 respectively which yields performance improvements over the</span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a>baselines in most cases (see</span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref"</span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a>reference="tab:summary"}). For the overall best performance, we</span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a>recommend to tune $p_{\cap}$ for the particular scenario. However, using</span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a>the generic best values of 0.82, 0.17, and 0.31 for RFJ, RI, and RJ,</span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a>respectively, provides a reasonable starting point that yields good</span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a>performance across the range of scenarios considered here.</span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a>The optimal value of $p_{\cap}$ allows us to draw conclusions with</span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a>respect to the predictive accuracy of the performance models we are</span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a>using. A small value would suggest that the predictions of the</span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a>performance models are not very accurate, as we have to include even</span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a>solvers whose predicted runtime distribution has a small overlap with</span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a>the runtime distribution of the best predicted solver to include solvers</span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a>that are actually good. If the optimal value of $p_{\cap}$ was 0, we</span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a>would have to include all solvers, even the ones whose predicted</span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a>distribution has no overlap with the best predicted solver -- in other</span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a>words, the predicted runtime distribution of the actual best solver has</span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a>no overlap with the predicted runtime distribution of the best predicted</span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a>solver.</span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a>Here, for the RFJ model, the optimal values for $p_{\cap}$ are</span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a>relatively large in most cases, and even the smallest values are far</span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a>greater than 0. For the RJ model, the values are lower than those for</span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a>the RFJ model, except for SAT16-MAIN, where the values are equal. For</span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a>the RI model, except for IPC2018, the values are even lower than those</span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a>for the RJ model. This indicates that the predictions of the performance</span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a>models for RFJ are quite good -- while the best predicted solver is not</span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a>always the actual best solver for a given problem instance, the</span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a>predicted runtime distribution of the actual best solver has a large</span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a>overlap with the predicted runtime distribution of the predicted best</span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a>solver.</span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a>Based on the low values of the RI model, it appears that this model</span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a>performs worse than the other two. This claim is also evident in</span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref" reference="tab:summary"}</span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a>where, for IPC2018, MAXSAT19-UCMS, and SAT11-INDU, the performance of</span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a>the $AS$ (RI) model is worse than the other two in at least two of the</span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a>performance measurements. For SAT16-MAIN, the $AS$ (RI) model performs</span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a>worst only in terms of PAR10, indicating more timeouts; however, on</span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a>average, it provides better runtime predictions, so the runtime and MCP</span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a>measures are better than those of the RJ model. For SAT18-EXP, as shown</span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a>in Table&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#tab:pcap)</span>{reference-type="ref" reference="tab:pcap"},</span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a>the RI model has a slightly lower $p_{\cap}$ value than the RJ model;</span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a>however, the difference is minimal, and the RI model performs better</span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a>than the RJ model according to</span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref" reference="tab:summary"}.</span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a>Overall, according to Table&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref"</span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a>reference="tab:summary"}, the RFJ model outperforms the other two models</span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a>in at least two performance metrics in 4 out of 5 scenarios when</span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a>performing single algorithm selection.</span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a><span class="fu">### Algorithm Selection Results</span></span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:all_results"&gt;</span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a>&lt;embed src="plots/line_chart_parallel_NormalizedGap_2col.svg" style="width:95.0%"/&gt;</span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt; Summary of results. The plot shows the degree to which the</span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a>gap between the SBS and VBS PAR10 scores is closed by each method. For</span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a>the VBS and SBS, we choose the top &lt;span</span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; solvers, where &lt;span</span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; is the number of processors, for a</span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a>given problem instance and across all instances, respectively. &lt;span</span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>AS_0<span class="sc">\)</span>&lt;/span&gt; chooses the top &lt;span</span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; solvers predicted by algorithm</span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a>selection, without regard for any overlap in their predicted runtime</span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a>distributions. &lt;span class="math inline"&gt;<span class="sc">\(</span>AS_{p_{\cap}}<span class="sc">\)</span>&lt;/span&gt;</span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a>represents the proposed formulation, with the number of processors</span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a>restricted to at most the specific value indicated on the x axis –</span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a>depending on the overlap of the predicted runtime distributions, fewer</span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a>solvers than the maximum may be chosen. The &lt;span</span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>p_{\cap}<span class="sc">\)</span>&lt;/span&gt; values for IPC2018,</span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a>MAXSAT19-UCMS, SAT11-INDU, SAT18-EXP, and SAT16-MAIN are 0.59, 0.55,</span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a>0.63, 0.81, and 0.33 and respectively. Time Splitting is the baseline</span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a>approach that allocates time proportional to the predicted runtime and</span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a>standard deviation for each solver, scheduling more than one solver to</span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a>be run per processor.&lt;/figcaption&gt;</span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:x_Scenario_y_Solver"&gt;</span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;embed src="plots/x_Scenario_y_Solver.svg" style="width:60.0%" /&gt;</span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a>&lt;embed src="plots/number_of_solvers_infjack_pcap.svg"</span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a>style="width:60.0%" /&gt; &lt;embed</span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a>src="plots/number_of_solvers_jack_pcap.svg" style="width:60.0%" /&gt;&lt;/p&gt;</span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt; Violin plot of the distribution of the number of selected</span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a>solvers to run in parallel across all problem instances for each</span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a>scenario for the respective optimal &lt;span</span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>p_{\cap}<span class="sc">\)</span>&lt;/span&gt; and the maximum level of</span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a>parallelism (seven processors for MAXSAT19-UCMS and 10 for all other</span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a>scenarios). The diamond denotes the mean value. The top-left plot refers</span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a>to the RFJ model, the top-right plot to the RI model, and the bottom</span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a>plot to the RJ model. &lt;/figcaption&gt;</span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a>To evaluate the effectiveness of our approach, we carried out a series</span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a>of experiments using the optimum and the average best value for</span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a>$p_{\cap}$ for each scenario using the RFJ model where we varied the</span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a>number of processors used for parallel execution from one to ten for the</span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a>SAT18-EXP, SAT16-MAIN, SAT11-INDU, and IPC2018 scenarios. For the</span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a>MAXSAT19-UCMS scenario, we used a maximum of seven processors as there</span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a>are only seven algorithms. For RFJ model</span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#fig:all_results)</span>{reference-type="ref"</span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a>reference="fig:all_results"} shows the PAR10 score results in terms of</span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a>the normalized performance gap between the sequential single best solver</span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a>and sequential virtual best solver for all scenarios and numbers of</span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a>processors.</span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a>The figure demonstrates the promise of the approach we propose here. In</span>
<span id="cb1-737"><a href="#cb1-737" aria-hidden="true" tabindex="-1"></a>three out of five scenarios, we achieve the overall top performance with</span>
<span id="cb1-738"><a href="#cb1-738" aria-hidden="true" tabindex="-1"></a>the maximum number of processors (even better than the parallel virtual</span>
<span id="cb1-739"><a href="#cb1-739" aria-hidden="true" tabindex="-1"></a>best solver!) and for the remaining two scenarios only the parallel</span>
<span id="cb1-740"><a href="#cb1-740" aria-hidden="true" tabindex="-1"></a>virtual best solver is better. We are able to achieve better performance</span>
<span id="cb1-741"><a href="#cb1-741" aria-hidden="true" tabindex="-1"></a>than the parallel virtual best solver when running in parallel because</span>
<span id="cb1-742"><a href="#cb1-742" aria-hidden="true" tabindex="-1"></a>our approach does not necessarily use all available processors, unlike</span>
<span id="cb1-743"><a href="#cb1-743" aria-hidden="true" tabindex="-1"></a>the baseline approaches that we compare to. While the performance of the</span>
<span id="cb1-744"><a href="#cb1-744" aria-hidden="true" tabindex="-1"></a>virtual best solver suffers for a large number of parallel runs, our</span>
<span id="cb1-745"><a href="#cb1-745" aria-hidden="true" tabindex="-1"></a>approach keeps the overhead of running many things in parallel low and</span>
<span id="cb1-746"><a href="#cb1-746" aria-hidden="true" tabindex="-1"></a>is thus better overall. We emphasize that the results we show here are</span>
<span id="cb1-747"><a href="#cb1-747" aria-hidden="true" tabindex="-1"></a>actual measured values for running in parallel, rather than assuming</span>
<span id="cb1-748"><a href="#cb1-748" aria-hidden="true" tabindex="-1"></a>overhead-free parallelization based on sequential runtimes, as is</span>
<span id="cb1-749"><a href="#cb1-749" aria-hidden="true" tabindex="-1"></a>commonly done in the literature. Our results demonstrate that this</span>
<span id="cb1-750"><a href="#cb1-750" aria-hidden="true" tabindex="-1"></a>common assumption is unrealistic except for a small number of parallel</span>
<span id="cb1-751"><a href="#cb1-751" aria-hidden="true" tabindex="-1"></a>runs.</span>
<span id="cb1-752"><a href="#cb1-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-753"><a href="#cb1-753" aria-hidden="true" tabindex="-1"></a>Even for a small number of processors, our approach yields better</span>
<span id="cb1-754"><a href="#cb1-754" aria-hidden="true" tabindex="-1"></a>performance than others. Initially, the performance is similar to $AS_0$</span>
<span id="cb1-755"><a href="#cb1-755" aria-hidden="true" tabindex="-1"></a>(running the top $n$ solvers), but our approach quickly becomes better</span>
<span id="cb1-756"><a href="#cb1-756" aria-hidden="true" tabindex="-1"></a>as the number of available processors increases. This is expected, as</span>
<span id="cb1-757"><a href="#cb1-757" aria-hidden="true" tabindex="-1"></a>for a single processor the two methods run exactly the same solver, but</span>
<span id="cb1-758"><a href="#cb1-758" aria-hidden="true" tabindex="-1"></a>for a larger number of processors our method may not run as many as</span>
<span id="cb1-759"><a href="#cb1-759" aria-hidden="true" tabindex="-1"></a>$AS_0$, thus decreasing overhead and overall solving performance.</span>
<span id="cb1-760"><a href="#cb1-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-761"><a href="#cb1-761" aria-hidden="true" tabindex="-1"></a>For the IPC2018 scenario, we achieve the best overall results, improving</span>
<span id="cb1-762"><a href="#cb1-762" aria-hidden="true" tabindex="-1"></a>performance substantially over all other approaches for 10 processors.</span>
<span id="cb1-763"><a href="#cb1-763" aria-hidden="true" tabindex="-1"></a>The 3S approach is never close to the performance of our method and</span>
<span id="cb1-764"><a href="#cb1-764" aria-hidden="true" tabindex="-1"></a>consistently yields worse results. The greedy time-splitting method also</span>
<span id="cb1-765"><a href="#cb1-765" aria-hidden="true" tabindex="-1"></a>underperformed, often allocating time slices smaller than required to</span>
<span id="cb1-766"><a href="#cb1-766" aria-hidden="true" tabindex="-1"></a>solve the instance and thus wasting resources. For more than seven</span>
<span id="cb1-767"><a href="#cb1-767" aria-hidden="true" tabindex="-1"></a>parallel runs, the parallel virtual best solver, i.e.&nbsp;choosing the</span>
<span id="cb1-768"><a href="#cb1-768" aria-hidden="true" tabindex="-1"></a>actual best solvers for each instance to run in parallel, starts to</span>
<span id="cb1-769"><a href="#cb1-769" aria-hidden="true" tabindex="-1"></a>perform worse than our method, which does not use as many processors and</span>
<span id="cb1-770"><a href="#cb1-770" aria-hidden="true" tabindex="-1"></a>incurs lower overhead.</span>
<span id="cb1-771"><a href="#cb1-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-772"><a href="#cb1-772" aria-hidden="true" tabindex="-1"></a>The results for the other scenarios are qualitatively similar. While for</span>
<span id="cb1-773"><a href="#cb1-773" aria-hidden="true" tabindex="-1"></a>a small number of processors, other methods perform similar to ours, the</span>
<span id="cb1-774"><a href="#cb1-774" aria-hidden="true" tabindex="-1"></a>gap between them widens as the number of parallel runs increases. 3S</span>
<span id="cb1-775"><a href="#cb1-775" aria-hidden="true" tabindex="-1"></a>consistently shows worse performance, whereas running the top $n$</span>
<span id="cb1-776"><a href="#cb1-776" aria-hidden="true" tabindex="-1"></a>solvers based on algorithm selection (without considering the predicted</span>
<span id="cb1-777"><a href="#cb1-777" aria-hidden="true" tabindex="-1"></a>performance distributions) is usually competitive and in some cases</span>
<span id="cb1-778"><a href="#cb1-778" aria-hidden="true" tabindex="-1"></a>gives the same performance as our method. The baseline of allocating a</span>
<span id="cb1-779"><a href="#cb1-779" aria-hidden="true" tabindex="-1"></a>time to run proportional to the predicted runtime and standard deviation</span>
<span id="cb1-780"><a href="#cb1-780" aria-hidden="true" tabindex="-1"></a>for each solver is not competitive, consistently showing bad performance</span>
<span id="cb1-781"><a href="#cb1-781" aria-hidden="true" tabindex="-1"></a>-- this baseline is worse than simply running the top $n$ single best</span>
<span id="cb1-782"><a href="#cb1-782" aria-hidden="true" tabindex="-1"></a>solvers in parallel on three scenarios for large numbers of parallel</span>
<span id="cb1-783"><a href="#cb1-783" aria-hidden="true" tabindex="-1"></a>runs. For the IPC2018 and MAXSAT19-UCMS scenarios, the performance of</span>
<span id="cb1-784"><a href="#cb1-784" aria-hidden="true" tabindex="-1"></a>some methods becomes worse than the single best solver for large numbers</span>
<span id="cb1-785"><a href="#cb1-785" aria-hidden="true" tabindex="-1"></a>of processors, showing the limitations of these approaches. For the</span>
<span id="cb1-786"><a href="#cb1-786" aria-hidden="true" tabindex="-1"></a>SAT2016-MAIN scenario, our approach is performing so close to the naïve</span>
<span id="cb1-787"><a href="#cb1-787" aria-hidden="true" tabindex="-1"></a>parallel algorithm selection (top $n$ solvers based on algorithm</span>
<span id="cb1-788"><a href="#cb1-788" aria-hidden="true" tabindex="-1"></a>selection) because the standard error of the predictions was large and</span>
<span id="cb1-789"><a href="#cb1-789" aria-hidden="true" tabindex="-1"></a>this resulted in large parallel portfolios for the majority of</span>
<span id="cb1-790"><a href="#cb1-790" aria-hidden="true" tabindex="-1"></a>instances.</span>
<span id="cb1-791"><a href="#cb1-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-792"><a href="#cb1-792" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref" reference="tab:summary"}</span>
<span id="cb1-793"><a href="#cb1-793" aria-hidden="true" tabindex="-1"></a>shows more detailed results. The normalized gap closed represented the</span>
<span id="cb1-794"><a href="#cb1-794" aria-hidden="true" tabindex="-1"></a>mean and standard deviation of the normalized gap closed across the 10</span>
<span id="cb1-795"><a href="#cb1-795" aria-hidden="true" tabindex="-1"></a>folds, whereas the &nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#fig:all_results)</span>{reference-type="ref"</span>
<span id="cb1-796"><a href="#cb1-796" aria-hidden="true" tabindex="-1"></a>reference="fig:all_results"} shows the mean of the normalized gap closed</span>
<span id="cb1-797"><a href="#cb1-797" aria-hidden="true" tabindex="-1"></a>across all instances at once. We see that our method results in</span>
<span id="cb1-798"><a href="#cb1-798" aria-hidden="true" tabindex="-1"></a>substantial savings in terms of all three measures across all scenarios</span>
<span id="cb1-799"><a href="#cb1-799" aria-hidden="true" tabindex="-1"></a>-- the proposed approach is always the best overall, regardless of the</span>
<span id="cb1-800"><a href="#cb1-800" aria-hidden="true" tabindex="-1"></a>performance measure. Note that we never beat the sequential VBS, which</span>
<span id="cb1-801"><a href="#cb1-801" aria-hidden="true" tabindex="-1"></a>represents the upper bound on the performance of any algorithm selection</span>
<span id="cb1-802"><a href="#cb1-802" aria-hidden="true" tabindex="-1"></a>system -- we cannot do better than only running the actual best solver.</span>
<span id="cb1-803"><a href="#cb1-803" aria-hidden="true" tabindex="-1"></a>In many cases, the actual performance we achieve is close to the</span>
<span id="cb1-804"><a href="#cb1-804" aria-hidden="true" tabindex="-1"></a>sequential VBS though. The results also show that using the "generic"</span>
<span id="cb1-805"><a href="#cb1-805" aria-hidden="true" tabindex="-1"></a>best value for $p_{\cap}$ of 0.82 still gives substantial performance</span>
<span id="cb1-806"><a href="#cb1-806" aria-hidden="true" tabindex="-1"></a>improvements over other approaches -- usually it gives the second best</span>
<span id="cb1-807"><a href="#cb1-807" aria-hidden="true" tabindex="-1"></a>performance. The only exception to this are the MAXSAT19-UCMS and</span>
<span id="cb1-808"><a href="#cb1-808" aria-hidden="true" tabindex="-1"></a>SAT2016-MAIN scenarios, where running the top $n$ solvers predicted by</span>
<span id="cb1-809"><a href="#cb1-809" aria-hidden="true" tabindex="-1"></a>algorithm selection does better. The gap is relatively small though, and</span>
<span id="cb1-810"><a href="#cb1-810" aria-hidden="true" tabindex="-1"></a>we still beat most of the other baselines.</span>
<span id="cb1-811"><a href="#cb1-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-812"><a href="#cb1-812" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-813"><a href="#cb1-813" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary}</span>
<span id="cb1-814"><a href="#cb1-814" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                    Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                           MCP                                PAR10                             NormalizedGap</span>
<span id="cb1-815"><a href="#cb1-815" aria-hidden="true" tabindex="-1"></a>  ---------- -------------------------------- ----------------------------------- --------------------------------- ------------------------------------- -------------------------------------</span>
<span id="cb1-816"><a href="#cb1-816" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                              </span></span>
<span id="cb1-817"><a href="#cb1-817" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                 508$\pm$`&lt;!-- --&gt;`{=html}697                     0                    3478$\pm$`&lt;!-- --&gt;`{=html}6903                       1</span></span>
<span id="cb1-818"><a href="#cb1-818" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                            607$\pm$`&lt;!-- --&gt;`{=html}751        99$\pm$`&lt;!-- --&gt;`{=html}301       4657$\pm$`&lt;!-- --&gt;`{=html}7725        -0.44$\pm$`&lt;!-- --&gt;`{=html}2.84</span></span>
<span id="cb1-819"><a href="#cb1-819" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                             608$\pm$`&lt;!-- --&gt;`{=html}751       100$\pm$`&lt;!-- --&gt;`{=html}293       4456$\pm$`&lt;!-- --&gt;`{=html}7583        -0.35$\pm$`&lt;!-- --&gt;`{=html}2.85</span></span>
<span id="cb1-820"><a href="#cb1-820" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                             604$\pm$`&lt;!-- --&gt;`{=html}752        96$\pm$`&lt;!-- --&gt;`{=html}293       4519$\pm$`&lt;!-- --&gt;`{=html}7633        -0.39$\pm$`&lt;!-- --&gt;`{=html}2.84</span></span>
<span id="cb1-821"><a href="#cb1-821" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                 734$\pm$`&lt;!-- --&gt;`{=html}770       226$\pm$`&lt;!-- --&gt;`{=html}414       5459$\pm$`&lt;!-- --&gt;`{=html}8072                       0</span></span>
<span id="cb1-822"><a href="#cb1-822" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                            </span></span>
<span id="cb1-823"><a href="#cb1-823" aria-hidden="true" tabindex="-1"></a><span class="in">             3S                                  645$\pm$`&lt;!-- --&gt;`{=html}770       137$\pm$`&lt;!-- --&gt;`{=html}471       5235$\pm$`&lt;!-- --&gt;`{=html}8047        -0.76$\pm$`&lt;!-- --&gt;`{=html}2.7</span></span>
<span id="cb1-824"><a href="#cb1-824" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RFJ)                637$\pm$`&lt;!-- --&gt;`{=html}797       129$\pm$`&lt;!-- --&gt;`{=html}348       5565$\pm$`&lt;!-- --&gt;`{=html}8241        -0.84$\pm$`&lt;!-- --&gt;`{=html}2.5</span></span>
<span id="cb1-825"><a href="#cb1-825" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RI)                 641$\pm$`&lt;!-- --&gt;`{=html}799       133$\pm$`&lt;!-- --&gt;`{=html}361       5636$\pm$`&lt;!-- --&gt;`{=html}8274        -0.99$\pm$`&lt;!-- --&gt;`{=html}2.52</span></span>
<span id="cb1-826"><a href="#cb1-826" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RJ)                 636$\pm$`&lt;!-- --&gt;`{=html}794       128$\pm$`&lt;!-- --&gt;`{=html}353       5496$\pm$`&lt;!-- --&gt;`{=html}8206        -0.92$\pm$`&lt;!-- --&gt;`{=html}2.51</span></span>
<span id="cb1-827"><a href="#cb1-827" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RFJ)                        612$\pm$`&lt;!-- --&gt;`{=html}779       104$\pm$`&lt;!-- --&gt;`{=html}307       5134$\pm$`&lt;!-- --&gt;`{=html}8027        -0.66$\pm$`&lt;!-- --&gt;`{=html}2.56</span></span>
<span id="cb1-828"><a href="#cb1-828" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                         616$\pm$`&lt;!-- --&gt;`{=html}783       107$\pm$`&lt;!-- --&gt;`{=html}312       5206$\pm$`&lt;!-- --&gt;`{=html}8065        -0.69$\pm$`&lt;!-- --&gt;`{=html}2.54</span></span>
<span id="cb1-829"><a href="#cb1-829" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                         616$\pm$`&lt;!-- --&gt;`{=html}783       107$\pm$`&lt;!-- --&gt;`{=html}312       5206$\pm$`&lt;!-- --&gt;`{=html}8065        -0.69$\pm$`&lt;!-- --&gt;`{=html}2.54</span></span>
<span id="cb1-830"><a href="#cb1-830" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.59}$ (RFJ)       *569$\pm$`&lt;!-- --&gt;`{=html}745*      *61$\pm$`&lt;!-- --&gt;`{=html}223*      4484$\pm$`&lt;!-- --&gt;`{=html}7651      **-0.18$\pm$`&lt;!-- --&gt;`{=html}2.74**</span></span>
<span id="cb1-831"><a href="#cb1-831" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.44}$ (RI)       **557$\pm$`&lt;!-- --&gt;`{=html}728**    **49$\pm$`&lt;!-- --&gt;`{=html}190**   **4135$\pm$`&lt;!-- --&gt;`{=html}7403**     *-0.19$\pm$`&lt;!-- --&gt;`{=html}2.89*</span></span>
<span id="cb1-832"><a href="#cb1-832" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.27}$ (RJ)         570$\pm$`&lt;!-- --&gt;`{=html}744        62$\pm$`&lt;!-- --&gt;`{=html}229       4350$\pm$`&lt;!-- --&gt;`{=html}7552        -0.21$\pm$`&lt;!-- --&gt;`{=html}2.72</span></span>
<span id="cb1-833"><a href="#cb1-833" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)        579$\pm$`&lt;!-- --&gt;`{=html}742        70$\pm$`&lt;!-- --&gt;`{=html}233       4359$\pm$`&lt;!-- --&gt;`{=html}7548        -0.26$\pm$`&lt;!-- --&gt;`{=html}2.88</span></span>
<span id="cb1-834"><a href="#cb1-834" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)         570$\pm$`&lt;!-- --&gt;`{=html}739        62$\pm$`&lt;!-- --&gt;`{=html}230      *4283$\pm$`&lt;!-- --&gt;`{=html}7501*       -0.24$\pm$`&lt;!-- --&gt;`{=html}2.87</span></span>
<span id="cb1-835"><a href="#cb1-835" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)         570$\pm$`&lt;!-- --&gt;`{=html}743        62$\pm$`&lt;!-- --&gt;`{=html}229       4350$\pm$`&lt;!-- --&gt;`{=html}7552        -0.21$\pm$`&lt;!-- --&gt;`{=html}2.72</span></span>
<span id="cb1-836"><a href="#cb1-836" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                              </span></span>
<span id="cb1-837"><a href="#cb1-837" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                 858$\pm$`&lt;!-- --&gt;`{=html}1476                    0                    7768$\pm$`&lt;!-- --&gt;`{=html}14717                      1</span></span>
<span id="cb1-838"><a href="#cb1-838" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                           1037$\pm$`&lt;!-- --&gt;`{=html}1555      179$\pm$`&lt;!-- --&gt;`{=html}641       9363$\pm$`&lt;!-- --&gt;`{=html}15684       0.55$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-839"><a href="#cb1-839" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                            1076$\pm$`&lt;!-- --&gt;`{=html}1575      218$\pm$`&lt;!-- --&gt;`{=html}729       9686$\pm$`&lt;!-- --&gt;`{=html}15850       0.45$\pm$`&lt;!-- --&gt;`{=html}0.34</span></span>
<span id="cb1-840"><a href="#cb1-840" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                            1044$\pm$`&lt;!-- --&gt;`{=html}1565      186$\pm$`&lt;!-- --&gt;`{=html}666       9540$\pm$`&lt;!-- --&gt;`{=html}15793       0.49$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-841"><a href="#cb1-841" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                1190$\pm$`&lt;!-- --&gt;`{=html}1657      332$\pm$`&lt;!-- --&gt;`{=html}940      11386$\pm$`&lt;!-- --&gt;`{=html}16696                      0</span></span>
<span id="cb1-842"><a href="#cb1-842" aria-hidden="true" tabindex="-1"></a><span class="in">             **7 Processors**                                                                                                                             </span></span>
<span id="cb1-843"><a href="#cb1-843" aria-hidden="true" tabindex="-1"></a><span class="in">             3S                                  953$\pm$`&lt;!-- --&gt;`{=html}1480       95$\pm$`&lt;!-- --&gt;`{=html}437       8317$\pm$`&lt;!-- --&gt;`{=html}15031       0.83$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-844"><a href="#cb1-844" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RFJ)                908$\pm$`&lt;!-- --&gt;`{=html}1523       51$\pm$`&lt;!-- --&gt;`{=html}308       8668$\pm$`&lt;!-- --&gt;`{=html}15353       0.75$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-845"><a href="#cb1-845" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RI)                 919$\pm$`&lt;!-- --&gt;`{=html}1535       61$\pm$`&lt;!-- --&gt;`{=html}356       8849$\pm$`&lt;!-- --&gt;`{=html}15470        0.7$\pm$`&lt;!-- --&gt;`{=html}0.2</span></span>
<span id="cb1-846"><a href="#cb1-846" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RJ)                 917$\pm$`&lt;!-- --&gt;`{=html}1531       59$\pm$`&lt;!-- --&gt;`{=html}352       8790$\pm$`&lt;!-- --&gt;`{=html}15431        0.71$\pm$`&lt;!-- --&gt;`{=html}0.2</span></span>
<span id="cb1-847"><a href="#cb1-847" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RFJ)                       *894$\pm$`&lt;!-- --&gt;`{=html}1506*     *37$\pm$`&lt;!-- --&gt;`{=html}247*      8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-848"><a href="#cb1-848" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                        *894$\pm$`&lt;!-- --&gt;`{=html}1506*     *37$\pm$`&lt;!-- --&gt;`{=html}247*      8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-849"><a href="#cb1-849" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                        *894$\pm$`&lt;!-- --&gt;`{=html}1506*     *37$\pm$`&lt;!-- --&gt;`{=html}247*      8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-850"><a href="#cb1-850" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = {0.55}}$ (RFJ)    **891$\pm$`&lt;!-- --&gt;`{=html}1496**   **33$\pm$`&lt;!-- --&gt;`{=html}215**   **8141$\pm$`&lt;!-- --&gt;`{=html}14975**   **0.88$\pm$`&lt;!-- --&gt;`{=html}0.17**</span></span>
<span id="cb1-851"><a href="#cb1-851" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.03}$ (RI)        *894$\pm$`&lt;!-- --&gt;`{=html}1506*     *37$\pm$`&lt;!-- --&gt;`{=html}247*      8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-852"><a href="#cb1-852" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.14}$ (RJ)         921$\pm$`&lt;!-- --&gt;`{=html}1521       63$\pm$`&lt;!-- --&gt;`{=html}369       8568$\pm$`&lt;!-- --&gt;`{=html}15263       0.76$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-853"><a href="#cb1-853" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)        928$\pm$`&lt;!-- --&gt;`{=html}1513       70$\pm$`&lt;!-- --&gt;`{=html}364       8461$\pm$`&lt;!-- --&gt;`{=html}15175       0.81$\pm$`&lt;!-- --&gt;`{=html}0.18</span></span>
<span id="cb1-854"><a href="#cb1-854" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)         901$\pm$`&lt;!-- --&gt;`{=html}1502       43$\pm$`&lt;!-- --&gt;`{=html}275      *8208$\pm$`&lt;!-- --&gt;`{=html}15015*    **0.88$\pm$`&lt;!-- --&gt;`{=html}0.16**</span></span>
<span id="cb1-855"><a href="#cb1-855" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)         931$\pm$`&lt;!-- --&gt;`{=html}1525       73$\pm$`&lt;!-- --&gt;`{=html}402       8578$\pm$`&lt;!-- --&gt;`{=html}15259       0.78$\pm$`&lt;!-- --&gt;`{=html}0.21</span></span>
<span id="cb1-856"><a href="#cb1-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-857"><a href="#cb1-857" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-858"><a href="#cb1-858" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-859"><a href="#cb1-859" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-860"><a href="#cb1-860" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-861"><a href="#cb1-861" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-862"><a href="#cb1-862" aria-hidden="true" tabindex="-1"></a>  of processors (10 for IPC2018, and 7 for MAXSAT19-UCMS) for our</span>
<span id="cb1-863"><a href="#cb1-863" aria-hidden="true" tabindex="-1"></a>  approach and the baselines we compare to. All numbers were rounded to</span>
<span id="cb1-864"><a href="#cb1-864" aria-hidden="true" tabindex="-1"></a>  integers. The best value for each scenario and measure is shown in</span>
<span id="cb1-865"><a href="#cb1-865" aria-hidden="true" tabindex="-1"></a>  **bold** (excepting the sequential VBS, which is by definition always</span>
<span id="cb1-866"><a href="#cb1-866" aria-hidden="true" tabindex="-1"></a>  the best), the second best in *italics*. The normalized gap closed</span>
<span id="cb1-867"><a href="#cb1-867" aria-hidden="true" tabindex="-1"></a>  represents the mean and standard deviation of the normalized gap</span>
<span id="cb1-868"><a href="#cb1-868" aria-hidden="true" tabindex="-1"></a>  closed across the folds.</span>
<span id="cb1-869"><a href="#cb1-869" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-870"><a href="#cb1-870" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-871"><a href="#cb1-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-872"><a href="#cb1-872" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-873"><a href="#cb1-873" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary2}</span>
<span id="cb1-874"><a href="#cb1-874" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                  Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                            MCP                                 PAR10                             NormalizedGap</span>
<span id="cb1-875"><a href="#cb1-875" aria-hidden="true" tabindex="-1"></a>  ---------- ------------------------------ ------------------------------------ ---------------------------------- -------------------------------------- ------------------------------------</span>
<span id="cb1-876"><a href="#cb1-876" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                               </span></span>
<span id="cb1-877"><a href="#cb1-877" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                               1140$\pm$`&lt;!-- --&gt;`{=html}1836                    0                     8040$\pm$`&lt;!-- --&gt;`{=html}17905                      1</span></span>
<span id="cb1-878"><a href="#cb1-878" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                          1535$\pm$`&lt;!-- --&gt;`{=html}2058      395$\pm$`&lt;!-- --&gt;`{=html}1037       11735$\pm$`&lt;!-- --&gt;`{=html}20768       0.16$\pm$`&lt;!-- --&gt;`{=html}0.79</span></span>
<span id="cb1-879"><a href="#cb1-879" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                           1610$\pm$`&lt;!-- --&gt;`{=html}2108      470$\pm$`&lt;!-- --&gt;`{=html}1145       12710$\pm$`&lt;!-- --&gt;`{=html}21389       -0.06$\pm$`&lt;!-- --&gt;`{=html}0.9</span></span>
<span id="cb1-880"><a href="#cb1-880" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                           1565$\pm$`&lt;!-- --&gt;`{=html}2049      425$\pm$`&lt;!-- --&gt;`{=html}1017       11315$\pm$`&lt;!-- --&gt;`{=html}20402       0.34$\pm$`&lt;!-- --&gt;`{=html}0.49</span></span>
<span id="cb1-881"><a href="#cb1-881" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                               1818$\pm$`&lt;!-- --&gt;`{=html}2168      678$\pm$`&lt;!-- --&gt;`{=html}1340       14268$\pm$`&lt;!-- --&gt;`{=html}22154                     0</span></span>
<span id="cb1-882"><a href="#cb1-882" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                             </span></span>
<span id="cb1-883"><a href="#cb1-883" aria-hidden="true" tabindex="-1"></a><span class="in">             3S                                1298$\pm$`&lt;!-- --&gt;`{=html}1898       158$\pm$`&lt;!-- --&gt;`{=html}546       9098$\pm$`&lt;!-- --&gt;`{=html}18780        0.78$\pm$`&lt;!-- --&gt;`{=html}0.3</span></span>
<span id="cb1-884"><a href="#cb1-884" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RFJ)              1335$\pm$`&lt;!-- --&gt;`{=html}2009       225$\pm$`&lt;!-- --&gt;`{=html}708       10635$\pm$`&lt;!-- --&gt;`{=html}20138       0.49$\pm$`&lt;!-- --&gt;`{=html}0.61</span></span>
<span id="cb1-885"><a href="#cb1-885" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RI)               1429$\pm$`&lt;!-- --&gt;`{=html}2108       318$\pm$`&lt;!-- --&gt;`{=html}875       12379$\pm$`&lt;!-- --&gt;`{=html}21378       0.19$\pm$`&lt;!-- --&gt;`{=html}0.53</span></span>
<span id="cb1-886"><a href="#cb1-886" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RJ)               1334$\pm$`&lt;!-- --&gt;`{=html}1998       224$\pm$`&lt;!-- --&gt;`{=html}689       10634$\pm$`&lt;!-- --&gt;`{=html}20138       0.55$\pm$`&lt;!-- --&gt;`{=html}0.43</span></span>
<span id="cb1-887"><a href="#cb1-887" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RFJ)                      1272$\pm$`&lt;!-- --&gt;`{=html}1927       161$\pm$`&lt;!-- --&gt;`{=html}548       8922$\pm$`&lt;!-- --&gt;`{=html}18645       *0.89$\pm$`&lt;!-- --&gt;`{=html}0.12*</span></span>
<span id="cb1-888"><a href="#cb1-888" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                      *1238$\pm$`&lt;!-- --&gt;`{=html}1892*      127$\pm$`&lt;!-- --&gt;`{=html}385      *8588$\pm$`&lt;!-- --&gt;`{=html}18350*     **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-889"><a href="#cb1-889" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                       1262$\pm$`&lt;!-- --&gt;`{=html}1910       151$\pm$`&lt;!-- --&gt;`{=html}480       8612$\pm$`&lt;!-- --&gt;`{=html}18342      **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-890"><a href="#cb1-890" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.63}$ (RFJ)      1241$\pm$`&lt;!-- --&gt;`{=html}1901       131$\pm$`&lt;!-- --&gt;`{=html}451       8591$\pm$`&lt;!-- --&gt;`{=html}18349      **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-891"><a href="#cb1-891" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.01}$ (RI)     **1236$\pm$`&lt;!-- --&gt;`{=html}1890**   **121$\pm$`&lt;!-- --&gt;`{=html}379**   **8586$\pm$`&lt;!-- --&gt;`{=html}18351**    **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-892"><a href="#cb1-892" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       1289$\pm$`&lt;!-- --&gt;`{=html}1934       178$\pm$`&lt;!-- --&gt;`{=html}595       9089$\pm$`&lt;!-- --&gt;`{=html}18787        0.78$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-893"><a href="#cb1-893" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)      1247$\pm$`&lt;!-- --&gt;`{=html}1900      *123$\pm$`&lt;!-- --&gt;`{=html}431*      8747$\pm$`&lt;!-- --&gt;`{=html}18501        0.83$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-894"><a href="#cb1-894" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)       1259$\pm$`&lt;!-- --&gt;`{=html}1912       139$\pm$`&lt;!-- --&gt;`{=html}477       8909$\pm$`&lt;!-- --&gt;`{=html}18649        0.74$\pm$`&lt;!-- --&gt;`{=html}0.36</span></span>
<span id="cb1-895"><a href="#cb1-895" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       1289$\pm$`&lt;!-- --&gt;`{=html}1934       178$\pm$`&lt;!-- --&gt;`{=html}595       9089$\pm$`&lt;!-- --&gt;`{=html}18787        0.78$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-896"><a href="#cb1-896" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                               </span></span>
<span id="cb1-897"><a href="#cb1-897" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                               1867$\pm$`&lt;!-- --&gt;`{=html}2193                    0                     15005$\pm$`&lt;!-- --&gt;`{=html}22530                     1</span></span>
<span id="cb1-898"><a href="#cb1-898" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                          2315$\pm$`&lt;!-- --&gt;`{=html}2273      448$\pm$`&lt;!-- --&gt;`{=html}1109       19066$\pm$`&lt;!-- --&gt;`{=html}23883       0.33$\pm$`&lt;!-- --&gt;`{=html}0.56</span></span>
<span id="cb1-899"><a href="#cb1-899" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                           2383$\pm$`&lt;!-- --&gt;`{=html}2294      516$\pm$`&lt;!-- --&gt;`{=html}1151       19956$\pm$`&lt;!-- --&gt;`{=html}24111       0.05$\pm$`&lt;!-- --&gt;`{=html}0.66</span></span>
<span id="cb1-900"><a href="#cb1-900" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                           2400$\pm$`&lt;!-- --&gt;`{=html}2269      533$\pm$`&lt;!-- --&gt;`{=html}1177       19316$\pm$`&lt;!-- --&gt;`{=html}23880       0.3$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-901"><a href="#cb1-901" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                               2560$\pm$`&lt;!-- --&gt;`{=html}2294      693$\pm$`&lt;!-- --&gt;`{=html}1415       21940$\pm$`&lt;!-- --&gt;`{=html}24464                     0</span></span>
<span id="cb1-902"><a href="#cb1-902" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                             </span></span>
<span id="cb1-903"><a href="#cb1-903" aria-hidden="true" tabindex="-1"></a><span class="in">             3S                                2093$\pm$`&lt;!-- --&gt;`{=html}2228       226$\pm$`&lt;!-- --&gt;`{=html}547       16874$\pm$`&lt;!-- --&gt;`{=html}23228       0.59$\pm$`&lt;!-- --&gt;`{=html}0.59</span></span>
<span id="cb1-904"><a href="#cb1-904" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RFJ)              2101$\pm$`&lt;!-- --&gt;`{=html}2247       234$\pm$`&lt;!-- --&gt;`{=html}732       16717$\pm$`&lt;!-- --&gt;`{=html}23149     **0.78$\pm$`&lt;!-- --&gt;`{=html}0.46**</span></span>
<span id="cb1-905"><a href="#cb1-905" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RI)               2089$\pm$`&lt;!-- --&gt;`{=html}2256       222$\pm$`&lt;!-- --&gt;`{=html}642       17691$\pm$`&lt;!-- --&gt;`{=html}23593       0.37$\pm$`&lt;!-- --&gt;`{=html}0.85</span></span>
<span id="cb1-906"><a href="#cb1-906" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RJ)               2098$\pm$`&lt;!-- --&gt;`{=html}2254       231$\pm$`&lt;!-- --&gt;`{=html}674       17372$\pm$`&lt;!-- --&gt;`{=html}23447       0.56$\pm$`&lt;!-- --&gt;`{=html}0.39</span></span>
<span id="cb1-907"><a href="#cb1-907" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RFJ)                      2065$\pm$`&lt;!-- --&gt;`{=html}2221       198$\pm$`&lt;!-- --&gt;`{=html}652     **16189$\pm$`&lt;!-- --&gt;`{=html}22931**    *0.7$\pm$`&lt;!-- --&gt;`{=html}0.39*</span></span>
<span id="cb1-908"><a href="#cb1-908" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                     **2016$\pm$`&lt;!-- --&gt;`{=html}2225**   **150$\pm$`&lt;!-- --&gt;`{=html}503**     16469$\pm$`&lt;!-- --&gt;`{=html}23122       0.68$\pm$`&lt;!-- --&gt;`{=html}0.6</span></span>
<span id="cb1-909"><a href="#cb1-909" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                       2048$\pm$`&lt;!-- --&gt;`{=html}2228       181$\pm$`&lt;!-- --&gt;`{=html}597      *16336$\pm$`&lt;!-- --&gt;`{=html}23023*      0.68$\pm$`&lt;!-- --&gt;`{=html}0.59</span></span>
<span id="cb1-910"><a href="#cb1-910" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.33}$ (RFJ)      2065$\pm$`&lt;!-- --&gt;`{=html}2221       198$\pm$`&lt;!-- --&gt;`{=html}652     **16189$\pm$`&lt;!-- --&gt;`{=html}22931**    *0.7$\pm$`&lt;!-- --&gt;`{=html}0.39*</span></span>
<span id="cb1-911"><a href="#cb1-911" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)        **2016$\pm$`&lt;!-- --&gt;`{=html}2225**   **150$\pm$`&lt;!-- --&gt;`{=html}503**     16469$\pm$`&lt;!-- --&gt;`{=html}23122       0.68$\pm$`&lt;!-- --&gt;`{=html}0.6</span></span>
<span id="cb1-912"><a href="#cb1-912" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.33}$ (RJ)       2088$\pm$`&lt;!-- --&gt;`{=html}2239       222$\pm$`&lt;!-- --&gt;`{=html}704       16705$\pm$`&lt;!-- --&gt;`{=html}23156       0.64$\pm$`&lt;!-- --&gt;`{=html}0.37</span></span>
<span id="cb1-913"><a href="#cb1-913" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)      2094$\pm$`&lt;!-- --&gt;`{=html}2222       228$\pm$`&lt;!-- --&gt;`{=html}730       16383$\pm$`&lt;!-- --&gt;`{=html}22993       0.69$\pm$`&lt;!-- --&gt;`{=html}0.41</span></span>
<span id="cb1-914"><a href="#cb1-914" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)      *2041$\pm$`&lt;!-- --&gt;`{=html}2230*     *174$\pm$`&lt;!-- --&gt;`{=html}591*      16822$\pm$`&lt;!-- --&gt;`{=html}23261       0.57$\pm$`&lt;!-- --&gt;`{=html}0.63</span></span>
<span id="cb1-915"><a href="#cb1-915" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       2096$\pm$`&lt;!-- --&gt;`{=html}2240       229$\pm$`&lt;!-- --&gt;`{=html}713       16877$\pm$`&lt;!-- --&gt;`{=html}23227       0.63$\pm$`&lt;!-- --&gt;`{=html}0.36</span></span>
<span id="cb1-916"><a href="#cb1-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-917"><a href="#cb1-917" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-918"><a href="#cb1-918" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-919"><a href="#cb1-919" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-920"><a href="#cb1-920" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-921"><a href="#cb1-921" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-922"><a href="#cb1-922" aria-hidden="true" tabindex="-1"></a>  of processors (10 for SAT16-MAIN and SAT11-INDU) for our approach and</span>
<span id="cb1-923"><a href="#cb1-923" aria-hidden="true" tabindex="-1"></a>  the baselines we compare to. All numbers were rounded to integers. The</span>
<span id="cb1-924"><a href="#cb1-924" aria-hidden="true" tabindex="-1"></a>  best value for each scenario and measure is shown in **bold**</span>
<span id="cb1-925"><a href="#cb1-925" aria-hidden="true" tabindex="-1"></a>  (excepting the sequential VBS, which is by definition always the</span>
<span id="cb1-926"><a href="#cb1-926" aria-hidden="true" tabindex="-1"></a>  best), the second best in *italics*. The normalized gap closed</span>
<span id="cb1-927"><a href="#cb1-927" aria-hidden="true" tabindex="-1"></a>  represents the mean and standard deviation of the normalized gap</span>
<span id="cb1-928"><a href="#cb1-928" aria-hidden="true" tabindex="-1"></a>  closed across the folds.</span>
<span id="cb1-929"><a href="#cb1-929" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-930"><a href="#cb1-930" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-931"><a href="#cb1-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-932"><a href="#cb1-932" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-933"><a href="#cb1-933" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary3}</span>
<span id="cb1-934"><a href="#cb1-934" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                  Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                             MCP                                 PAR10                             NormalizedGap</span>
<span id="cb1-935"><a href="#cb1-935" aria-hidden="true" tabindex="-1"></a>  ---------- ------------------------------ ------------------------------------ ----------------------------------- -------------------------------------- ------------------------------------</span>
<span id="cb1-936"><a href="#cb1-936" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                                </span></span>
<span id="cb1-937"><a href="#cb1-937" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                               1146$\pm$`&lt;!-- --&gt;`{=html}1945                     0                     9687$\pm$`&lt;!-- --&gt;`{=html}19547                      1</span></span>
<span id="cb1-938"><a href="#cb1-938" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                          1615$\pm$`&lt;!-- --&gt;`{=html}2138       468$\pm$`&lt;!-- --&gt;`{=html}1192       13470$\pm$`&lt;!-- --&gt;`{=html}21889       0.64$\pm$`&lt;!-- --&gt;`{=html}0.18</span></span>
<span id="cb1-939"><a href="#cb1-939" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                           1648$\pm$`&lt;!-- --&gt;`{=html}2151       502$\pm$`&lt;!-- --&gt;`{=html}1256       13758$\pm$`&lt;!-- --&gt;`{=html}22034       0.59$\pm$`&lt;!-- --&gt;`{=html}0.18</span></span>
<span id="cb1-940"><a href="#cb1-940" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                           1690$\pm$`&lt;!-- --&gt;`{=html}2170       543$\pm$`&lt;!-- --&gt;`{=html}1302       14183$\pm$`&lt;!-- --&gt;`{=html}22247       0.57$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-941"><a href="#cb1-941" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                               2400$\pm$`&lt;!-- --&gt;`{=html}2249      1254$\pm$`&lt;!-- --&gt;`{=html}1832       20629$\pm$`&lt;!-- --&gt;`{=html}24280                     0</span></span>
<span id="cb1-942"><a href="#cb1-942" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                              </span></span>
<span id="cb1-943"><a href="#cb1-943" aria-hidden="true" tabindex="-1"></a><span class="in">             3S                                1625$\pm$`&lt;!-- --&gt;`{=html}2228       479$\pm$`&lt;!-- --&gt;`{=html}1265       15010$\pm$`&lt;!-- --&gt;`{=html}22802       0.5$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-944"><a href="#cb1-944" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RFJ)              1714$\pm$`&lt;!-- --&gt;`{=html}2292       571$\pm$`&lt;!-- --&gt;`{=html}1384       15992$\pm$`&lt;!-- --&gt;`{=html}23222       0.42$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-945"><a href="#cb1-945" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RI)               1640$\pm$`&lt;!-- --&gt;`{=html}2266       497$\pm$`&lt;!-- --&gt;`{=html}1280       15408$\pm$`&lt;!-- --&gt;`{=html}23003       0.46$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-946"><a href="#cb1-946" aria-hidden="true" tabindex="-1"></a><span class="in">             Time Splitting (RJ)               1745$\pm$`&lt;!-- --&gt;`{=html}2308       602$\pm$`&lt;!-- --&gt;`{=html}1434       16151$\pm$`&lt;!-- --&gt;`{=html}23267       0.4$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-947"><a href="#cb1-947" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RFJ)                      1702$\pm$`&lt;!-- --&gt;`{=html}2301       559$\pm$`&lt;!-- --&gt;`{=html}1389       16235$\pm$`&lt;!-- --&gt;`{=html}23355       0.39$\pm$`&lt;!-- --&gt;`{=html}0.27</span></span>
<span id="cb1-948"><a href="#cb1-948" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                       1654$\pm$`&lt;!-- --&gt;`{=html}2285       511$\pm$`&lt;!-- --&gt;`{=html}1324       15804$\pm$`&lt;!-- --&gt;`{=html}23194       0.42$\pm$`&lt;!-- --&gt;`{=html}0.29</span></span>
<span id="cb1-949"><a href="#cb1-949" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                       1678$\pm$`&lt;!-- --&gt;`{=html}2288       535$\pm$`&lt;!-- --&gt;`{=html}1351       15956$\pm$`&lt;!-- --&gt;`{=html}23243        0.4$\pm$`&lt;!-- --&gt;`{=html}0.3</span></span>
<span id="cb1-950"><a href="#cb1-950" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.81}$ (RFJ)    **1518$\pm$`&lt;!-- --&gt;`{=html}2172**   **372$\pm$`&lt;!-- --&gt;`{=html}1124**   **13884$\pm$`&lt;!-- --&gt;`{=html}22265**   **0.62$\pm$`&lt;!-- --&gt;`{=html}0.22**</span></span>
<span id="cb1-951"><a href="#cb1-951" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.55}$ (RI)       1541$\pm$`&lt;!-- --&gt;`{=html}2191       397$\pm$`&lt;!-- --&gt;`{=html}1177       14034$\pm$`&lt;!-- --&gt;`{=html}22332      *0.6$\pm$`&lt;!-- --&gt;`{=html}0.21*</span></span>
<span id="cb1-952"><a href="#cb1-952" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.58}$ (RJ)       1622$\pm$`&lt;!-- --&gt;`{=html}2237       477$\pm$`&lt;!-- --&gt;`{=html}1268       15008$\pm$`&lt;!-- --&gt;`{=html}22805       0.5$\pm$`&lt;!-- --&gt;`{=html}0.25</span></span>
<span id="cb1-953"><a href="#cb1-953" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)     *1532$\pm$`&lt;!-- --&gt;`{=html}2178*     *386$\pm$`&lt;!-- --&gt;`{=html}1146*     *14025$\pm$`&lt;!-- --&gt;`{=html}22336*     *0.6$\pm$`&lt;!-- --&gt;`{=html}0.23*</span></span>
<span id="cb1-954"><a href="#cb1-954" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)       1555$\pm$`&lt;!-- --&gt;`{=html}2221       410$\pm$`&lt;!-- --&gt;`{=html}1191       14558$\pm$`&lt;!-- --&gt;`{=html}22628       0.57$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-955"><a href="#cb1-955" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       1649$\pm$`&lt;!-- --&gt;`{=html}2265       505$\pm$`&lt;!-- --&gt;`{=html}1319       15544$\pm$`&lt;!-- --&gt;`{=html}23064       0.46$\pm$`&lt;!-- --&gt;`{=html}0.26</span></span>
<span id="cb1-956"><a href="#cb1-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-957"><a href="#cb1-957" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-958"><a href="#cb1-958" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-959"><a href="#cb1-959" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-960"><a href="#cb1-960" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-961"><a href="#cb1-961" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-962"><a href="#cb1-962" aria-hidden="true" tabindex="-1"></a>  of processors (10 for SAT18-EXP) for our approach and the baselines we</span>
<span id="cb1-963"><a href="#cb1-963" aria-hidden="true" tabindex="-1"></a>  compare to. All numbers were rounded to integers. The best value for</span>
<span id="cb1-964"><a href="#cb1-964" aria-hidden="true" tabindex="-1"></a>  each scenario and measure is shown in **bold** (excepting the</span>
<span id="cb1-965"><a href="#cb1-965" aria-hidden="true" tabindex="-1"></a>  sequential VBS, which is by definition always the best), the second</span>
<span id="cb1-966"><a href="#cb1-966" aria-hidden="true" tabindex="-1"></a>  best in *italics*. The normalized gap closed represents the mean and</span>
<span id="cb1-967"><a href="#cb1-967" aria-hidden="true" tabindex="-1"></a>  standard deviation of the normalized gap closed across the folds.</span>
<span id="cb1-968"><a href="#cb1-968" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-969"><a href="#cb1-969" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-970"><a href="#cb1-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-971"><a href="#cb1-971" aria-hidden="true" tabindex="-1"></a><span class="fu">### Number of Selected Solvers</span></span>
<span id="cb1-972"><a href="#cb1-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-973"><a href="#cb1-973" aria-hidden="true" tabindex="-1"></a>As mentioned above, allowing our approach to use up to a certain number</span>
<span id="cb1-974"><a href="#cb1-974" aria-hidden="true" tabindex="-1"></a>of processors does not mean that this exact number of parallel runs will</span>
<span id="cb1-975"><a href="#cb1-975" aria-hidden="true" tabindex="-1"></a>be done. In practice, it is often much lower than that, as we see when</span>
<span id="cb1-976"><a href="#cb1-976" aria-hidden="true" tabindex="-1"></a>comparing the performance of our approach to $AS_0$, which runs the top</span>
<span id="cb1-977"><a href="#cb1-977" aria-hidden="true" tabindex="-1"></a>$n$ predicted solvers in parallel.</span>
<span id="cb1-978"><a href="#cb1-978" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#fig:x_Scenario_y_Solver)</span>{reference-type="ref"</span>
<span id="cb1-979"><a href="#cb1-979" aria-hidden="true" tabindex="-1"></a>reference="fig:x_Scenario_y_Solver"} shows the distribution of the</span>
<span id="cb1-980"><a href="#cb1-980" aria-hidden="true" tabindex="-1"></a>number of selected solvers for each scenario and each algorithm</span>
<span id="cb1-981"><a href="#cb1-981" aria-hidden="true" tabindex="-1"></a>selector. For RFJ, the mean number of solvers chosen for IPC2018 is</span>
<span id="cb1-982"><a href="#cb1-982" aria-hidden="true" tabindex="-1"></a>around 6.5, for MAXSAT19-UCMS around 6 (out of 7), for SAT11-INDU around</span>
<span id="cb1-983"><a href="#cb1-983" aria-hidden="true" tabindex="-1"></a>9, for SAT16-MAIN around 10, and for SAT18-EXP around 5.5. For RI, the</span>
<span id="cb1-984"><a href="#cb1-984" aria-hidden="true" tabindex="-1"></a>mean number of solvers chosen for IPC2018 is around 4.5, for</span>
<span id="cb1-985"><a href="#cb1-985" aria-hidden="true" tabindex="-1"></a>MAXSAT19-UCMS around 7 (out of 7), for SAT11-INDU around 9.5, for</span>
<span id="cb1-986"><a href="#cb1-986" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN around 10, and for SAT18-EXP around 6.5. Similarly, for RJ,</span>
<span id="cb1-987"><a href="#cb1-987" aria-hidden="true" tabindex="-1"></a>the mean number of solvers chosen for IPC2018 is around 6, for</span>
<span id="cb1-988"><a href="#cb1-988" aria-hidden="true" tabindex="-1"></a>MAXSAT19-UCMS around 6 (out of 7), for SAT11-INDU around 8, for</span>
<span id="cb1-989"><a href="#cb1-989" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN around 8, and for SAT18-EXP around 6.</span>
<span id="cb1-990"><a href="#cb1-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-991"><a href="#cb1-991" aria-hidden="true" tabindex="-1"></a>For RFJ, we see that the largest difference to the maximum number of</span>
<span id="cb1-992"><a href="#cb1-992" aria-hidden="true" tabindex="-1"></a>parallel runs occurs for the two scenarios where we observe the largest</span>
<span id="cb1-993"><a href="#cb1-993" aria-hidden="true" tabindex="-1"></a>performance improvements of our approach, IPC2018 and SAT18-EXP.</span>
<span id="cb1-994"><a href="#cb1-994" aria-hidden="true" tabindex="-1"></a>Similarly, the scenario with the highest number of solvers chosen on</span>
<span id="cb1-995"><a href="#cb1-995" aria-hidden="true" tabindex="-1"></a>average (SAT16-MAIN) is where we see the smallest performance</span>
<span id="cb1-996"><a href="#cb1-996" aria-hidden="true" tabindex="-1"></a>improvement. For RI and RJ the same comparison also exists. This clearly</span>
<span id="cb1-997"><a href="#cb1-997" aria-hidden="true" tabindex="-1"></a>shows again that the advantage of our approach is that it does not</span>
<span id="cb1-998"><a href="#cb1-998" aria-hidden="true" tabindex="-1"></a>simply use as many parallel processors as are available, which increases</span>
<span id="cb1-999"><a href="#cb1-999" aria-hidden="true" tabindex="-1"></a>overhead, but intelligently chooses how many of the available processors</span>
<span id="cb1-1000"><a href="#cb1-1000" aria-hidden="true" tabindex="-1"></a>to use for best performance. In at least some cases, more is less, and</span>
<span id="cb1-1001"><a href="#cb1-1001" aria-hidden="true" tabindex="-1"></a>we show how to leverage this.</span>
<span id="cb1-1002"><a href="#cb1-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1003"><a href="#cb1-1003" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#fig:x_Scenario_y_Solver)</span>{reference-type="ref"</span>
<span id="cb1-1004"><a href="#cb1-1004" aria-hidden="true" tabindex="-1"></a>reference="fig:x_Scenario_y_Solver"} also shows that our approach uses</span>
<span id="cb1-1005"><a href="#cb1-1005" aria-hidden="true" tabindex="-1"></a>the full range of available parallel runs in most cases, from running</span>
<span id="cb1-1006"><a href="#cb1-1006" aria-hidden="true" tabindex="-1"></a>only a single solver to as many parallel runs as there are processors.</span>
<span id="cb1-1007"><a href="#cb1-1007" aria-hidden="true" tabindex="-1"></a>Our approach is not simply a one-size-fits all that usually uses a</span>
<span id="cb1-1008"><a href="#cb1-1008" aria-hidden="true" tabindex="-1"></a>similar number of runs, but varies the size of the selected parallel</span>
<span id="cb1-1009"><a href="#cb1-1009" aria-hidden="true" tabindex="-1"></a>portfolio dynamically, based on the instance to be solved.</span>
<span id="cb1-1010"><a href="#cb1-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1011"><a href="#cb1-1011" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ranger vs RandomForest Results</span></span>
<span id="cb1-1012"><a href="#cb1-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1013"><a href="#cb1-1013" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.5</span><span class="co">](#fig:rangervsrf)</span>{reference-type="ref"</span>
<span id="cb1-1014"><a href="#cb1-1014" aria-hidden="true" tabindex="-1"></a>reference="fig:rangervsrf"} presents a comparison between the random</span>
<span id="cb1-1015"><a href="#cb1-1015" aria-hidden="true" tabindex="-1"></a>forest implementation and the ranger implementations. When comparing the</span>
<span id="cb1-1016"><a href="#cb1-1016" aria-hidden="true" tabindex="-1"></a>naive algorithm selection methods $AS (RFJ)$, $AS (RJ)$ and $AS (RI)$,</span>
<span id="cb1-1017"><a href="#cb1-1017" aria-hidden="true" tabindex="-1"></a>which select the best predicted algorithm, based on</span>
<span id="cb1-1018"><a href="#cb1-1018" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref"</span>
<span id="cb1-1019"><a href="#cb1-1019" aria-hidden="true" tabindex="-1"></a>reference="tab:summary"},&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary2)</span>{reference-type="ref"</span>
<span id="cb1-1020"><a href="#cb1-1020" aria-hidden="true" tabindex="-1"></a>reference="tab:summary2"} and&nbsp;<span class="co">[</span><span class="ot">1.5</span><span class="co">](#tab:summary3)</span>{reference-type="ref"</span>
<span id="cb1-1021"><a href="#cb1-1021" aria-hidden="true" tabindex="-1"></a>reference="tab:summary3"}, the RFJ model emerges as a more promising</span>
<span id="cb1-1022"><a href="#cb1-1022" aria-hidden="true" tabindex="-1"></a>algorithm selector in all scenarios except IPC2018, where the RJ model</span>
<span id="cb1-1023"><a href="#cb1-1023" aria-hidden="true" tabindex="-1"></a>performs slightly better in terms of runtime and MCP. For SAT11-INDU,</span>
<span id="cb1-1024"><a href="#cb1-1024" aria-hidden="true" tabindex="-1"></a>the $AS (RFJ)$ method is superior in terms of runtime and MCP, but</span>
<span id="cb1-1025"><a href="#cb1-1025" aria-hidden="true" tabindex="-1"></a>performs slightly worse than the RI model in terms of PAR10.</span>
<span id="cb1-1026"><a href="#cb1-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1027"><a href="#cb1-1027" aria-hidden="true" tabindex="-1"></a>When we compare $AS_{0} (RFJ)$, $AS_{0} (RJ)$, and $AS_{0} (RI)$, which</span>
<span id="cb1-1028"><a href="#cb1-1028" aria-hidden="true" tabindex="-1"></a>select the top predicted algorithms to run in parallel, the performance</span>
<span id="cb1-1029"><a href="#cb1-1029" aria-hidden="true" tabindex="-1"></a>of these methods is very competitive. In some cases, the RI model</span>
<span id="cb1-1030"><a href="#cb1-1030" aria-hidden="true" tabindex="-1"></a>performs better, such as in SAT18-EXP and SAT11-INDU, across all</span>
<span id="cb1-1031"><a href="#cb1-1031" aria-hidden="true" tabindex="-1"></a>metrics, and is superior only in terms of runtime and MCP in SAT16-MAIN.</span>
<span id="cb1-1032"><a href="#cb1-1032" aria-hidden="true" tabindex="-1"></a>In other cases, the RFJ model performs better, as seen in IPC2018. For</span>
<span id="cb1-1033"><a href="#cb1-1033" aria-hidden="true" tabindex="-1"></a>MAXSAT19-UCMS, all algorithm selectors perform equally, as with</span>
<span id="cb1-1034"><a href="#cb1-1034" aria-hidden="true" tabindex="-1"></a>$p_{\cap} = 0$, all 7 available solvers are selected.</span>
<span id="cb1-1035"><a href="#cb1-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1036"><a href="#cb1-1036" aria-hidden="true" tabindex="-1"></a>When comparing the methods using a tuned value of $p_{\cap}$, denoted as</span>
<span id="cb1-1037"><a href="#cb1-1037" aria-hidden="true" tabindex="-1"></a>$AS_{p_{\cap}}$, the RI model outperformed the others in most cases. In</span>
<span id="cb1-1038"><a href="#cb1-1038" aria-hidden="true" tabindex="-1"></a>IPC2018 and SAT11-INDU, it was superior in terms of runtime, MCP, and</span>
<span id="cb1-1039"><a href="#cb1-1039" aria-hidden="true" tabindex="-1"></a>PAR10. For SAT16-MAIN, it outperformed the other two in terms of MCP and</span>
<span id="cb1-1040"><a href="#cb1-1040" aria-hidden="true" tabindex="-1"></a>runtime, although the PAR10 of RFJ was slightly better. For</span>
<span id="cb1-1041"><a href="#cb1-1041" aria-hidden="true" tabindex="-1"></a>MAXSAT19-UCMS and SAT18-EXP, the RFJ model performed better than the</span>
<span id="cb1-1042"><a href="#cb1-1042" aria-hidden="true" tabindex="-1"></a>others across all performance metrics. It is worth mentioning that the</span>
<span id="cb1-1043"><a href="#cb1-1043" aria-hidden="true" tabindex="-1"></a>RJ model could not beat other models in the $AS_{p_{\cap}}$ method.</span>
<span id="cb1-1044"><a href="#cb1-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1045"><a href="#cb1-1045" aria-hidden="true" tabindex="-1"></a>These comparisons is based on the runtime, MCP, and PAR10 scores listed</span>
<span id="cb1-1046"><a href="#cb1-1046" aria-hidden="true" tabindex="-1"></a>in Tables&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary)</span>{reference-type="ref"</span>
<span id="cb1-1047"><a href="#cb1-1047" aria-hidden="true" tabindex="-1"></a>reference="tab:summary"}, <span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary2)</span>{reference-type="ref"</span>
<span id="cb1-1048"><a href="#cb1-1048" aria-hidden="true" tabindex="-1"></a>reference="tab:summary2"}, and <span class="co">[</span><span class="ot">1.5</span><span class="co">](#tab:summary3)</span>{reference-type="ref"</span>
<span id="cb1-1049"><a href="#cb1-1049" aria-hidden="true" tabindex="-1"></a>reference="tab:summary3"}. As shown in</span>
<span id="cb1-1050"><a href="#cb1-1050" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.5</span><span class="co">](#fig:rangervsrf)</span>{reference-type="ref"</span>
<span id="cb1-1051"><a href="#cb1-1051" aria-hidden="true" tabindex="-1"></a>reference="fig:rangervsrf"}, a similar comparison exists, with the</span>
<span id="cb1-1052"><a href="#cb1-1052" aria-hidden="true" tabindex="-1"></a>values representing the PAR10 score normalized gap closed between SBS</span>
<span id="cb1-1053"><a href="#cb1-1053" aria-hidden="true" tabindex="-1"></a>and VBS. In this context, $AS_{p_{\cap}} (RI)$ is superior in three out</span>
<span id="cb1-1054"><a href="#cb1-1054" aria-hidden="true" tabindex="-1"></a>of five scenarios, while $AS_{p_{\cap}} (RFJ)$ performs best in the</span>
<span id="cb1-1055"><a href="#cb1-1055" aria-hidden="true" tabindex="-1"></a>remaining two scenarios. Although using RI for single algorithm</span>
<span id="cb1-1056"><a href="#cb1-1056" aria-hidden="true" tabindex="-1"></a>selection performed the worst, it appears to be a better model for</span>
<span id="cb1-1057"><a href="#cb1-1057" aria-hidden="true" tabindex="-1"></a>applying the portfolio selection approach.</span>
<span id="cb1-1058"><a href="#cb1-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1059"><a href="#cb1-1059" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:rangervsrf"&gt;</span>
<span id="cb1-1060"><a href="#cb1-1060" aria-hidden="true" tabindex="-1"></a>&lt;embed</span>
<span id="cb1-1061"><a href="#cb1-1061" aria-hidden="true" tabindex="-1"></a>src="plots/learner_comparison_line_chart_parallel_NormalizedGap.svg" style="width:95.0%"/&gt;</span>
<span id="cb1-1062"><a href="#cb1-1062" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt; Results Overview. The plot illustrates the extent to which</span>
<span id="cb1-1063"><a href="#cb1-1063" aria-hidden="true" tabindex="-1"></a>each method narrows the gap between the PAR10 scores of the Single Best</span>
<span id="cb1-1064"><a href="#cb1-1064" aria-hidden="true" tabindex="-1"></a>Solver (SBS) and the Virtual Best Solver (VBS). For VBS and SBS, the top</span>
<span id="cb1-1065"><a href="#cb1-1065" aria-hidden="true" tabindex="-1"></a>&lt;span class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; solvers are selected, where &lt;span</span>
<span id="cb1-1066"><a href="#cb1-1066" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; matches the number of processors</span>
<span id="cb1-1067"><a href="#cb1-1067" aria-hidden="true" tabindex="-1"></a>available for each problem instance and across all instances,</span>
<span id="cb1-1068"><a href="#cb1-1068" aria-hidden="true" tabindex="-1"></a>respectively. &lt;span class="math inline"&gt;<span class="sc">\(</span>AS_0<span class="sc">\)</span>&lt;/span&gt; selects the top</span>
<span id="cb1-1069"><a href="#cb1-1069" aria-hidden="true" tabindex="-1"></a>&lt;span class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; solvers as predicted by algorithm</span>
<span id="cb1-1070"><a href="#cb1-1070" aria-hidden="true" tabindex="-1"></a>selection, disregarding any overlap in their predicted runtime</span>
<span id="cb1-1071"><a href="#cb1-1071" aria-hidden="true" tabindex="-1"></a>distributions. &lt;span class="math inline"&gt;<span class="sc">\(</span>AS_{p_{\cap}}<span class="sc">\)</span>&lt;/span&gt;</span>
<span id="cb1-1072"><a href="#cb1-1072" aria-hidden="true" tabindex="-1"></a>follows the approach proposed in &lt;span class="citation"</span>
<span id="cb1-1073"><a href="#cb1-1073" aria-hidden="true" tabindex="-1"></a>data-cites="kashgarani2023automatic"&gt;&lt;/span&gt;, with the number of</span>
<span id="cb1-1074"><a href="#cb1-1074" aria-hidden="true" tabindex="-1"></a>processors capped at the specific value on the x-axis — fewer solvers</span>
<span id="cb1-1075"><a href="#cb1-1075" aria-hidden="true" tabindex="-1"></a>than this maximum may be selected based on the overlap in runtime</span>
<span id="cb1-1076"><a href="#cb1-1076" aria-hidden="true" tabindex="-1"></a>predictions. The RFJ model is trained with the randomForest and</span>
<span id="cb1-1077"><a href="#cb1-1077" aria-hidden="true" tabindex="-1"></a>Jackknife method, RI uses the Ranger model with the Infinitesimal</span>
<span id="cb1-1078"><a href="#cb1-1078" aria-hidden="true" tabindex="-1"></a>Jackknife method, and RJ applies the Ranger model with the Jackknife</span>
<span id="cb1-1079"><a href="#cb1-1079" aria-hidden="true" tabindex="-1"></a>method. The optimal &lt;span class="math inline"&gt;<span class="sc">\(</span>p_{\cap}<span class="sc">\)</span>&lt;/span&gt; values</span>
<span id="cb1-1080"><a href="#cb1-1080" aria-hidden="true" tabindex="-1"></a>for each scenario and each model are listed in Table&nbsp;&lt;a href="#tab:pcap"</span>
<span id="cb1-1081"><a href="#cb1-1081" aria-hidden="true" tabindex="-1"></a>data-reference-type="ref" data-reference="tab:pcap"&gt;1.2&lt;/a&gt;.</span>
<span id="cb1-1082"><a href="#cb1-1082" aria-hidden="true" tabindex="-1"></a>&lt;/figcaption&gt;</span>
<span id="cb1-1083"><a href="#cb1-1083" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-1084"><a href="#cb1-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1085"><a href="#cb1-1085" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusions and Future Work</span></span>
<span id="cb1-1086"><a href="#cb1-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1087"><a href="#cb1-1087" aria-hidden="true" tabindex="-1"></a>In this study, we proposed a general method for selecting solvers from a</span>
<span id="cb1-1088"><a href="#cb1-1088" aria-hidden="true" tabindex="-1"></a>portfolio of solvers and scheduling them in parallel, taking into</span>
<span id="cb1-1089"><a href="#cb1-1089" aria-hidden="true" tabindex="-1"></a>account the predicted runtime distribution to intelligently choose not</span>
<span id="cb1-1090"><a href="#cb1-1090" aria-hidden="true" tabindex="-1"></a>only which solvers to run, but also how many. This is in contrast to</span>
<span id="cb1-1091"><a href="#cb1-1091" aria-hidden="true" tabindex="-1"></a>most other approaches in the literature, which either choose a constant</span>
<span id="cb1-1092"><a href="#cb1-1092" aria-hidden="true" tabindex="-1"></a>number or use all available processors. Further, we measured the actual</span>
<span id="cb1-1093"><a href="#cb1-1093" aria-hidden="true" tabindex="-1"></a>runtime when running more than one algorithm in parallel, rather than</span>
<span id="cb1-1094"><a href="#cb1-1094" aria-hidden="true" tabindex="-1"></a>assuming the sequential runtime. We demonstrated substantial performance</span>
<span id="cb1-1095"><a href="#cb1-1095" aria-hidden="true" tabindex="-1"></a>improvements across a wide range of scenarios, handily beating baseline</span>
<span id="cb1-1096"><a href="#cb1-1096" aria-hidden="true" tabindex="-1"></a>methods and other approaches from the literature. The proposed method</span>
<span id="cb1-1097"><a href="#cb1-1097" aria-hidden="true" tabindex="-1"></a>establishes a new state of the art in parallel algorithm selection and</span>
<span id="cb1-1098"><a href="#cb1-1098" aria-hidden="true" tabindex="-1"></a>is simple to apply in practice -- we are only using information that is</span>
<span id="cb1-1099"><a href="#cb1-1099" aria-hidden="true" tabindex="-1"></a>readily available in common algorithm selection methods, and while for</span>
<span id="cb1-1100"><a href="#cb1-1100" aria-hidden="true" tabindex="-1"></a>the best performance the parameter $p_{\cap}$ of our method should be</span>
<span id="cb1-1101"><a href="#cb1-1101" aria-hidden="true" tabindex="-1"></a>tuned, a reasonable default already shows good performance. This</span>
<span id="cb1-1102"><a href="#cb1-1102" aria-hidden="true" tabindex="-1"></a>parameter allows our method to be tailored to specific application</span>
<span id="cb1-1103"><a href="#cb1-1103" aria-hidden="true" tabindex="-1"></a>domains and scenarios. We also compared three different algorithm</span>
<span id="cb1-1104"><a href="#cb1-1104" aria-hidden="true" tabindex="-1"></a>performance models, specifically three variations of the regression</span>
<span id="cb1-1105"><a href="#cb1-1105" aria-hidden="true" tabindex="-1"></a>random forest, and applied the method to evaluate their effectiveness.</span>
<span id="cb1-1106"><a href="#cb1-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1107"><a href="#cb1-1107" aria-hidden="true" tabindex="-1"></a>While we do show substantial performance improvements, there is room for</span>
<span id="cb1-1108"><a href="#cb1-1108" aria-hidden="true" tabindex="-1"></a>further advances. We have focused our investigation on state-of-the-art</span>
<span id="cb1-1109"><a href="#cb1-1109" aria-hidden="true" tabindex="-1"></a>random forest performance models, the jackknife and infinitesimal</span>
<span id="cb1-1110"><a href="#cb1-1110" aria-hidden="true" tabindex="-1"></a>jackknife method for estimating uncertainties. It is possible that other</span>
<span id="cb1-1111"><a href="#cb1-1111" aria-hidden="true" tabindex="-1"></a>types of models may perform better in this context if the uncertainty</span>
<span id="cb1-1112"><a href="#cb1-1112" aria-hidden="true" tabindex="-1"></a>estimates of their predictions are better. It is also possible to</span>
<span id="cb1-1113"><a href="#cb1-1113" aria-hidden="true" tabindex="-1"></a>combine different types of performance models for different algorithms,</span>
<span id="cb1-1114"><a href="#cb1-1114" aria-hidden="true" tabindex="-1"></a>allowing much more flexibility and potentially greater performance</span>
<span id="cb1-1115"><a href="#cb1-1115" aria-hidden="true" tabindex="-1"></a>improvements. While our baseline method that allocates resources to each</span>
<span id="cb1-1116"><a href="#cb1-1116" aria-hidden="true" tabindex="-1"></a>algorithm did not perform well, investigating more sophisticated</span>
<span id="cb1-1117"><a href="#cb1-1117" aria-hidden="true" tabindex="-1"></a>approaches for this would also be interesting.</span>
<span id="cb1-1118"><a href="#cb1-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1119"><a href="#cb1-1119" aria-hidden="true" tabindex="-1"></a>Furthermore, the optimal values of $p_{\cap}$ varied significantly</span>
<span id="cb1-1120"><a href="#cb1-1120" aria-hidden="true" tabindex="-1"></a>between different scenarios and performance models, requiring tuning for</span>
<span id="cb1-1121"><a href="#cb1-1121" aria-hidden="true" tabindex="-1"></a>each. This can increase the complexity of the algorithm selection</span>
<span id="cb1-1122"><a href="#cb1-1122" aria-hidden="true" tabindex="-1"></a>process, as well as the computational effort and time required for</span>
<span id="cb1-1123"><a href="#cb1-1123" aria-hidden="true" tabindex="-1"></a>method configuration, since each scenario needs specific adjustments to</span>
<span id="cb1-1124"><a href="#cb1-1124" aria-hidden="true" tabindex="-1"></a>achieve optimal performance.</span>
<span id="cb1-1125"><a href="#cb1-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1126"><a href="#cb1-1126" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>For SAT11-INDU, the ASlib benchmark repository contains 115</span>
<span id="cb1-1127"><a href="#cb1-1127" aria-hidden="true" tabindex="-1"></a>    extracted features, including those from SATZilla. However, we were</span>
<span id="cb1-1128"><a href="#cb1-1128" aria-hidden="true" tabindex="-1"></a>    unable to find the feature extraction for this scenario and used the</span>
<span id="cb1-1129"><a href="#cb1-1129" aria-hidden="true" tabindex="-1"></a>    same 54 instance features extracted by SATZilla.</span>
<span id="cb1-1130"><a href="#cb1-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1131"><a href="#cb1-1131" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: https://github.com/uwyo-mallet/llama-mlr3</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="https://haniyeka.github.io">Website</a> | <a href="https://github.com/haniyeka">GitHub</a> | <a href="https://github.com/uwyo-mallet">UWYO-Mallet</a></p>
</div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>