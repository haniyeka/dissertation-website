<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Parallel Portfolio Selection with Parallel Data Training – Dynamic Selection of Parallel Portfolio of Algorithms for Solving Combinatorial Problems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter7/DiscussionandConclusion.html" rel="next">
<link href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-8eef5ae80df721a84869b784b4d5419f.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-812d013f591176c02f613616752f8d70.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter6/ParallelPortfolioSelectionwithParallelDataTraining.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Parallel Portfolio Selection with Parallel Data Training</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Dynamic Selection of Parallel Portfolio of Algorithms for Solving Combinatorial Problems</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/haniyeka/dissertation-website" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Abstract</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/Background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Background</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/IsAlgorithmSelectionWorthItComparingSelectingSingleAlgorithmsandParallelExecution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter4/AutomaticParallelPortfolioSelection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic Parallel Portfolio Selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Revisiting Parallel Portfolio Selection with KL Divergence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter6/ParallelPortfolioSelectionwithParallelDataTraining.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Parallel Portfolio Selection with Parallel Data Training</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter7/DiscussionandConclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Discussion and Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/appendixA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Appendix</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">7.1</span> Introduction</a></li>
  <li><a href="#training-performance-modeling-with-parallel-data" id="toc-training-performance-modeling-with-parallel-data" class="nav-link" data-scroll-target="#training-performance-modeling-with-parallel-data"><span class="header-section-number">7.2</span> Training Performance Modeling with Parallel Data</a>
  <ul class="collapse">
  <li><a href="#parallel-portfolio-selection" id="toc-parallel-portfolio-selection" class="nav-link" data-scroll-target="#parallel-portfolio-selection"><span class="header-section-number">7.2.1</span> Parallel Portfolio Selection</a></li>
  </ul></li>
  <li><a href="#experimental-setup" id="toc-experimental-setup" class="nav-link" data-scroll-target="#experimental-setup"><span class="header-section-number">7.3</span> Experimental Setup</a>
  <ul class="collapse">
  <li><a href="#data-collection" id="toc-data-collection" class="nav-link" data-scroll-target="#data-collection"><span class="header-section-number">7.3.1</span> Data Collection</a></li>
  <li><a href="#training-and-tuning" id="toc-training-and-tuning" class="nav-link" data-scroll-target="#training-and-tuning"><span class="header-section-number">7.3.2</span> Training and Tuning</a></li>
  <li><a href="#baselines" id="toc-baselines" class="nav-link" data-scroll-target="#baselines"><span class="header-section-number">7.3.3</span> Baselines</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">7.4</span> Results</a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions"><span class="header-section-number">7.5</span> Conclusions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Parallel Portfolio Selection with Parallel Data Training</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">7.1</span> Introduction</h2>
<p>Combinatorial problem solvers often exhibit complementary performance when solving given problem instances. The use of algorithms portfolios has proven to be more effective than choosing the best single solver (SBS) averaged across all instances <span class="citation" data-cites="Huberman1997 GOMES200143">(<a href="#ref-Huberman1997" role="doc-biblioref">Huberman, Lukose, and Hogg 1997</a>; <a href="#ref-GOMES200143" role="doc-biblioref">Gomes and Selman 2001</a>)</span>. Different portfolio approaches and designs are presented in the literature. Entire portfolios can be run in parallel or a single algorithm can be selected instance by instance using algorithm selection techniques.</p>
<p>This selection-based approach is often addressed by training performance models using machine learning algorithms and instance features <span class="citation" data-cites="Kotthoff2014 10.1162/evco_a_00242">(<a href="#ref-Kotthoff2014" role="doc-biblioref">Kotthoff 2014</a>; <a href="#ref-10.1162/evco_a_00242" role="doc-biblioref">Kerschke et al. 2019</a>)</span>. One drawback of this approach is that since no machine learning model is perfect, the selections might be incorrect, and performance models might not always be able to select the best algorithm for a given instance. This means that selecting the wrong algorithm can waste time and resources.</p>
<p>Since the hardware architecture of modern computing units can handle multiple tasks in parallel, another portfolio approach is to execute the entire portfolio simultaneously. This approach avoids the drawback of algorithm selection, as the actual best solver will always be included in the portfolio and executed alongside other algorithms. However, running too many solvers in parallel can lead to resource wastage by overloading computing processors. Additionally, this method can introduce significant overhead, as solvers and cores compete for shared resources when too many solvers are executed simultaneously. The more algorithms executed in parallel, the greater the risk of time-out computations and overhead. The preliminary results presented in Chapter 3 <span class="citation" data-cites="pmlr-v140-kashgarani21a">(<a href="#ref-pmlr-v140-kashgarani21a" role="doc-biblioref">Kashgarani and Kotthoff 2021</a>)</span> showed that, while the selection of a single algorithm is suboptimal and imperfect, it performs better than running too many solvers in parallel.</p>
<p>In Chapter 4, we proposed a hybrid approach that combines the benefits of algorithm selection and parallel execution. We further extend this method to a variation that performs competitively with the original approach in Chapter 5. These "middle-path" methods aim to select the most promising subset of algorithms to run in parallel on a single non-distributed computing node <span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>. These promising methods optimized performance by utilizing regression-based random forest algorithm selectors, incorporating the estimated uncertainty of predictions, and accounting for the overhead associated with parallel portfolio execution. However, these approaches were tested using performance models trained on sequential data, which do not account for the overhead associated with parallel execution.</p>
<p>In this chapter, instead of relying on regression random forest models trained on sequential data, we train performance models using actual parallel data. We then compare algorithm selectors trained on sequential data with those trained on parallel data, applying the method proposed in Chapter 4 for parallel portfolio selection. By evaluating the effectiveness of these two types of algorithm selector in portfolio selection, we investigate whether collecting parallel data provides a significant advantage or whether sequential data are equally effective.</p>
</section>
<section id="training-performance-modeling-with-parallel-data" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="training-performance-modeling-with-parallel-data"><span class="header-section-number">7.2</span> Training Performance Modeling with Parallel Data</h2>
<p>In the paper Chapter 4 and 5<span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>, we used data collected from running a single solver exclusively on a computing node to train the regression-based random forest model. This data does not account for parallelization or the overhead associated with running multiple solvers concurrently. Although this approach has proven effective, since we have already collected parallel data, we now aim to investigate the efficiency of training the performance model using these parallel data as well. Specifically, we focus on training performance models on parallel data. These parallel data are gathered by running solvers in parallel alongside other solvers, with varying numbers of solvers executed simultaneously on a single, exclusive computing node ensuring that no other tasks interfere with the recorded runtimes.</p>
<p>In this approach, for scenarios such as SAT11-NDU, SAT18-EXP, SAT16-MAIN, and IPC2018, where data are available for up to 10 parallel runs, we trained 10 distinct performance models, each tailored to a specific level of parallelization. Similarly, for MAXSAT2019, which includes data for up to 7 parallel runs, we trained 7 separate models, each trained for a given parallel run level. This means that the performance model, trained on data collected from running <span class="math inline">\(n\)</span> parallel runs, is used to predict the performance of a solver when running <span class="math inline">\(n\)</span> parallel runs.</p>
<section id="parallel-portfolio-selection" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="parallel-portfolio-selection"><span class="header-section-number">7.2.1</span> Parallel Portfolio Selection</h3>
<p>Algorithm performance for combinatorial problems varies widely between instances, and portfolio approaches that use machine learning-based algorithm selection aim to optimize performance by selecting the best algorithms to execute while minimizing overhead from concurrent execution. Algorithm selection has been effective in domains like SAT and mixed integer programming. However, selecting a single algorithm can sometimes lead to suboptimal outcomes due to inaccurate predictions. This issue can be addressed by selecting a small subset of algorithms to run in parallel, which mitigates prediction inaccuracies while reducing overhead and resource demands.</p>
<p>We follow the methods and equations outlined in Chapter 4 as described in&nbsp;<span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>. We do not include the subportfolio selection method using KL divergence, as it consistently performed worse than the method proposed in Chapter 4. The selection approach in Chapter 4 aims to select a subportfolio of solvers to run in parallel for a given problem instance by leveraging predicted performance rankings. Solvers are ranked according to their predicted performance metric, forming a total order, and a subset of size <span class="math inline">\(n\)</span> is selected from the top-ranked solvers. The key challenge is determining the optimal portfolio size <span class="math inline">\(n\)</span>, as including too many algorithms increases the chance of including the best solver but also introduces significant overhead from running solvers in parallel. To address this, the method incorporates a probabilistic approach using the predicted performance distribution of each solver.</p>
<p>Rather than relying on point predictions, the method uses the predicted performance distributions and extends typical algorithm selection practices by incorporating uncertainty of performance predictions. We assume that predictions follow a normal distribution characterized by their mean and standard deviation. The overlap between these distributions is used to compute the likelihood that a solver performs comparably to the best-predicted solver. A threshold parameter, <span class="math inline">\(p_{\cap}\)</span>, controls the size of the parallel portfolio by including solvers whose distributions overlap sufficiently with that of the best solver. This approach balances the trade-off between including solvers that might achieve optimal performance and limiting computational overhead, providing a flexible and robust framework for parallel portfolio selection.</p>
<p>As in previous chapters, we used regression random forests as the algorithm selector, identified as the best performing approach in the ASLib study <span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>. Furthermore, we transitioned from using a model trained exclusively on sequential data to one trained on sequential and parallel data to assess their comparative effectiveness. Through this approach and our experiments, we sought to optimize the utilization of parallel computational resources for solving combinatorial problems while minimizing the overhead associated with parallel execution.</p>
</section>
</section>
<section id="experimental-setup" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="experimental-setup"><span class="header-section-number">7.3</span> Experimental Setup</h2>
<section id="data-collection" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="data-collection"><span class="header-section-number">7.3.1</span> Data Collection</h3>
<p>We used the same five scenarios from previous chapters <span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>, all now included in the ASlib benchmark repository <span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>: MAXSAT19-UCMS, SAT11-INDU, SAT18-EXP, SAT16-MAIN, and IPC2018. Although the ASlib data repository only provides performance data for single runs, we incorporated parallel run measurements from <span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>, performed on standalone machines. For MAXSAT19-UCMS, SAT11-INDU, SAT16-MAIN, and SAT18-EXP, 54 features are computed using the SATZilla feature extraction code <span class="citation" data-cites="satzilla">(<a href="#ref-satzilla" role="doc-biblioref">Xu et al. 2008</a>)</span>. For IPC2018, feature extraction tool by <span class="citation" data-cites="Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014">(<a href="#ref-Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014" role="doc-biblioref">Fawcett et al. 2014</a>)</span> generated 305 features. The scenarios, data and features of our experiments align with those used in <span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>, as summarized in Table&nbsp;<a href="#tab:scenarios6" data-reference-type="ref" data-reference="tab:scenarios6">1.1</a>.</p>
<p>The data were collected on compute nodes with 32 processors, a 40 MB cache (Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz), and 128 GB of memory, running Red Hat Linux version 8.6. We adhered to the ASlib time limits: 5000 CPU seconds for SAT18-EXP, SAT11-INDU, and SAT16-MAIN; 3600 seconds for MAXSAT19-UCMS; and 1800 seconds for IPC2018. Each algorithm was individually executed over 2 to 10 parallel runs during data collection.</p>
<div id="tab:scenarios6">
<table class="caption-top table">
<caption>Number of Algorithms, Instances, and Features Across All Scenarios.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Scenario</th>
<th style="text-align: center;">Algorithms</th>
<th style="text-align: center;">Instances</th>
<th style="text-align: center;">Instance Features</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">IPC2018</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">240</td>
<td style="text-align: center;">305</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">MAXSAT19-UCMS</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">572</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT11-INDU</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">300</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">SAT16-MAIN</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">274</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT18-EXP</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">353</td>
<td style="text-align: center;">54</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="training-and-tuning" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="training-and-tuning"><span class="header-section-number">7.3.2</span> Training and Tuning</h3>
<p>We constructed random forest regression models using the Ranger implementation from the MLR3 package <span class="citation" data-cites="ranger">(<a href="#ref-ranger" role="doc-biblioref">Wright and Ziegler 2017</a>)</span> in R to predict the algorithm performance in specific instances. Although we previously presented results from various random forest implementations in R, this chapter focuses exclusively on Ranger models to compare the performance of models trained on sequential data with those trained on parallel data. Our setup closely follows the methodology outlined in Chapter 4 and in <span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>: we excluded instance features with constant values and imputed missing feature values using the mean of all nonmissing values for each feature. The random forest hyperparameters were optimized using random search with 250 iterations, varying <span class="math inline">\(ntree\)</span> between 10 and 200 and mtry between 1 and 30. Nested cross-validation with three inner folds and ten outer folds was used for model evaluation <span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>.</p>
<p>For training the models with parallel data, we trained 10 models for the SAT11-INDU, SAT16-MAIN, SAT18-EXP, and IPC2018 scenarios, and 7 models for the MAXSAT19-UCMS scenario, as only 7 solvers are available for this benchmark. Each model was trained using the runtimes associated with its specific parallel configuration. For instance, we trained one performance model using the runtimes of algorithms running in parallel with 2 other solvers, another model using the data collected when running 3 solvers in parallel, and so forth.</p>
<p>Our random forest regression models, built with the MLR3 and Ranger packages, predict solver runtime as the mean of the underlying distribution and estimate the standard deviation using the Jackknife and Infinitesimal Jackknife methods <span class="citation" data-cites="wager2014confidence mlr">(<a href="#ref-wager2014confidence" role="doc-biblioref">Wager, Hastie, and Efron 2014</a>; <a href="#ref-mlr" role="doc-biblioref">Bischl, Lang, et al. 2016</a>)</span>. The Jackknife method calculates the standard deviation of the mean predictions in all training observations. In this approach, the random forest model is trained on <span class="math inline">\(n-1\)</span> observations, leaving one out for prediction, and this process is repeated for each observation. The mean prediction for each tree is calculated by averaging its predictions for the left-out observations. The Jackknife method assumes a normal distribution of the predictions, where the standard deviation quantifies the uncertainty of the overall prediction. The Infinitesimal Jackknife method, rather than completely removing observations, assigns them a small weight to account for their influence on the model.</p>
<p>The tuned <span class="math inline">\(p_{\cap}\)</span> values of Equation&nbsp;<a href="#eq:7" data-reference-type="ref" data-reference="eq:7">[eq:7]</a> for each benchmark and model are provided in Table <a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">[tab:pcap]</a>. These values were individually optimized for each scenario to ensure that the selected portfolio achieved an optimal balance between performance and computational efficiency.</p>
<p>We first compare the predictions of the performance models trained on sequential data with those trained on data collected under different levels of parallelism. The analysis was performed using the McNemar test to assess whether there are significant differences in predictive performance between the sequential and parallel models in various scenarios. For each scenario, models trained on sequential data were compared with models trained on parallel data, involving varying numbers of parallel runs, ranging from 2 to the maximum number of solvers available for each scenario. We used contingency tables to capture the outcomes: instances where both models made correct or incorrect predictions and instances where one model succeeded while the other failed. The McNemar test provided p-values and test statistics for each comparison. The resulting <span class="math inline">\(p-values\)</span> indicate significant differences between the predictions of sequential and parallel models across all with significant level <span class="math inline">\(\alpha = 0.05\)</span> configurations. For example, in the MAXSAT2019 scenario, the <span class="math inline">\(p-value\)</span> for models trained with 2 parallel runs was <span class="math inline">\(2.51e-8\)</span>, highlighting substantial differences in their predictions compared to sequential models. Similar trends were observed in other scenarios, such as IPC2018 and SAT18-EXP, where p-values remained very low at different levels of parallelism. These results demonstrate that the predictions of sequential models are notably distinct from those of parallel models, with significant differences observed in most scenarios and configurations.</p>
<p>Although the McNemar tests showed that the predictions are significantly different, we further investigated the Critical Difference (CD). CD analysis reveals that while the predictions of algorithm selectors trained in sequential and parallel data may vary, their ranking among the models on the five benchmarks is not significantly different at <span class="math inline">\(\alpha = 0.05\)</span>. Using a critical difference value of 6.06 (calculated for 10 models and 5 datasets), the CD diagram in Figure&nbsp;<a href="#fig:critical" data-reference-type="ref" data-reference="fig:critical">1.1</a> confirms that the variations in average ranks fall within the nonsignificant range. For instance, the average ranks of the models show minor differences across parallel configurations (e.g., the Sequential model has an average rank of 4.11 compared to the "10 parallel runs" model with 6.12), but these differences do not exceed the CD threshold. The rankings of the average ranks matrix in Table&nbsp;<a href="#tab:rank_mat" data-reference-type="ref" data-reference="tab:rank_mat">1.3</a> highlight consistent algorithm selection performance trends in datasets such as MAXSAT2019, IPC2018, SAT11-INDU, SAT16-MAIN and SAT18-EXP. Although individual rankings may differ slightly between scenarios, the overall rankings do not exhibit significant divergence. This suggests that algorithm selectors, whether trained in sequential or parallel data, produce models that rank algorithms similarly in terms of performance when evaluated across multiple datasets.</p>
<p><span id="tab:scenarios2" data-label="tab:scenarios2"></span></p>
<div id="tab:scenarios2">
<table class="caption-top table">
<caption>P-values for McNemar tests comparing models trained on parallel data with the model trained on sequential data. The McNemar tests were conducted by selecting the top single solver based on the performance model and constructing the corresponding 2x2 contingency matrix.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Model</th>
<th style="text-align: center;">MAXSAT19-UCMS</th>
<th style="text-align: center;">IPC2018</th>
<th style="text-align: center;">SAT11-INDU</th>
<th style="text-align: center;">SAT16-MAIN</th>
<th style="text-align: center;">SAT18-EXP</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2 parallel runs</td>
<td style="text-align: center;">2.51e-08</td>
<td style="text-align: center;">3.39e-02</td>
<td style="text-align: center;">4.53e-03</td>
<td style="text-align: center;">4.54e-04</td>
<td style="text-align: center;">6.17e-04</td>
</tr>
<tr class="even">
<td style="text-align: left;">3 parallel runs</td>
<td style="text-align: center;">2.19e-06</td>
<td style="text-align: center;">4.89e-03</td>
<td style="text-align: center;">2.85e-02</td>
<td style="text-align: center;">1.42e-03</td>
<td style="text-align: center;">2.29e-04</td>
</tr>
<tr class="odd">
<td style="text-align: left;">4 parallel runs</td>
<td style="text-align: center;">3.97e-04</td>
<td style="text-align: center;">9.51e-04</td>
<td style="text-align: center;">1.05e-03</td>
<td style="text-align: center;">1.26e-03</td>
<td style="text-align: center;">2.97e-04</td>
</tr>
<tr class="even">
<td style="text-align: left;">5 parallel runs</td>
<td style="text-align: center;">3.15e-05</td>
<td style="text-align: center;">1.39e-03</td>
<td style="text-align: center;">5.66e-03</td>
<td style="text-align: center;">1.56e-03</td>
<td style="text-align: center;">7.66e-04</td>
</tr>
<tr class="odd">
<td style="text-align: left;">6 parallel runs</td>
<td style="text-align: center;">8.25e-04</td>
<td style="text-align: center;">5.85e-03</td>
<td style="text-align: center;">4.01e-03</td>
<td style="text-align: center;">9.37e-04</td>
<td style="text-align: center;">3.83e-04</td>
</tr>
<tr class="even">
<td style="text-align: left;">7 parallel runs</td>
<td style="text-align: center;">3.80e-03</td>
<td style="text-align: center;">8.97e-03</td>
<td style="text-align: center;">3.68e-02</td>
<td style="text-align: center;">3.82e-03</td>
<td style="text-align: center;">6.14e-06</td>
</tr>
<tr class="odd">
<td style="text-align: left;">8 parallel runs</td>
<td style="text-align: center;">–</td>
<td style="text-align: center;">4.65e-04</td>
<td style="text-align: center;">1.13e-03</td>
<td style="text-align: center;">1.76e-04</td>
<td style="text-align: center;">6.85e-06</td>
</tr>
<tr class="even">
<td style="text-align: left;">9 parallel runs</td>
<td style="text-align: center;">–</td>
<td style="text-align: center;">4.07e-04</td>
<td style="text-align: center;">4.67e-02</td>
<td style="text-align: center;">1.09e-03</td>
<td style="text-align: center;">1.28e-04</td>
</tr>
<tr class="odd">
<td style="text-align: left;">10 parallel runs</td>
<td style="text-align: center;">–</td>
<td style="text-align: center;">2.16e-04</td>
<td style="text-align: center;">5.07e-03</td>
<td style="text-align: center;">1.09e-03</td>
<td style="text-align: center;">2.28e-05</td>
</tr>
</tbody>
</table>
</div>
<div id="tab:rank_mat">
<table class="caption-top table">
<caption>Ranking Matrix for Critical Difference</caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><strong>Seq.</strong></th>
<th style="text-align: center;"><strong>2p</strong></th>
<th style="text-align: center;"><strong>3p</strong></th>
<th style="text-align: center;"><strong>4p</strong></th>
<th style="text-align: center;"><strong>5p</strong></th>
<th style="text-align: center;"><strong>6p</strong></th>
<th style="text-align: center;"><strong>7p</strong></th>
<th style="text-align: center;"><strong>8p</strong></th>
<th style="text-align: center;"><strong>9p</strong></th>
<th style="text-align: center;"><strong>10p</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MAXSAT19-UCMS</td>
<td style="text-align: center;">3.42</td>
<td style="text-align: center;">3.65</td>
<td style="text-align: center;">4.01</td>
<td style="text-align: center;">3.92</td>
<td style="text-align: center;">4.21</td>
<td style="text-align: center;">4.42</td>
<td style="text-align: center;">4.38</td>
<td style="text-align: center;">–</td>
<td style="text-align: center;">–</td>
<td style="text-align: center;">–</td>
</tr>
<tr class="even">
<td>IPC2018</td>
<td style="text-align: center;">3.88</td>
<td style="text-align: center;">4.59</td>
<td style="text-align: center;">4.94</td>
<td style="text-align: center;">5.19</td>
<td style="text-align: center;">5.28</td>
<td style="text-align: center;">5.96</td>
<td style="text-align: center;">5.69</td>
<td style="text-align: center;">6.19</td>
<td style="text-align: center;">6.58</td>
<td style="text-align: center;">6.69</td>
</tr>
<tr class="odd">
<td>SAT11-INDU</td>
<td style="text-align: center;">4.18</td>
<td style="text-align: center;">4.58</td>
<td style="text-align: center;">4.67</td>
<td style="text-align: center;">5.25</td>
<td style="text-align: center;">5.28</td>
<td style="text-align: center;">5.83</td>
<td style="text-align: center;">5.88</td>
<td style="text-align: center;">6.34</td>
<td style="text-align: center;">6.32</td>
<td style="text-align: center;">6.68</td>
</tr>
<tr class="even">
<td>SAT16-MAIN</td>
<td style="text-align: center;">5.13</td>
<td style="text-align: center;">4.98</td>
<td style="text-align: center;">4.85</td>
<td style="text-align: center;">5.07</td>
<td style="text-align: center;">5.42</td>
<td style="text-align: center;">5.53</td>
<td style="text-align: center;">5.61</td>
<td style="text-align: center;">5.77</td>
<td style="text-align: center;">6.51</td>
<td style="text-align: center;">6.13</td>
</tr>
<tr class="odd">
<td>SAT18-EXP</td>
<td style="text-align: center;">3.94</td>
<td style="text-align: center;">4.80</td>
<td style="text-align: center;">5.11</td>
<td style="text-align: center;">5.61</td>
<td style="text-align: center;">5.55</td>
<td style="text-align: center;">6.01</td>
<td style="text-align: center;">6.17</td>
<td style="text-align: center;">6.44</td>
<td style="text-align: center;">6.40</td>
<td style="text-align: center;">4.99</td>
</tr>
<tr class="even">
<td><strong>Average</strong></td>
<td style="text-align: center;">4.11</td>
<td style="text-align: center;">4.52</td>
<td style="text-align: center;">4.71</td>
<td style="text-align: center;">5.01</td>
<td style="text-align: center;">5.15</td>
<td style="text-align: center;">5.55</td>
<td style="text-align: center;">5.54</td>
<td style="text-align: center;">6.19</td>
<td style="text-align: center;">6.45</td>
<td style="text-align: center;">6.12</td>
</tr>
</tbody>
</table>
</div>
<figure id="fig:critical" class="figure">
<img src="plots/Alternating_Label_Critical_Difference_Diagram.png" style="width:95%" class="figure-img">
<figcaption>
Critical Difference Diagram. This figure shows the average ranking of each performance model trained at different levels of parallelism, based on the actual performance of the selected algorithms. The CD of 6.06 means that the Critical Difference (CD) threshold for determining statistically significant differences in rankings is 6.06. If the difference in average rankings between two models is greater than 6.06, the rankings are considered statistically significantly different at a significance level of <span class="math inline">()</span>.
</figcaption>
</figure>
</section>
<section id="baselines" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="baselines"><span class="header-section-number">7.3.3</span> Baselines</h3>
<p>Although the algorithm selection rankings did not show significant differences in algorithm selection in these five scenarios, we evaluated the performance of the dynamic parallel portfolio approach against several baseline methods using sequential and parallel data-trained models. Specifically, we compared the results to the sequential Virtual Best Solver (VBS), which selects the best solver for each problem instance with a cumulative misclassification penalty of zero, and the sequential Single Best Solver (SBS), which is the solver with the best average performance across all instances and has a cumulative misclassification penalty of one. For parallel runs, the VBS selects the best solver for each instance but accounts for the overhead of <span class="math inline">\(n\)</span> parallel runs. The parallel SBS is determined similarly, based on the solver with the best average performance across all instances instead of the best solver for each instance. To ensure a realistic evaluation, we executed multiple solvers in parallel to measure the actual runtime of the best solver in this setup, rather than assuming it would run sequentially.</p>
<p>We used two methods to train algorithm selectors: one trained using Ranger with the Jackknife method and another using Ranger with the Infinitesimal Jackknife method to estimate the uncertainty of predictions. Initially, we trained models on sequential data and then trained performance models on parallel performance data (<span class="math inline">\(AS_{\parallel}\)</span>). In the <span class="math inline">\(AS_{\parallel}\)</span> method, to predict performance for <span class="math inline">\(n\)</span> parallel runs, we used the predictions of the performance model trained on data collected from <span class="math inline">\(n\)</span> parallel runs.</p>
<p>We evaluated the proposed approach using three metrics: penalized average runtime with a factor of 10 (PAR10), misclassification penalty (MCP), and runtime. The PAR10 metric corresponds to the actual runtime if the algorithm successfully solves the instance within the timeout; otherwise, it is calculated as the timeout multiplied by 10. The MCP represents the difference between the performance of the selected algorithm and that of the optimal algorithm. To ensure comparability across scenarios, all performance metrics are normalized relative to the Virtual Best Solver (VBS) and Single Best Solver (SBS). The results, shown in Figure&nbsp;<a href="#fig:parallelvssequential" data-reference-type="ref" data-reference="fig:parallelvssequential">1.2</a>, depict the proportion of the performance gap closed by each approach. On this normalized scale, a value of 0 corresponds to the performance of the SBS, while a value of 1 corresponds to the performance of the VBS.</p>
</section>
</section>
<section id="results" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="results"><span class="header-section-number">7.4</span> Results</h2>
<p>We experimented with training Ranger models using parallel data to compare their performance with models trained on sequential data. Figures&nbsp;<a href="#fig:rangervsrf" data-reference-type="ref" data-reference="fig:rangervsrf">[fig:rangervsrf]</a> present the PAR10 score results in terms of the normalized performance gap between the sequential Single Best Solver (SBS) and the sequential Virtual Best Solver (VBS) across all scenarios and processor counts. These figures specifically compare Ranger models trained with the Infinitesimal Jackknife method. Additionally, Tables&nbsp;<a href="#tab:summary6-ipc-max" data-reference-type="ref" data-reference="tab:summary6-ipc-max">1.4</a>,&nbsp;<a href="#tab:summary6-sat11-sat16" data-reference-type="ref" data-reference="tab:summary6-sat11-sat16">1.5</a> and&nbsp;<a href="#tab:summary6-sat18" data-reference-type="ref" data-reference="tab:summary6-sat18">1.6</a> provide the exact runtime, Misclassification Penalty (MCP), and PAR10 scores for the methods, limiting the maximum number of parallel runs to 10 for SAT18-EXP, SAT16-MAIN, SAT11-INDU, and IPC2018, and to 7 for MAXSAT19-UCMS.</p>
<figure id="fig:parallelvssequential" class="figure">
<embed src="plots/pl_pcap_comparison_line_chart_parallel_NormalizedGap.svg" style="width:95%">
<figcaption>
Results Overview. The plot illustrates the extent to which each method narrows the gap between the PAR10 scores of the Single Best Solver (SBS) and the Virtual Best Solver (VBS). For VBS and SBS, the top <span class="math inline">(n)</span> solvers are selected, where <span class="math inline">(n)</span> matches the number of processors available for each problem instance and across all instances, respectively. <span class="math inline">(AS_0)</span> selects the top <span class="math inline">(n)</span> solvers as predicted by algorithm selection, disregarding any overlap in their predicted runtime distributions. <span class="math inline">(AS_{p_{}})</span> follows the approach proposed in <span class="citation" data-cites="kashgarani2023automatic"></span>, with the number of processors capped at the specific value on the x-axis — fewer solvers than this maximum may be selected based on the overlap in runtime predictions. The algorithm selection here is Ranger model with the Infinitesimal Jackknife method for predicting uncertainty. The <span class="math inline">()</span> symbol is referring to the performance model trained on parallel data.
</figcaption>
</figure>
<div class="center">
<div id="tab:summary6-ipc-max">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for IPC2018, and 7 for MAXSAT19-UCMS) for our approaches and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">508<span class="math inline">\(\pm\)</span><!-- -->697</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3478<span class="math inline">\(\pm\)</span><!-- -->6903</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">608<span class="math inline">\(\pm\)</span><!-- -->751</td>
<td style="text-align: center;">100<span class="math inline">\(\pm\)</span><!-- -->293</td>
<td style="text-align: center;">4456<span class="math inline">\(\pm\)</span><!-- -->7583</td>
<td style="text-align: center;">-0.35<span class="math inline">\(\pm\)</span><!-- -->2.85</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">604<span class="math inline">\(\pm\)</span><!-- -->752</td>
<td style="text-align: center;">96<span class="math inline">\(\pm\)</span><!-- -->293</td>
<td style="text-align: center;">4519<span class="math inline">\(\pm\)</span><!-- -->7633</td>
<td style="text-align: center;">-0.39<span class="math inline">\(\pm\)</span><!-- -->2.84</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">734<span class="math inline">\(\pm\)</span><!-- -->770</td>
<td style="text-align: center;">226<span class="math inline">\(\pm\)</span><!-- -->414</td>
<td style="text-align: center;">5459<span class="math inline">\(\pm\)</span><!-- -->8072</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;">616<span class="math inline">\(\pm\)</span><!-- -->783</td>
<td style="text-align: center;">107<span class="math inline">\(\pm\)</span><!-- -->312</td>
<td style="text-align: center;">5206<span class="math inline">\(\pm\)</span><!-- -->8065</td>
<td style="text-align: center;">-0.69<span class="math inline">\(\pm\)</span><!-- -->2.54</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">616<span class="math inline">\(\pm\)</span><!-- -->783</td>
<td style="text-align: center;">107<span class="math inline">\(\pm\)</span><!-- -->312</td>
<td style="text-align: center;">5206<span class="math inline">\(\pm\)</span><!-- -->8065</td>
<td style="text-align: center;">-0.69<span class="math inline">\(\pm\)</span><!-- -->2.54</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.44}\)</span> (RI)</td>
<td style="text-align: center;"><strong>557<span class="math inline">\(\pm\)</span><!-- -->728</strong></td>
<td style="text-align: center;"><strong>49<span class="math inline">\(\pm\)</span><!-- -->190</strong></td>
<td style="text-align: center;"><strong>4135<span class="math inline">\(\pm\)</span><!-- -->7403</strong></td>
<td style="text-align: center;"><strong>-0.19<span class="math inline">\(\pm\)</span><!-- -->2.89</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.27}\)</span> (RJ)</td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->744</td>
<td style="text-align: center;"><em>62<span class="math inline">\(\pm\)</span><!-- -->229</em></td>
<td style="text-align: center;">4350<span class="math inline">\(\pm\)</span><!-- -->7552</td>
<td style="text-align: center;"><em>-0.21<span class="math inline">\(\pm\)</span><!-- -->2.72</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RI)\)</span></td>
<td style="text-align: center;">615<span class="math inline">\(\pm\)</span><!-- -->782</td>
<td style="text-align: center;">107<span class="math inline">\(\pm\)</span><!-- -->311</td>
<td style="text-align: center;">5205<span class="math inline">\(\pm\)</span><!-- -->8065</td>
<td style="text-align: center;">-0.69<span class="math inline">\(\pm\)</span><!-- -->2.55</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RJ)\)</span></td>
<td style="text-align: center;">619<span class="math inline">\(\pm\)</span><!-- -->786</td>
<td style="text-align: center;">112<span class="math inline">\(\pm\)</span><!-- -->322</td>
<td style="text-align: center;">5277<span class="math inline">\(\pm\)</span><!-- -->8102</td>
<td style="text-align: center;">-0.71<span class="math inline">\(\pm\)</span><!-- -->2.54</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.44} (RI)\)</span></td>
<td style="text-align: center;">581<span class="math inline">\(\pm\)</span><!-- -->743</td>
<td style="text-align: center;">73<span class="math inline">\(\pm\)</span><!-- -->252</td>
<td style="text-align: center;">4428<span class="math inline">\(\pm\)</span><!-- -->7596</td>
<td style="text-align: center;">-0.34<span class="math inline">\(\pm\)</span><!-- -->2.67</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.27} (RJ)\)</span></td>
<td style="text-align: center;">608<span class="math inline">\(\pm\)</span><!-- -->771</td>
<td style="text-align: center;">100<span class="math inline">\(\pm\)</span><!-- -->304</td>
<td style="text-align: center;">4996<span class="math inline">\(\pm\)</span><!-- -->7946</td>
<td style="text-align: center;">-1.5<span class="math inline">\(\pm\)</span><!-- -->5.65</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">858<span class="math inline">\(\pm\)</span><!-- -->1476</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">7768<span class="math inline">\(\pm\)</span><!-- -->14717</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1076<span class="math inline">\(\pm\)</span><!-- -->1575</td>
<td style="text-align: center;">218<span class="math inline">\(\pm\)</span><!-- -->729</td>
<td style="text-align: center;">9686<span class="math inline">\(\pm\)</span><!-- -->15850</td>
<td style="text-align: center;">0.45<span class="math inline">\(\pm\)</span><!-- -->0.34</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1044<span class="math inline">\(\pm\)</span><!-- -->1565</td>
<td style="text-align: center;">186<span class="math inline">\(\pm\)</span><!-- -->666</td>
<td style="text-align: center;">9540<span class="math inline">\(\pm\)</span><!-- -->15793</td>
<td style="text-align: center;">0.49<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">1190<span class="math inline">\(\pm\)</span><!-- -->1657</td>
<td style="text-align: center;">332<span class="math inline">\(\pm\)</span><!-- -->940</td>
<td style="text-align: center;">11386<span class="math inline">\(\pm\)</span><!-- -->16696</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">2-6</td>
<td style="text-align: left;"><strong>7 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">2-6</td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;"><strong>894<span class="math inline">\(\pm\)</span><!-- -->1506</strong></td>
<td style="text-align: center;"><strong>37<span class="math inline">\(\pm\)</span><!-- -->247</strong></td>
<td style="text-align: center;"><em>8258<span class="math inline">\(\pm\)</span><!-- -->15062</em></td>
<td style="text-align: center;"><em>0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;"><strong>894<span class="math inline">\(\pm\)</span><!-- -->1506</strong></td>
<td style="text-align: center;"><strong>37<span class="math inline">\(\pm\)</span><!-- -->247</strong></td>
<td style="text-align: center;"><em>8258<span class="math inline">\(\pm\)</span><!-- -->15062</em></td>
<td style="text-align: center;"><em>0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.03}\)</span> (RI)</td>
<td style="text-align: center;"><strong>894<span class="math inline">\(\pm\)</span><!-- -->1506</strong></td>
<td style="text-align: center;"><strong>37<span class="math inline">\(\pm\)</span><!-- -->247</strong></td>
<td style="text-align: center;"><em>8258<span class="math inline">\(\pm\)</span><!-- -->15062</em></td>
<td style="text-align: center;"><em>0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.14}\)</span> (RJ)</td>
<td style="text-align: center;">921<span class="math inline">\(\pm\)</span><!-- -->1521</td>
<td style="text-align: center;">63<span class="math inline">\(\pm\)</span><!-- -->369</td>
<td style="text-align: center;">8568<span class="math inline">\(\pm\)</span><!-- -->15263</td>
<td style="text-align: center;">0.76<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RI)\)</span></td>
<td style="text-align: center;"><strong>894<span class="math inline">\(\pm\)</span><!-- -->1506</strong></td>
<td style="text-align: center;"><strong>37<span class="math inline">\(\pm\)</span><!-- -->247</strong></td>
<td style="text-align: center;"><em>8258<span class="math inline">\(\pm\)</span><!-- -->15062</em></td>
<td style="text-align: center;"><em>0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RJ)\)</span></td>
<td style="text-align: center;"><strong>894<span class="math inline">\(\pm\)</span><!-- -->1506</strong></td>
<td style="text-align: center;"><strong>37<span class="math inline">\(\pm\)</span><!-- -->247</strong></td>
<td style="text-align: center;"><em>8258<span class="math inline">\(\pm\)</span><!-- -->15062</em></td>
<td style="text-align: center;"><em>0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.03} (RI)\)</span></td>
<td style="text-align: center;"><strong>894<span class="math inline">\(\pm\)</span><!-- -->1506</strong></td>
<td style="text-align: center;"><strong>37<span class="math inline">\(\pm\)</span><!-- -->247</strong></td>
<td style="text-align: center;"><em>8258<span class="math inline">\(\pm\)</span><!-- -->15062</em></td>
<td style="text-align: center;"><em>0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.14} (RJ)\)</span></td>
<td style="text-align: center;">939<span class="math inline">\(\pm\)</span><!-- -->1534</td>
<td style="text-align: center;">82<span class="math inline">\(\pm\)</span><!-- -->442</td>
<td style="text-align: center;">8756<span class="math inline">\(\pm\)</span><!-- -->15379</td>
<td style="text-align: center;">0.71<span class="math inline">\(\pm\)</span><!-- -->0.31</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="center">
<div id="tab:summary6-sat11-sat16">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for SAT16-MAIN and SAT11-INDU) for our approaches and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1140<span class="math inline">\(\pm\)</span><!-- -->1836</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">8040<span class="math inline">\(\pm\)</span><!-- -->17905</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1610<span class="math inline">\(\pm\)</span><!-- -->2108</td>
<td style="text-align: center;">470<span class="math inline">\(\pm\)</span><!-- -->1145</td>
<td style="text-align: center;">12710<span class="math inline">\(\pm\)</span><!-- -->21389</td>
<td style="text-align: center;">-0.06<span class="math inline">\(\pm\)</span><!-- -->0.9</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1565<span class="math inline">\(\pm\)</span><!-- -->2049</td>
<td style="text-align: center;">425<span class="math inline">\(\pm\)</span><!-- -->1017</td>
<td style="text-align: center;">11315<span class="math inline">\(\pm\)</span><!-- -->20402</td>
<td style="text-align: center;">0.34<span class="math inline">\(\pm\)</span><!-- -->0.49</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">1818<span class="math inline">\(\pm\)</span><!-- -->2168</td>
<td style="text-align: center;">678<span class="math inline">\(\pm\)</span><!-- -->1340</td>
<td style="text-align: center;">14268<span class="math inline">\(\pm\)</span><!-- -->22154</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;"><em>1238<span class="math inline">\(\pm\)</span><!-- -->1892</em></td>
<td style="text-align: center;"><em>127<span class="math inline">\(\pm\)</span><!-- -->385</em></td>
<td style="text-align: center;"><em>8588<span class="math inline">\(\pm\)</span><!-- -->18350</em></td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">1262<span class="math inline">\(\pm\)</span><!-- -->1910</td>
<td style="text-align: center;">151<span class="math inline">\(\pm\)</span><!-- -->480</td>
<td style="text-align: center;">8612<span class="math inline">\(\pm\)</span><!-- -->18342</td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.01}\)</span> (RI)</td>
<td style="text-align: center;"><strong>1236<span class="math inline">\(\pm\)</span><!-- -->1890</strong></td>
<td style="text-align: center;"><strong>121<span class="math inline">\(\pm\)</span><!-- -->379</strong></td>
<td style="text-align: center;"><strong>8586<span class="math inline">\(\pm\)</span><!-- -->18351</strong></td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">1289<span class="math inline">\(\pm\)</span><!-- -->1934</td>
<td style="text-align: center;">178<span class="math inline">\(\pm\)</span><!-- -->595</td>
<td style="text-align: center;">9089<span class="math inline">\(\pm\)</span><!-- -->18787</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RI)\)</span></td>
<td style="text-align: center;">1276<span class="math inline">\(\pm\)</span><!-- -->1926</td>
<td style="text-align: center;">166<span class="math inline">\(\pm\)</span><!-- -->546</td>
<td style="text-align: center;">8926<span class="math inline">\(\pm\)</span><!-- -->18643</td>
<td style="text-align: center;">0.89<span class="math inline">\(\pm\)</span><!-- -->0.13</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RJ)\)</span></td>
<td style="text-align: center;">1286<span class="math inline">\(\pm\)</span><!-- -->1939</td>
<td style="text-align: center;">175<span class="math inline">\(\pm\)</span><!-- -->564</td>
<td style="text-align: center;">8936<span class="math inline">\(\pm\)</span><!-- -->18640</td>
<td style="text-align: center;">0.88<span class="math inline">\(\pm\)</span><!-- -->0.12</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.01} (RI)\)</span></td>
<td style="text-align: center;">1279<span class="math inline">\(\pm\)</span><!-- -->1929</td>
<td style="text-align: center;">162<span class="math inline">\(\pm\)</span><!-- -->530</td>
<td style="text-align: center;">9079<span class="math inline">\(\pm\)</span><!-- -->18791</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.27</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.31} (RJ)\)</span></td>
<td style="text-align: center;">1365<span class="math inline">\(\pm\)</span><!-- -->2004</td>
<td style="text-align: center;">247<span class="math inline">\(\pm\)</span><!-- -->794</td>
<td style="text-align: center;">10065<span class="math inline">\(\pm\)</span><!-- -->19605</td>
<td style="text-align: center;">0.64<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1867<span class="math inline">\(\pm\)</span><!-- -->2193</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">15005<span class="math inline">\(\pm\)</span><!-- -->22530</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">2383<span class="math inline">\(\pm\)</span><!-- -->2294</td>
<td style="text-align: center;">516<span class="math inline">\(\pm\)</span><!-- -->1151</td>
<td style="text-align: center;">19956<span class="math inline">\(\pm\)</span><!-- -->24111</td>
<td style="text-align: center;">0.05<span class="math inline">\(\pm\)</span><!-- -->0.66</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">2400<span class="math inline">\(\pm\)</span><!-- -->2269</td>
<td style="text-align: center;">533<span class="math inline">\(\pm\)</span><!-- -->1177</td>
<td style="text-align: center;">19316<span class="math inline">\(\pm\)</span><!-- -->23880</td>
<td style="text-align: center;">0.3<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">2560<span class="math inline">\(\pm\)</span><!-- -->2294</td>
<td style="text-align: center;">693<span class="math inline">\(\pm\)</span><!-- -->1415</td>
<td style="text-align: center;">21940<span class="math inline">\(\pm\)</span><!-- -->24464</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">2-6</td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">2-6</td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;"><strong>2016<span class="math inline">\(\pm\)</span><!-- -->2225</strong></td>
<td style="text-align: center;"><strong>150<span class="math inline">\(\pm\)</span><!-- -->503</strong></td>
<td style="text-align: center;"><em>16469<span class="math inline">\(\pm\)</span><!-- -->23122</em></td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.6</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">2048<span class="math inline">\(\pm\)</span><!-- -->2228</td>
<td style="text-align: center;">181<span class="math inline">\(\pm\)</span><!-- -->597</td>
<td style="text-align: center;"><strong>16336<span class="math inline">\(\pm\)</span><!-- -->23023</strong></td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.59</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;"><strong>2016<span class="math inline">\(\pm\)</span><!-- -->2225</strong></td>
<td style="text-align: center;"><strong>150<span class="math inline">\(\pm\)</span><!-- -->503</strong></td>
<td style="text-align: center;"><em>16469<span class="math inline">\(\pm\)</span><!-- -->23122</em></td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.6</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.33}\)</span> (RJ)</td>
<td style="text-align: center;">2088<span class="math inline">\(\pm\)</span><!-- -->2239</td>
<td style="text-align: center;">222<span class="math inline">\(\pm\)</span><!-- -->704</td>
<td style="text-align: center;">16705<span class="math inline">\(\pm\)</span><!-- -->23156</td>
<td style="text-align: center;">0.64<span class="math inline">\(\pm\)</span><!-- -->0.37</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RI)\)</span></td>
<td style="text-align: center;">2053<span class="math inline">\(\pm\)</span><!-- -->2246</td>
<td style="text-align: center;">186<span class="math inline">\(\pm\)</span><!-- -->593</td>
<td style="text-align: center;">16505<span class="math inline">\(\pm\)</span><!-- -->23101</td>
<td style="text-align: center;"><em>0.79<span class="math inline">\(\pm\)</span><!-- -->0.49</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RJ)\)</span></td>
<td style="text-align: center;"><em>2040<span class="math inline">\(\pm\)</span><!-- -->2223</em></td>
<td style="text-align: center;"><em>174<span class="math inline">\(\pm\)</span><!-- -->579</em></td>
<td style="text-align: center;">16000<span class="math inline">\(\pm\)</span><!-- -->22864</td>
<td style="text-align: center;"><strong>0.8<span class="math inline">\(\pm\)</span><!-- -->0.34</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0} (RI)\)</span></td>
<td style="text-align: center;">2053<span class="math inline">\(\pm\)</span><!-- -->2246</td>
<td style="text-align: center;">186<span class="math inline">\(\pm\)</span><!-- -->593</td>
<td style="text-align: center;">16505<span class="math inline">\(\pm\)</span><!-- -->23101</td>
<td style="text-align: center;"><em>0.79<span class="math inline">\(\pm\)</span><!-- -->0.49</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.33} (RJ)\)</span></td>
<td style="text-align: center;">2197<span class="math inline">\(\pm\)</span><!-- -->2271</td>
<td style="text-align: center;">330<span class="math inline">\(\pm\)</span><!-- -->924</td>
<td style="text-align: center;">17635<span class="math inline">\(\pm\)</span><!-- -->23454</td>
<td style="text-align: center;">0.6<span class="math inline">\(\pm\)</span><!-- -->0.43</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="center">
<div id="tab:summary6-sat18">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for SAT18-EXP) for our approaches and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1146<span class="math inline">\(\pm\)</span><!-- -->1945</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">9687<span class="math inline">\(\pm\)</span><!-- -->19547</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1648<span class="math inline">\(\pm\)</span><!-- -->2151</td>
<td style="text-align: center;">502<span class="math inline">\(\pm\)</span><!-- -->1256</td>
<td style="text-align: center;">13758<span class="math inline">\(\pm\)</span><!-- -->22034</td>
<td style="text-align: center;">0.59<span class="math inline">\(\pm\)</span><!-- -->0.18</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1690<span class="math inline">\(\pm\)</span><!-- -->2170</td>
<td style="text-align: center;">543<span class="math inline">\(\pm\)</span><!-- -->1302</td>
<td style="text-align: center;">14183<span class="math inline">\(\pm\)</span><!-- -->22247</td>
<td style="text-align: center;">0.57<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">2400<span class="math inline">\(\pm\)</span><!-- -->2249</td>
<td style="text-align: center;">1254<span class="math inline">\(\pm\)</span><!-- -->1832</td>
<td style="text-align: center;">20629<span class="math inline">\(\pm\)</span><!-- -->24280</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RI)</td>
<td style="text-align: center;">1654<span class="math inline">\(\pm\)</span><!-- -->2285</td>
<td style="text-align: center;">511<span class="math inline">\(\pm\)</span><!-- -->1324</td>
<td style="text-align: center;">15804<span class="math inline">\(\pm\)</span><!-- -->23194</td>
<td style="text-align: center;">0.42<span class="math inline">\(\pm\)</span><!-- -->0.29</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_0\)</span> (RJ)</td>
<td style="text-align: center;">1678<span class="math inline">\(\pm\)</span><!-- -->2288</td>
<td style="text-align: center;">535<span class="math inline">\(\pm\)</span><!-- -->1351</td>
<td style="text-align: center;">15956<span class="math inline">\(\pm\)</span><!-- -->23243</td>
<td style="text-align: center;">0.4<span class="math inline">\(\pm\)</span><!-- -->0.3</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.55}\)</span> (RI)</td>
<td style="text-align: center;"><strong>1541<span class="math inline">\(\pm\)</span><!-- -->2191</strong></td>
<td style="text-align: center;"><strong>397<span class="math inline">\(\pm\)</span><!-- -->1177</strong></td>
<td style="text-align: center;"><strong>14034<span class="math inline">\(\pm\)</span><!-- -->22332</strong></td>
<td style="text-align: center;"><strong>0.6<span class="math inline">\(\pm\)</span><!-- -->0.21</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.58}\)</span> (RJ)</td>
<td style="text-align: center;">1622<span class="math inline">\(\pm\)</span><!-- -->2237</td>
<td style="text-align: center;">477<span class="math inline">\(\pm\)</span><!-- -->1268</td>
<td style="text-align: center;">15008<span class="math inline">\(\pm\)</span><!-- -->22805</td>
<td style="text-align: center;">0.5<span class="math inline">\(\pm\)</span><!-- -->0.25</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RI)\)</span></td>
<td style="text-align: center;">1709<span class="math inline">\(\pm\)</span><!-- -->2303</td>
<td style="text-align: center;">566<span class="math inline">\(\pm\)</span><!-- -->1397</td>
<td style="text-align: center;">16242<span class="math inline">\(\pm\)</span><!-- -->23351</td>
<td style="text-align: center;">0.4<span class="math inline">\(\pm\)</span><!-- -->0.21</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel 0} (RJ)\)</span></td>
<td style="text-align: center;">1676<span class="math inline">\(\pm\)</span><!-- -->2294</td>
<td style="text-align: center;">533<span class="math inline">\(\pm\)</span><!-- -->1358</td>
<td style="text-align: center;">15954<span class="math inline">\(\pm\)</span><!-- -->23245</td>
<td style="text-align: center;">0.42<span class="math inline">\(\pm\)</span><!-- -->0.22</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.55} (RI)\)</span></td>
<td style="text-align: center;">1624<span class="math inline">\(\pm\)</span><!-- -->2217</td>
<td style="text-align: center;">478<span class="math inline">\(\pm\)</span><!-- -->1218</td>
<td style="text-align: center;">14754<span class="math inline">\(\pm\)</span><!-- -->22660</td>
<td style="text-align: center;">0.54<span class="math inline">\(\pm\)</span><!-- -->0.2</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{\parallel p_{\cap} = 0.58} (RJ)\)</span></td>
<td style="text-align: center;">1708<span class="math inline">\(\pm\)</span><!-- -->2269</td>
<td style="text-align: center;">563<span class="math inline">\(\pm\)</span><!-- -->1363</td>
<td style="text-align: center;">15730<span class="math inline">\(\pm\)</span><!-- -->23095</td>
<td style="text-align: center;">0.43<span class="math inline">\(\pm\)</span><!-- -->0.25</td>
</tr>
</tbody>
</table>
</div>
</div>
<figure id="fig:numberofsolvers_kl" class="figure">
<p>
<embed src="plots/number_of_solvers_infjack_pcap_parallel.svg" style="width:50.0%">
<embed src="plots/number_of_solvers_jack_pcap_parallel.svg" style="width:50.0%">
</p>
<figcaption>
Violin plot of the distribution of the number of selected solvers to run in parallel across all problem instances for each scenario for the respective optimal <span class="math inline">(p_{})</span> and the maximum level of parallelism (seven processors for MAXSAT19-UCMS and 10 for all other scenarios). The diamond denotes the mean value. The top-left plot refers to the RFJ model, the top-right plot to the RI model, and the bottom plot to the RJ model.
</figcaption>
</figure>
<p>When comparing models trained on sequential data with those trained on parallel data for portfolio selection, the model trained on sequential data consistently outperforms the model trained on parallel data. This is evident in Tables&nbsp;<a href="#tab:summary5-ipc-max" data-reference-type="ref" data-reference="tab:summary5-ipc-max">[tab:summary5-ipc-max]</a>, <a href="#tab:summary5-sat11-sat16" data-reference-type="ref" data-reference="tab:summary5-sat11-sat16">[tab:summary5-sat11-sat16]</a> and&nbsp;<a href="#tab:summary5-sat18" data-reference-type="ref" data-reference="tab:summary5-sat18">[tab:summary5-sat18]</a>, which show that both the <span class="math inline">\(AS_0\)</span> and <span class="math inline">\(AS_{p_{\cap}}\)</span> methods are superior to <span class="math inline">\(AS_{\parallel 0}\)</span> and <span class="math inline">\(AS_{\parallel p_{\cap}}\)</span>, respectively. This holds for both the RJ and RI models in all scenarios, except when comparing <span class="math inline">\(AS_0\)</span> and <span class="math inline">\(AS_{\parallel 0}\)</span> for SAT16-MAIN and SAT18-EXP, where the RJ model performs slightly better. In Figure&nbsp;<a href="#fig:parallelvssequential" data-reference-type="ref" data-reference="fig:parallelvssequential">1.2</a>, for the RI model with a number of parallel runs limited to 10, the <span class="math inline">\(AS_{\cap}\)</span> method, using a model trained on sequential data, emerges as the best approach to portfolio selection.</p>
</section>
<section id="conclusions" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="conclusions"><span class="header-section-number">7.5</span> Conclusions</h2>
<p>In this chapter, we explore the impact of training algorithm selectors using parallel data versus sequential data for parallel portfolio selection. Using both sequential and parallel performance models, our objective was to understand whether incorporating data collected under parallel execution conditions would offer a significant advantage in portfolio selection tasks. Our initial analysis reveals that while predictions of algorithm selectors trained on parallel data differ significantly from those trained on sequential data, their overall rankings across models on the benchmarks are not significantly different.</p>
<p>Furthermore, when comparing the effectiveness of portfolio selection, models trained on sequential data consistently outperform those trained on parallel data in most scenarios. Specifically, the <span class="math inline">\(AS_{p_{\cap}}\)</span> method trained in sequential data demonstrated superior performance compared to its counterpart trained in parallel data <span class="math inline">\(AS_{\parallel p_{\cap}}\)</span>).</p>
<p>These findings underscore the robustness of sequentially trained models for portfolio selection, even in parallel execution environments. Importantly, the results suggest that collecting parallel data may not be necessary for effective portfolio selection. Sequential data models are just as effective, if not superior, for predicting solver performance and guiding efficient portfolio selection. Although parallel data offers insight into runtime overheads, sequential data models remain more effective in predicting solver performance and ranking which resulted in efficient portfolio selection.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BISCHL201641" class="csl-entry" role="listitem">
Bischl, Bernd, Pascal Kerschke, Lars Kotthoff, Marius Lindauer, Yuri Malitsky, Alexandre Fréchette, Holger Hoos, et al. 2016. <span>“<span>ASlib</span>: A Benchmark Library for Algorithm Selection.”</span> <em>Artificial Intelligence</em> 237: 41–58.
</div>
<div id="ref-mlr" class="csl-entry" role="listitem">
Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2016. <span>“<span class="nocase">mlr: Machine Learning in R</span>.”</span> <em>Journal of Machine Learning Research</em> 17 (170): 1–5. <a href="https://jmlr.org/papers/v17/15-066.html">https://jmlr.org/papers/v17/15-066.html</a>.
</div>
<div id="ref-Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014" class="csl-entry" role="listitem">
Fawcett, Chris, Mauro Vallati, Frank Hutter, Jörg Hoffmann, Holger Hoos, and Kevin Leyton-Brown. 2014. <span>“<span class="nocase">Improved Features for Runtime Prediction of Domain-Independent Planners</span>.”</span> <em>Proceedings of the International Conference on Automated Planning and Scheduling</em> 24 (1): 355–59. <a href="https://doi.org/10.1609/icaps.v24i1.13680">https://doi.org/10.1609/icaps.v24i1.13680</a>.
</div>
<div id="ref-GOMES200143" class="csl-entry" role="listitem">
Gomes, Carla, and Bart Selman. 2001. <span>“Algorithm Portfolios.”</span> <em>Artificial Intelligence</em> 126: 43–62.
</div>
<div id="ref-Huberman1997" class="csl-entry" role="listitem">
Huberman, Bernardo A., Rajan M. Lukose, and Tad Hogg. 1997. <span>“<span class="nocase">An economics approach to hard computational problems</span>.”</span> <em>Science</em> 275 (5296): 51–54. <a href="https://doi.org/10.1126/science.275.5296.51">https://doi.org/10.1126/science.275.5296.51</a>.
</div>
<div id="ref-pmlr-v140-kashgarani21a" class="csl-entry" role="listitem">
Kashgarani, Haniye, and Lars Kotthoff. 2021. <span>“<span class="nocase">Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution</span>.”</span> In <em>AAAI Workshop on Meta-Learning and MetaDL Challenge</em>, 140:58–64. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v140/kashgarani21a.html">https://proceedings.mlr.press/v140/kashgarani21a.html</a>.
</div>
<div id="ref-kashgarani2023automatic" class="csl-entry" role="listitem">
———. 2023. <span>“<span>Automatic Parallel Portfolio Selection</span>.”</span> In <em>ECAI 2023</em>, 1215–22. IOS Press.
</div>
<div id="ref-10.1162/evco_a_00242" class="csl-entry" role="listitem">
Kerschke, Pascal, Holger H. Hoos, Frank Neumann, and Heike Trautmann. 2019. <span>“<span class="nocase">Automated Algorithm Selection: Survey and Perspectives</span>.”</span> <em>Evolutionary Computation</em> 27 (1): 3–45. <a href="https://doi.org/10.1162/evco_a_00242">https://doi.org/10.1162/evco_a_00242</a>.
</div>
<div id="ref-Kotthoff2014" class="csl-entry" role="listitem">
Kotthoff, Lars. 2014. <span>“<span class="nocase">Algorithm selection for combinatorial search problems: A survey</span>.”</span> <em>AI Magazine</em> 35 (3): 48–69.
</div>
<div id="ref-wager2014confidence" class="csl-entry" role="listitem">
Wager, Stefan, Trevor Hastie, and Bradley Efron. 2014. <span>“<span class="nocase">Confidence intervals for random forests: The jackknife and the infinitesimal jackknife</span>.”</span> <em>The Journal of Machine Learning Research</em> 15 (1): 1625–51.
</div>
<div id="ref-ranger" class="csl-entry" role="listitem">
Wright, Marvin N., and Andreas Ziegler. 2017. <span>“<span class="nocase">ranger</span>: A Fast Implementation of Random Forests for High Dimensional Data in <span>C++</span> and <span>R</span>.”</span> <em>Journal of Statistical Software</em> 77 (1): 1–17. <a href="https://doi.org/10.18637/jss.v077.i01">https://doi.org/10.18637/jss.v077.i01</a>.
</div>
<div id="ref-satzilla" class="csl-entry" role="listitem">
Xu, Lin, Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. 2008. <span>“<span>SATzilla</span>: Portfolio-Based Algorithm Selection for <span>SAT</span>.”</span> <em>J. Artif. Int. Res.</em> 32 (1): 565–606.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html" class="pagination-link" aria-label="Revisiting Parallel Portfolio Selection with KL Divergence">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Revisiting Parallel Portfolio Selection with KL Divergence</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter7/DiscussionandConclusion.html" class="pagination-link" aria-label="Discussion and Conclusion">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Discussion and Conclusion</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Parallel Portfolio Selection with Parallel Data Training</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>Combinatorial problem solvers often exhibit complementary performance</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>when solving given problem instances. The use of algorithms portfolios</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>has proven to be more effective than choosing the best single solver</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>(SBS) averaged across all instances <span class="co">[</span><span class="ot">@Huberman1997; @GOMES200143</span><span class="co">]</span>.</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Different portfolio approaches and designs are presented in the</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>literature. Entire portfolios can be run in parallel or a single</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>algorithm can be selected instance by instance using algorithm selection</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>techniques.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>This selection-based approach is often addressed by training performance</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>models using machine learning algorithms and instance features</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@Kotthoff2014; @10.1162/evco_a_00242</span><span class="co">]</span>. One drawback of this approach is</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>that since no machine learning model is perfect, the selections might be</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>incorrect, and performance models might not always be able to select the</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>best algorithm for a given instance. This means that selecting the wrong</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>algorithm can waste time and resources.</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>Since the hardware architecture of modern computing units can handle</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>multiple tasks in parallel, another portfolio approach is to execute the</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>entire portfolio simultaneously. This approach avoids the drawback of</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>algorithm selection, as the actual best solver will always be included</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>in the portfolio and executed alongside other algorithms. However,</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>running too many solvers in parallel can lead to resource wastage by</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>overloading computing processors. Additionally, this method can</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>introduce significant overhead, as solvers and cores compete for shared</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>resources when too many solvers are executed simultaneously. The more</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>algorithms executed in parallel, the greater the risk of time-out</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>computations and overhead. The preliminary results presented in Chapter</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>3 <span class="co">[</span><span class="ot">@pmlr-v140-kashgarani21a</span><span class="co">]</span> showed that, while the selection of a</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>single algorithm is suboptimal and imperfect, it performs better than</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>running too many solvers in parallel.</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>In Chapter 4, we proposed a hybrid approach that combines the benefits</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>of algorithm selection and parallel execution. We further extend this</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>method to a variation that performs competitively with the original</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>approach in Chapter 5. These \"middle-path\" methods aim to select the</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>most promising subset of algorithms to run in parallel on a single</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>non-distributed computing node <span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>. These</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>promising methods optimized performance by utilizing regression-based</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>random forest algorithm selectors, incorporating the estimated</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>uncertainty of predictions, and accounting for the overhead associated</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>with parallel portfolio execution. However, these approaches were tested</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>using performance models trained on sequential data, which do not</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>account for the overhead associated with parallel execution.</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>In this chapter, instead of relying on regression random forest models</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>trained on sequential data, we train performance models using actual</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>parallel data. We then compare algorithm selectors trained on sequential</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>data with those trained on parallel data, applying the method proposed</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>in Chapter 4 for parallel portfolio selection. By evaluating the</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>effectiveness of these two types of algorithm selector in portfolio</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>selection, we investigate whether collecting parallel data provides a</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>significant advantage or whether sequential data are equally effective.</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Performance Modeling with Parallel Data</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>In the paper Chapter 4 and 5<span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>, we used data</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>collected from running a single solver exclusively on a computing node</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>to train the regression-based random forest model. This data does not</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>account for parallelization or the overhead associated with running</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>multiple solvers concurrently. Although this approach has proven</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>effective, since we have already collected parallel data, we now aim to</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>investigate the efficiency of training the performance model using these</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>parallel data as well. Specifically, we focus on training performance</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>models on parallel data. These parallel data are gathered by running</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>solvers in parallel alongside other solvers, with varying numbers of</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>solvers executed simultaneously on a single, exclusive computing node</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>ensuring that no other tasks interfere with the recorded runtimes.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>In this approach, for scenarios such as SAT11-NDU, SAT18-EXP,</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN, and IPC2018, where data are available for up to 10 parallel</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>runs, we trained 10 distinct performance models, each tailored to a</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>specific level of parallelization. Similarly, for MAXSAT2019, which</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>includes data for up to 7 parallel runs, we trained 7 separate models,</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>each trained for a given parallel run level. This means that the</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>performance model, trained on data collected from running $n$ parallel</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>runs, is used to predict the performance of a solver when running $n$</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>parallel runs.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parallel Portfolio Selection</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>Algorithm performance for combinatorial problems varies widely between</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>instances, and portfolio approaches that use machine learning-based</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>algorithm selection aim to optimize performance by selecting the best</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>algorithms to execute while minimizing overhead from concurrent</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>execution. Algorithm selection has been effective in domains like SAT</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>and mixed integer programming. However, selecting a single algorithm can</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>sometimes lead to suboptimal outcomes due to inaccurate predictions.</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>This issue can be addressed by selecting a small subset of algorithms to</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>run in parallel, which mitigates prediction inaccuracies while reducing</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>overhead and resource demands.</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>We follow the methods and equations outlined in Chapter 4 as described</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>in&nbsp;<span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>. We do not include the subportfolio</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>selection method using KL divergence, as it consistently performed worse</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>than the method proposed in Chapter 4. The selection approach in Chapter</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>4 aims to select a subportfolio of solvers to run in parallel for a</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>given problem instance by leveraging predicted performance rankings.</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>Solvers are ranked according to their predicted performance metric,</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>forming a total order, and a subset of size $n$ is selected from the</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>top-ranked solvers. The key challenge is determining the optimal</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>portfolio size $n$, as including too many algorithms increases the</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>chance of including the best solver but also introduces significant</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>overhead from running solvers in parallel. To address this, the method</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>incorporates a probabilistic approach using the predicted performance</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>distribution of each solver.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>Rather than relying on point predictions, the method uses the predicted</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>performance distributions and extends typical algorithm selection</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>practices by incorporating uncertainty of performance predictions. We</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>assume that predictions follow a normal distribution characterized by</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>their mean and standard deviation. The overlap between these</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>distributions is used to compute the likelihood that a solver performs</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>comparably to the best-predicted solver. A threshold parameter,</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>$p_{\cap}$, controls the size of the parallel portfolio by including</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>solvers whose distributions overlap sufficiently with that of the best</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>solver. This approach balances the trade-off between including solvers</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>that might achieve optimal performance and limiting computational</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>overhead, providing a flexible and robust framework for parallel</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>portfolio selection.</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>As in previous chapters, we used regression random forests as the</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>algorithm selector, identified as the best performing approach in the</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>ASLib study <span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>. Furthermore, we transitioned from using a</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>model trained exclusively on sequential data to one trained on</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>sequential and parallel data to assess their comparative effectiveness.</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>Through this approach and our experiments, we sought to optimize the</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>utilization of parallel computational resources for solving</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>combinatorial problems while minimizing the overhead associated with</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>parallel execution.</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experimental Setup</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Collection</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>We used the same five scenarios from previous chapters</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>, all now included in the ASlib benchmark</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>repository <span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>: MAXSAT19-UCMS, SAT11-INDU, SAT18-EXP,</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN, and IPC2018. Although the ASlib data repository only</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>provides performance data for single runs, we incorporated parallel run</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>measurements from <span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>, performed on standalone</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>machines. For MAXSAT19-UCMS, SAT11-INDU, SAT16-MAIN, and SAT18-EXP, 54</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>features are computed using the SATZilla feature extraction code</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@satzilla</span><span class="co">]</span>. For IPC2018, feature extraction tool by</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014</span><span class="co">]</span> generated 305</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>features. The scenarios, data and features of our experiments align with</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>those used in <span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>, as summarized in</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#tab:scenarios6)</span>{reference-type="ref"</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>reference="tab:scenarios6"}.</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>The data were collected on compute nodes with 32 processors, a 40 MB</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>cache (Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz), and 128 GB of memory,</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>running Red Hat Linux version 8.6. We adhered to the ASlib time limits:</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>5000 CPU seconds for SAT18-EXP, SAT11-INDU, and SAT16-MAIN; 3600 seconds</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>for MAXSAT19-UCMS; and 1800 seconds for IPC2018. Each algorithm was</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>individually executed over 2 to 10 parallel runs during data collection.</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>::: {#tab:scenarios6}</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>  Scenario         Algorithms   Instances   Instance Features  </span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>  --------------- ------------ ----------- ------------------- --</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>  IPC2018              15          240             305         </span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>  MAXSAT19-UCMS        7           572             54          </span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>  SAT11-INDU           14          300             54          </span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>  SAT16-MAIN           25          274             54          </span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>  SAT18-EXP            37          353             54          </span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>  : Number of Algorithms, Instances, and Features Across All Scenarios.</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training and Tuning</span></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>We constructed random forest regression models using the Ranger</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>implementation from the MLR3 package <span class="co">[</span><span class="ot">@ranger</span><span class="co">]</span> in R to predict the</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>algorithm performance in specific instances. Although we previously</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>presented results from various random forest implementations in R, this</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>chapter focuses exclusively on Ranger models to compare the performance</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>of models trained on sequential data with those trained on parallel</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>data. Our setup closely follows the methodology outlined in Chapter 4</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>and in <span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>: we excluded instance features with constant</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>values and imputed missing feature values using the mean of all</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>nonmissing values for each feature. The random forest hyperparameters</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>were optimized using random search with 250 iterations, varying $ntree$</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>between 10 and 200 and mtry between 1 and 30. Nested cross-validation</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>with three inner folds and ten outer folds was used for model evaluation</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>.</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>For training the models with parallel data, we trained 10 models for the</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>SAT11-INDU, SAT16-MAIN, SAT18-EXP, and IPC2018 scenarios, and 7 models</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>for the MAXSAT19-UCMS scenario, as only 7 solvers are available for this</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>benchmark. Each model was trained using the runtimes associated with its</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>specific parallel configuration. For instance, we trained one</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>performance model using the runtimes of algorithms running in parallel</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>with 2 other solvers, another model using the data collected when</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>running 3 solvers in parallel, and so forth.</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>Our random forest regression models, built with the MLR3 and Ranger</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>packages, predict solver runtime as the mean of the underlying</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>distribution and estimate the standard deviation using the Jackknife and</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>Infinitesimal Jackknife methods <span class="co">[</span><span class="ot">@wager2014confidence; @mlr</span><span class="co">]</span>. The</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>Jackknife method calculates the standard deviation of the mean</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>predictions in all training observations. In this approach, the random</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>forest model is trained on $n-1$ observations, leaving one out for</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>prediction, and this process is repeated for each observation. The mean</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>prediction for each tree is calculated by averaging its predictions for</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>the left-out observations. The Jackknife method assumes a normal</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>distribution of the predictions, where the standard deviation quantifies</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>the uncertainty of the overall prediction. The Infinitesimal Jackknife</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>method, rather than completely removing observations, assigns them a</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>small weight to account for their influence on the model.</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>The tuned $p_{\cap}$ values of</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>Equation&nbsp;<span class="co">[</span><span class="ot">\[eq:7\]</span><span class="co">](#eq:7)</span>{reference-type="ref" reference="eq:7"} for</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>each benchmark and model are provided in Table</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">\[tab:pcap\]</span><span class="co">](#tab:pcap)</span>{reference-type="ref" reference="tab:pcap"}.</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>These values were individually optimized for each scenario to ensure</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>that the selected portfolio achieved an optimal balance between</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>performance and computational efficiency.</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>We first compare the predictions of the performance models trained on</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>sequential data with those trained on data collected under different</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>levels of parallelism. The analysis was performed using the McNemar test</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>to assess whether there are significant differences in predictive</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>performance between the sequential and parallel models in various</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>scenarios. For each scenario, models trained on sequential data were</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>compared with models trained on parallel data, involving varying numbers</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>of parallel runs, ranging from 2 to the maximum number of solvers</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>available for each scenario. We used contingency tables to capture the</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>outcomes: instances where both models made correct or incorrect</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>predictions and instances where one model succeeded while the other</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>failed. The McNemar test provided p-values and test statistics for each</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>comparison. The resulting $p-values$ indicate significant differences</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>between the predictions of sequential and parallel models across all</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>with significant level $\alpha = 0.05$ configurations. For example, in</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>the MAXSAT2019 scenario, the $p-value$ for models trained with 2</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>parallel runs was $2.51e-8$, highlighting substantial differences in</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>their predictions compared to sequential models. Similar trends were</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>observed in other scenarios, such as IPC2018 and SAT18-EXP, where</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>p-values remained very low at different levels of parallelism. These</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>results demonstrate that the predictions of sequential models are</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>notably distinct from those of parallel models, with significant</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>differences observed in most scenarios and configurations.</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>Although the McNemar tests showed that the predictions are significantly</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>different, we further investigated the Critical Difference (CD). CD</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>analysis reveals that while the predictions of algorithm selectors</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>trained in sequential and parallel data may vary, their ranking among</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>the models on the five benchmarks is not significantly different at</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>$\alpha = 0.05$. Using a critical difference value of 6.06 (calculated</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>for 10 models and 5 datasets), the CD diagram in</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#fig:critical)</span>{reference-type="ref"</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>reference="fig:critical"} confirms that the variations in average ranks</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>fall within the nonsignificant range. For instance, the average ranks of</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>the models show minor differences across parallel configurations (e.g.,</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>the Sequential model has an average rank of 4.11 compared to the \"10</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>parallel runs\" model with 6.12), but these differences do not exceed</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>the CD threshold. The rankings of the average ranks matrix in</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:rank_mat)</span>{reference-type="ref"</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>reference="tab:rank_mat"} highlight consistent algorithm selection</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>performance trends in datasets such as MAXSAT2019, IPC2018, SAT11-INDU,</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN and SAT18-EXP. Although individual rankings may differ</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>slightly between scenarios, the overall rankings do not exhibit</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>significant divergence. This suggests that algorithm selectors, whether</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>trained in sequential or parallel data, produce models that rank</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>algorithms similarly in terms of performance when evaluated across</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>multiple datasets.</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>[]{#tab:scenarios2 label="tab:scenarios2"}</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>::: {#tab:scenarios2}</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>  Model               MAXSAT19-UCMS   IPC2018    SAT11-INDU   SAT16-MAIN   SAT18-EXP</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>  ------------------ --------------- ---------- ------------ ------------ -----------</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>  2 parallel runs       2.51e-08      3.39e-02    4.53e-03     4.54e-04    6.17e-04</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>  3 parallel runs       2.19e-06      4.89e-03    2.85e-02     1.42e-03    2.29e-04</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>  4 parallel runs       3.97e-04      9.51e-04    1.05e-03     1.26e-03    2.97e-04</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>  5 parallel runs       3.15e-05      1.39e-03    5.66e-03     1.56e-03    7.66e-04</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>  6 parallel runs       8.25e-04      5.85e-03    4.01e-03     9.37e-04    3.83e-04</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>  7 parallel runs       3.80e-03      8.97e-03    3.68e-02     3.82e-03    6.14e-06</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>  8 parallel runs          --         4.65e-04    1.13e-03     1.76e-04    6.85e-06</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>  9 parallel runs          --         4.07e-04    4.67e-02     1.09e-03    1.28e-04</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>  10 parallel runs         --         2.16e-04    5.07e-03     1.09e-03    2.28e-05</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>  : P-values for McNemar tests comparing models trained on parallel data</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>  with the model trained on sequential data. The McNemar tests were</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a>  conducted by selecting the top single solver based on the performance</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>  model and constructing the corresponding 2x2 contingency matrix.</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>::: {#tab:rank_mat}</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>                   **Seq.**   **2p**   **3p**   **4p**   **5p**   **6p**   **7p**   **8p**   **9p**   **10p**</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>  --------------- ---------- -------- -------- -------- -------- -------- -------- -------- -------- ---------</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>  MAXSAT19-UCMS      3.42      3.65     4.01     3.92     4.21     4.42     4.38      --       --       --</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>  IPC2018            3.88      4.59     4.94     5.19     5.28     5.96     5.69     6.19     6.58     6.69</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>  SAT11-INDU         4.18      4.58     4.67     5.25     5.28     5.83     5.88     6.34     6.32     6.68</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>  SAT16-MAIN         5.13      4.98     4.85     5.07     5.42     5.53     5.61     5.77     6.51     6.13</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>  SAT18-EXP          3.94      4.80     5.11     5.61     5.55     6.01     6.17     6.44     6.40     4.99</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>  **Average**        4.11      4.52     4.71     5.01     5.15     5.55     5.54     6.19     6.45     6.12</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>  : Ranking Matrix for Critical Difference</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:critical"&gt;</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>&lt;img src="plots/Alternating_Label_Critical_Difference_Diagram.png" style="width:95%"/&gt;</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt;Critical Difference Diagram. This figure shows the average</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>ranking of each performance model trained at different levels of</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>parallelism, based on the actual performance of the selected algorithms.</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>The CD of 6.06 means that the Critical Difference (CD) threshold for</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>determining statistically significant differences in rankings is 6.06.</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>If the difference in average rankings between two models is greater than</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>6.06, the rankings are considered statistically significantly different</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>at a significance level of &lt;span</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>\alpha=0.05<span class="sc">\)</span>&lt;/span&gt;.&lt;/figcaption&gt;</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a><span class="fu">### Baselines</span></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>Although the algorithm selection rankings did not show significant</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>differences in algorithm selection in these five scenarios, we evaluated</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>the performance of the dynamic parallel portfolio approach against</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>several baseline methods using sequential and parallel data-trained</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>models. Specifically, we compared the results to the sequential Virtual</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>Best Solver (VBS), which selects the best solver for each problem</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>instance with a cumulative misclassification penalty of zero, and the</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a>sequential Single Best Solver (SBS), which is the solver with the best</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a>average performance across all instances and has a cumulative</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a>misclassification penalty of one. For parallel runs, the VBS selects the</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>best solver for each instance but accounts for the overhead of $n$</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>parallel runs. The parallel SBS is determined similarly, based on the</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>solver with the best average performance across all instances instead of</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a>the best solver for each instance. To ensure a realistic evaluation, we</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>executed multiple solvers in parallel to measure the actual runtime of</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>the best solver in this setup, rather than assuming it would run</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>sequentially.</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>We used two methods to train algorithm selectors: one trained using</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>Ranger with the Jackknife method and another using Ranger with the</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a>Infinitesimal Jackknife method to estimate the uncertainty of</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>predictions. Initially, we trained models on sequential data and then</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>trained performance models on parallel performance data</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>($AS_{\parallel}$). In the $AS_{\parallel}$ method, to predict</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>performance for $n$ parallel runs, we used the predictions of the</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>performance model trained on data collected from $n$ parallel runs.</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>We evaluated the proposed approach using three metrics: penalized</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>average runtime with a factor of 10 (PAR10), misclassification penalty</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>(MCP), and runtime. The PAR10 metric corresponds to the actual runtime</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>if the algorithm successfully solves the instance within the timeout;</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>otherwise, it is calculated as the timeout multiplied by 10. The MCP</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>represents the difference between the performance of the selected</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>algorithm and that of the optimal algorithm. To ensure comparability</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>across scenarios, all performance metrics are normalized relative to the</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>Virtual Best Solver (VBS) and Single Best Solver (SBS). The results,</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>shown in Figure&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#fig:parallelvssequential)</span>{reference-type="ref"</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>reference="fig:parallelvssequential"}, depict the proportion of the</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a>performance gap closed by each approach. On this normalized scale, a</span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a>value of 0 corresponds to the performance of the SBS, while a value of 1</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a>corresponds to the performance of the VBS.</span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a><span class="fu">## Results</span></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>We experimented with training Ranger models using parallel data to</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a>compare their performance with models trained on sequential data.</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>Figures&nbsp;<span class="co">[</span><span class="ot">\[fig:rangervsrf\]</span><span class="co">](#fig:rangervsrf)</span>{reference-type="ref"</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>reference="fig:rangervsrf"} present the PAR10 score results in terms of</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>the normalized performance gap between the sequential Single Best Solver</span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>(SBS) and the sequential Virtual Best Solver (VBS) across all scenarios</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>and processor counts. These figures specifically compare Ranger models</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>trained with the Infinitesimal Jackknife method. Additionally,</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary6-ipc-max)</span>{reference-type="ref"</span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>reference="tab:summary6-ipc-max"},&nbsp;<span class="co">[</span><span class="ot">1.5</span><span class="co">](#tab:summary6-sat11-sat16)</span>{reference-type="ref"</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>reference="tab:summary6-sat11-sat16"}</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>and&nbsp;<span class="co">[</span><span class="ot">1.6</span><span class="co">](#tab:summary6-sat18)</span>{reference-type="ref"</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>reference="tab:summary6-sat18"} provide the exact runtime,</span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>Misclassification Penalty (MCP), and PAR10 scores for the methods,</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a>limiting the maximum number of parallel runs to 10 for SAT18-EXP,</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN, SAT11-INDU, and IPC2018, and to 7 for MAXSAT19-UCMS.</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:parallelvssequential"&gt;</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a>&lt;embed</span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a>src="plots/pl_pcap_comparison_line_chart_parallel_NormalizedGap.svg" style="width:95%"/&gt;</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt; Results Overview. The plot illustrates the extent to which</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a>each method narrows the gap between the PAR10 scores of the Single Best</span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a>Solver (SBS) and the Virtual Best Solver (VBS). For VBS and SBS, the top</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a>&lt;span class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; solvers are selected, where &lt;span</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; matches the number of processors</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>available for each problem instance and across all instances,</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a>respectively. &lt;span class="math inline"&gt;<span class="sc">\(</span>AS_0<span class="sc">\)</span>&lt;/span&gt; selects the top</span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>&lt;span class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; solvers as predicted by algorithm</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a>selection, disregarding any overlap in their predicted runtime</span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>distributions. &lt;span class="math inline"&gt;<span class="sc">\(</span>AS_{p_{\cap}}<span class="sc">\)</span>&lt;/span&gt;</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>follows the approach proposed in &lt;span class="citation"</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a>data-cites="kashgarani2023automatic"&gt;&lt;/span&gt;, with the number of</span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>processors capped at the specific value on the x-axis — fewer solvers</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a>than this maximum may be selected based on the overlap in runtime</span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>predictions. The algorithm selection here is Ranger model with the</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>Infinitesimal Jackknife method for predicting uncertainty. The &lt;span</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>\parallel<span class="sc">\)</span>&lt;/span&gt; symbol is referring to the</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>performance model trained on parallel data. &lt;/figcaption&gt;</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary6-ipc-max}</span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                           Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                           MCP                               PAR10                             NormalizedGap</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>  ---------- --------------------------------------- ----------------------------------- --------------------------------- ------------------------------------ -------------------------------------</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                                    </span></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                        508$\pm$`&lt;!-- --&gt;`{=html}697                     0                    3478$\pm$`&lt;!-- --&gt;`{=html}6903                      1</span></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                                    608$\pm$`&lt;!-- --&gt;`{=html}751       100$\pm$`&lt;!-- --&gt;`{=html}293       4456$\pm$`&lt;!-- --&gt;`{=html}7583       -0.35$\pm$`&lt;!-- --&gt;`{=html}2.85</span></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                                    604$\pm$`&lt;!-- --&gt;`{=html}752        96$\pm$`&lt;!-- --&gt;`{=html}293       4519$\pm$`&lt;!-- --&gt;`{=html}7633       -0.39$\pm$`&lt;!-- --&gt;`{=html}2.84</span></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                        734$\pm$`&lt;!-- --&gt;`{=html}770       226$\pm$`&lt;!-- --&gt;`{=html}414       5459$\pm$`&lt;!-- --&gt;`{=html}8072                      0</span></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                                  </span></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                                616$\pm$`&lt;!-- --&gt;`{=html}783       107$\pm$`&lt;!-- --&gt;`{=html}312       5206$\pm$`&lt;!-- --&gt;`{=html}8065       -0.69$\pm$`&lt;!-- --&gt;`{=html}2.54</span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                                616$\pm$`&lt;!-- --&gt;`{=html}783       107$\pm$`&lt;!-- --&gt;`{=html}312       5206$\pm$`&lt;!-- --&gt;`{=html}8065       -0.69$\pm$`&lt;!-- --&gt;`{=html}2.54</span></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.44}$ (RI)              **557$\pm$`&lt;!-- --&gt;`{=html}728**    **49$\pm$`&lt;!-- --&gt;`{=html}190**   **4135$\pm$`&lt;!-- --&gt;`{=html}7403**   **-0.19$\pm$`&lt;!-- --&gt;`{=html}2.89**</span></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.27}$ (RJ)                570$\pm$`&lt;!-- --&gt;`{=html}744       *62$\pm$`&lt;!-- --&gt;`{=html}229*      4350$\pm$`&lt;!-- --&gt;`{=html}7552      *-0.21$\pm$`&lt;!-- --&gt;`{=html}2.72*</span></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RI)$                    615$\pm$`&lt;!-- --&gt;`{=html}782       107$\pm$`&lt;!-- --&gt;`{=html}311       5205$\pm$`&lt;!-- --&gt;`{=html}8065       -0.69$\pm$`&lt;!-- --&gt;`{=html}2.55</span></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RJ)$                    619$\pm$`&lt;!-- --&gt;`{=html}786       112$\pm$`&lt;!-- --&gt;`{=html}322       5277$\pm$`&lt;!-- --&gt;`{=html}8102       -0.71$\pm$`&lt;!-- --&gt;`{=html}2.54</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.44} (RI)$      581$\pm$`&lt;!-- --&gt;`{=html}743        73$\pm$`&lt;!-- --&gt;`{=html}252       4428$\pm$`&lt;!-- --&gt;`{=html}7596       -0.34$\pm$`&lt;!-- --&gt;`{=html}2.67</span></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.27} (RJ)$      608$\pm$`&lt;!-- --&gt;`{=html}771       100$\pm$`&lt;!-- --&gt;`{=html}304       4996$\pm$`&lt;!-- --&gt;`{=html}7946       -1.5$\pm$`&lt;!-- --&gt;`{=html}5.65</span></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                                    </span></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                        858$\pm$`&lt;!-- --&gt;`{=html}1476                    0                   7768$\pm$`&lt;!-- --&gt;`{=html}14717                      1</span></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                                   1076$\pm$`&lt;!-- --&gt;`{=html}1575      218$\pm$`&lt;!-- --&gt;`{=html}729      9686$\pm$`&lt;!-- --&gt;`{=html}15850       0.45$\pm$`&lt;!-- --&gt;`{=html}0.34</span></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                                   1044$\pm$`&lt;!-- --&gt;`{=html}1565      186$\pm$`&lt;!-- --&gt;`{=html}666      9540$\pm$`&lt;!-- --&gt;`{=html}15793       0.49$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                       1190$\pm$`&lt;!-- --&gt;`{=html}1657      332$\pm$`&lt;!-- --&gt;`{=html}940      11386$\pm$`&lt;!-- --&gt;`{=html}16696                     0</span></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a><span class="in">     2-6     **7 Processors**                                                                                                                                   </span></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a><span class="in">     2-6     $AS_0$ (RI)                              **894$\pm$`&lt;!-- --&gt;`{=html}1506**   **37$\pm$`&lt;!-- --&gt;`{=html}247**   *8258$\pm$`&lt;!-- --&gt;`{=html}15062*     *0.85$\pm$`&lt;!-- --&gt;`{=html}0.16*</span></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                              **894$\pm$`&lt;!-- --&gt;`{=html}1506**   **37$\pm$`&lt;!-- --&gt;`{=html}247**   *8258$\pm$`&lt;!-- --&gt;`{=html}15062*     *0.85$\pm$`&lt;!-- --&gt;`{=html}0.16*</span></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.03}$ (RI)              **894$\pm$`&lt;!-- --&gt;`{=html}1506**   **37$\pm$`&lt;!-- --&gt;`{=html}247**   *8258$\pm$`&lt;!-- --&gt;`{=html}15062*     *0.85$\pm$`&lt;!-- --&gt;`{=html}0.16*</span></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.14}$ (RJ)                921$\pm$`&lt;!-- --&gt;`{=html}1521       63$\pm$`&lt;!-- --&gt;`{=html}369      8568$\pm$`&lt;!-- --&gt;`{=html}15263       0.76$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RI)$                  **894$\pm$`&lt;!-- --&gt;`{=html}1506**   **37$\pm$`&lt;!-- --&gt;`{=html}247**   *8258$\pm$`&lt;!-- --&gt;`{=html}15062*     *0.85$\pm$`&lt;!-- --&gt;`{=html}0.16*</span></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RJ)$                  **894$\pm$`&lt;!-- --&gt;`{=html}1506**   **37$\pm$`&lt;!-- --&gt;`{=html}247**   *8258$\pm$`&lt;!-- --&gt;`{=html}15062*     *0.85$\pm$`&lt;!-- --&gt;`{=html}0.16*</span></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.03} (RI)$    **894$\pm$`&lt;!-- --&gt;`{=html}1506**   **37$\pm$`&lt;!-- --&gt;`{=html}247**   *8258$\pm$`&lt;!-- --&gt;`{=html}15062*     *0.85$\pm$`&lt;!-- --&gt;`{=html}0.16*</span></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.14} (RJ)$      939$\pm$`&lt;!-- --&gt;`{=html}1534       82$\pm$`&lt;!-- --&gt;`{=html}442      8756$\pm$`&lt;!-- --&gt;`{=html}15379       0.71$\pm$`&lt;!-- --&gt;`{=html}0.31</span></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>  of processors (10 for IPC2018, and 7 for MAXSAT19-UCMS) for our</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a>  approaches and the baselines we compare to. All numbers were rounded</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a>  to integers. The best value for each scenario and measure is shown in</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a>  **bold** (excepting the sequential VBS, which is by definition always</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a>  the best), the second best in *italics*. The normalized gap closed</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>  represents the mean and standard deviation of the normalized gap</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a>  closed across the folds.</span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary6-sat11-sat16}</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                           Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                            MCP                                 PAR10                             NormalizedGap</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>  ---------- --------------------------------------- ------------------------------------ ---------------------------------- -------------------------------------- -----------------------------------</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                                        </span></span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                        1140$\pm$`&lt;!-- --&gt;`{=html}1836                    0                     8040$\pm$`&lt;!-- --&gt;`{=html}17905                      1</span></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                                    1610$\pm$`&lt;!-- --&gt;`{=html}2108      470$\pm$`&lt;!-- --&gt;`{=html}1145       12710$\pm$`&lt;!-- --&gt;`{=html}21389      -0.06$\pm$`&lt;!-- --&gt;`{=html}0.9</span></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                                    1565$\pm$`&lt;!-- --&gt;`{=html}2049      425$\pm$`&lt;!-- --&gt;`{=html}1017       11315$\pm$`&lt;!-- --&gt;`{=html}20402      0.34$\pm$`&lt;!-- --&gt;`{=html}0.49</span></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                        1818$\pm$`&lt;!-- --&gt;`{=html}2168      678$\pm$`&lt;!-- --&gt;`{=html}1340       14268$\pm$`&lt;!-- --&gt;`{=html}22154                     0</span></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                                      </span></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                               *1238$\pm$`&lt;!-- --&gt;`{=html}1892*     *127$\pm$`&lt;!-- --&gt;`{=html}385*     *8588$\pm$`&lt;!-- --&gt;`{=html}18350*     **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                                1262$\pm$`&lt;!-- --&gt;`{=html}1910       151$\pm$`&lt;!-- --&gt;`{=html}480       8612$\pm$`&lt;!-- --&gt;`{=html}18342      **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.01}$ (RI)              **1236$\pm$`&lt;!-- --&gt;`{=html}1890**   **121$\pm$`&lt;!-- --&gt;`{=html}379**   **8586$\pm$`&lt;!-- --&gt;`{=html}18351**    **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)                1289$\pm$`&lt;!-- --&gt;`{=html}1934       178$\pm$`&lt;!-- --&gt;`{=html}595       9089$\pm$`&lt;!-- --&gt;`{=html}18787       0.78$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RI)$                    1276$\pm$`&lt;!-- --&gt;`{=html}1926       166$\pm$`&lt;!-- --&gt;`{=html}546       8926$\pm$`&lt;!-- --&gt;`{=html}18643       0.89$\pm$`&lt;!-- --&gt;`{=html}0.13</span></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RJ)$                    1286$\pm$`&lt;!-- --&gt;`{=html}1939       175$\pm$`&lt;!-- --&gt;`{=html}564       8936$\pm$`&lt;!-- --&gt;`{=html}18640       0.88$\pm$`&lt;!-- --&gt;`{=html}0.12</span></span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.01} (RI)$      1279$\pm$`&lt;!-- --&gt;`{=html}1929       162$\pm$`&lt;!-- --&gt;`{=html}530       9079$\pm$`&lt;!-- --&gt;`{=html}18791       0.78$\pm$`&lt;!-- --&gt;`{=html}0.27</span></span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.31} (RJ)$      1365$\pm$`&lt;!-- --&gt;`{=html}2004       247$\pm$`&lt;!-- --&gt;`{=html}794       10065$\pm$`&lt;!-- --&gt;`{=html}19605      0.64$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                                        </span></span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                        1867$\pm$`&lt;!-- --&gt;`{=html}2193                    0                     15005$\pm$`&lt;!-- --&gt;`{=html}22530                     1</span></span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                                    2383$\pm$`&lt;!-- --&gt;`{=html}2294      516$\pm$`&lt;!-- --&gt;`{=html}1151       19956$\pm$`&lt;!-- --&gt;`{=html}24111      0.05$\pm$`&lt;!-- --&gt;`{=html}0.66</span></span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                                    2400$\pm$`&lt;!-- --&gt;`{=html}2269      533$\pm$`&lt;!-- --&gt;`{=html}1177       19316$\pm$`&lt;!-- --&gt;`{=html}23880       0.3$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                        2560$\pm$`&lt;!-- --&gt;`{=html}2294      693$\pm$`&lt;!-- --&gt;`{=html}1415       21940$\pm$`&lt;!-- --&gt;`{=html}24464                     0</span></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a><span class="in">     2-6     **10 Processors**                                                                                                                                      </span></span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a><span class="in">     2-6     $AS_0$ (RI)                              **2016$\pm$`&lt;!-- --&gt;`{=html}2225**   **150$\pm$`&lt;!-- --&gt;`{=html}503**    *16469$\pm$`&lt;!-- --&gt;`{=html}23122*      0.68$\pm$`&lt;!-- --&gt;`{=html}0.6</span></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                                2048$\pm$`&lt;!-- --&gt;`{=html}2228       181$\pm$`&lt;!-- --&gt;`{=html}597     **16336$\pm$`&lt;!-- --&gt;`{=html}23023**    0.68$\pm$`&lt;!-- --&gt;`{=html}0.59</span></span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)                 **2016$\pm$`&lt;!-- --&gt;`{=html}2225**   **150$\pm$`&lt;!-- --&gt;`{=html}503**    *16469$\pm$`&lt;!-- --&gt;`{=html}23122*      0.68$\pm$`&lt;!-- --&gt;`{=html}0.6</span></span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.33}$ (RJ)                2088$\pm$`&lt;!-- --&gt;`{=html}2239       222$\pm$`&lt;!-- --&gt;`{=html}704       16705$\pm$`&lt;!-- --&gt;`{=html}23156      0.64$\pm$`&lt;!-- --&gt;`{=html}0.37</span></span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RI)$                    2053$\pm$`&lt;!-- --&gt;`{=html}2246       186$\pm$`&lt;!-- --&gt;`{=html}593       16505$\pm$`&lt;!-- --&gt;`{=html}23101     *0.79$\pm$`&lt;!-- --&gt;`{=html}0.49*</span></span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RJ)$                   *2040$\pm$`&lt;!-- --&gt;`{=html}2223*     *174$\pm$`&lt;!-- --&gt;`{=html}579*      16000$\pm$`&lt;!-- --&gt;`{=html}22864     **0.8$\pm$`&lt;!-- --&gt;`{=html}0.34**</span></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0} (RI)$         2053$\pm$`&lt;!-- --&gt;`{=html}2246       186$\pm$`&lt;!-- --&gt;`{=html}593       16505$\pm$`&lt;!-- --&gt;`{=html}23101     *0.79$\pm$`&lt;!-- --&gt;`{=html}0.49*</span></span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.33} (RJ)$      2197$\pm$`&lt;!-- --&gt;`{=html}2271       330$\pm$`&lt;!-- --&gt;`{=html}924       17635$\pm$`&lt;!-- --&gt;`{=html}23454       0.6$\pm$`&lt;!-- --&gt;`{=html}0.43</span></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>  of processors (10 for SAT16-MAIN and SAT11-INDU) for our approaches</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>  and the baselines we compare to. All numbers were rounded to integers.</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a>  The best value for each scenario and measure is shown in **bold**</span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>  (excepting the sequential VBS, which is by definition always the</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>  best), the second best in *italics*. The normalized gap closed</span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>  represents the mean and standard deviation of the normalized gap</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a>  closed across the folds.</span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary6-sat18}</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                           Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                             MCP                                 PAR10                             NormalizedGap</span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>  ---------- --------------------------------------- ------------------------------------ ----------------------------------- -------------------------------------- -----------------------------------</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                                         </span></span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                        1146$\pm$`&lt;!-- --&gt;`{=html}1945                     0                     9687$\pm$`&lt;!-- --&gt;`{=html}19547                      1</span></span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                                    1648$\pm$`&lt;!-- --&gt;`{=html}2151       502$\pm$`&lt;!-- --&gt;`{=html}1256       13758$\pm$`&lt;!-- --&gt;`{=html}22034      0.59$\pm$`&lt;!-- --&gt;`{=html}0.18</span></span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                                    1690$\pm$`&lt;!-- --&gt;`{=html}2170       543$\pm$`&lt;!-- --&gt;`{=html}1302       14183$\pm$`&lt;!-- --&gt;`{=html}22247      0.57$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                        2400$\pm$`&lt;!-- --&gt;`{=html}2249      1254$\pm$`&lt;!-- --&gt;`{=html}1832       20629$\pm$`&lt;!-- --&gt;`{=html}24280                     0</span></span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                                       </span></span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RI)                                1654$\pm$`&lt;!-- --&gt;`{=html}2285       511$\pm$`&lt;!-- --&gt;`{=html}1324       15804$\pm$`&lt;!-- --&gt;`{=html}23194      0.42$\pm$`&lt;!-- --&gt;`{=html}0.29</span></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_0$ (RJ)                                1678$\pm$`&lt;!-- --&gt;`{=html}2288       535$\pm$`&lt;!-- --&gt;`{=html}1351       15956$\pm$`&lt;!-- --&gt;`{=html}23243       0.4$\pm$`&lt;!-- --&gt;`{=html}0.3</span></span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.55}$ (RI)              **1541$\pm$`&lt;!-- --&gt;`{=html}2191**   **397$\pm$`&lt;!-- --&gt;`{=html}1177**   **14034$\pm$`&lt;!-- --&gt;`{=html}22332**   **0.6$\pm$`&lt;!-- --&gt;`{=html}0.21**</span></span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.58}$ (RJ)                1622$\pm$`&lt;!-- --&gt;`{=html}2237       477$\pm$`&lt;!-- --&gt;`{=html}1268       15008$\pm$`&lt;!-- --&gt;`{=html}22805       0.5$\pm$`&lt;!-- --&gt;`{=html}0.25</span></span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RI)$                    1709$\pm$`&lt;!-- --&gt;`{=html}2303       566$\pm$`&lt;!-- --&gt;`{=html}1397       16242$\pm$`&lt;!-- --&gt;`{=html}23351       0.4$\pm$`&lt;!-- --&gt;`{=html}0.21</span></span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel 0} (RJ)$                    1676$\pm$`&lt;!-- --&gt;`{=html}2294       533$\pm$`&lt;!-- --&gt;`{=html}1358       15954$\pm$`&lt;!-- --&gt;`{=html}23245      0.42$\pm$`&lt;!-- --&gt;`{=html}0.22</span></span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.55} (RI)$      1624$\pm$`&lt;!-- --&gt;`{=html}2217       478$\pm$`&lt;!-- --&gt;`{=html}1218       14754$\pm$`&lt;!-- --&gt;`{=html}22660       0.54$\pm$`&lt;!-- --&gt;`{=html}0.2</span></span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{\parallel p_{\cap} = 0.58} (RJ)$      1708$\pm$`&lt;!-- --&gt;`{=html}2269       563$\pm$`&lt;!-- --&gt;`{=html}1363       15730$\pm$`&lt;!-- --&gt;`{=html}23095      0.43$\pm$`&lt;!-- --&gt;`{=html}0.25</span></span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a>  of processors (10 for SAT18-EXP) for our approaches and the baselines</span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a>  we compare to. All numbers were rounded to integers. The best value</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a>  for each scenario and measure is shown in **bold** (excepting the</span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>  sequential VBS, which is by definition always the best), the second</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a>  best in *italics*. The normalized gap closed represents the mean and</span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>  standard deviation of the normalized gap closed across the folds.</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:numberofsolvers_kl"&gt;</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;embed src="plots/number_of_solvers_infjack_pcap_parallel.svg"</span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a>style="width:50.0%" /&gt; &lt;embed</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a>src="plots/number_of_solvers_jack_pcap_parallel.svg"</span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>style="width:50.0%" /&gt;&lt;/p&gt;</span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt; Violin plot of the distribution of the number of selected</span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a>solvers to run in parallel across all problem instances for each</span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a>scenario for the respective optimal &lt;span</span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>p_{\cap}<span class="sc">\)</span>&lt;/span&gt; and the maximum level of</span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a>parallelism (seven processors for MAXSAT19-UCMS and 10 for all other</span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a>scenarios). The diamond denotes the mean value. The top-left plot refers</span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a>to the RFJ model, the top-right plot to the RI model, and the bottom</span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a>plot to the RJ model. &lt;/figcaption&gt;</span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a>When comparing models trained on sequential data with those trained on</span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a>parallel data for portfolio selection, the model trained on sequential</span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a>data consistently outperforms the model trained on parallel data. This</span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a>is evident in</span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">\[tab:summary5-ipc-max\]</span><span class="co">](#tab:summary5-ipc-max)</span>{reference-type="ref"</span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-ipc-max"},</span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">\[tab:summary5-sat11-sat16\]</span><span class="co">](#tab:summary5-sat11-sat16)</span>{reference-type="ref"</span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat11-sat16"}</span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a>and&nbsp;<span class="co">[</span><span class="ot">\[tab:summary5-sat18\]</span><span class="co">](#tab:summary5-sat18)</span>{reference-type="ref"</span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat18"}, which show that both the $AS_0$ and</span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a>$AS_{p_{\cap}}$ methods are superior to $AS_{\parallel 0}$ and</span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a>$AS_{\parallel p_{\cap}}$, respectively. This holds for both the RJ and</span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a>RI models in all scenarios, except when comparing $AS_0$ and</span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a>$AS_{\parallel 0}$ for SAT16-MAIN and SAT18-EXP, where the RJ model</span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a>performs slightly better. In</span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#fig:parallelvssequential)</span>{reference-type="ref"</span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a>reference="fig:parallelvssequential"}, for the RI model with a number of</span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a>parallel runs limited to 10, the $AS_{\cap}$ method, using a model</span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a>trained on sequential data, emerges as the best approach to portfolio</span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a>selection.</span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusions</span></span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a>In this chapter, we explore the impact of training algorithm selectors</span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a>using parallel data versus sequential data for parallel portfolio</span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a>selection. Using both sequential and parallel performance models, our</span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a>objective was to understand whether incorporating data collected under</span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a>parallel execution conditions would offer a significant advantage in</span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a>portfolio selection tasks. Our initial analysis reveals that while</span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a>predictions of algorithm selectors trained on parallel data differ</span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a>significantly from those trained on sequential data, their overall</span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>rankings across models on the benchmarks are not significantly</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a>different.</span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a>Furthermore, when comparing the effectiveness of portfolio selection,</span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>models trained on sequential data consistently outperform those trained</span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a>on parallel data in most scenarios. Specifically, the $AS_{p_{\cap}}$</span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a>method trained in sequential data demonstrated superior performance</span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a>compared to its counterpart trained in parallel data</span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a>$AS_{\parallel p_{\cap}}$).</span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a>These findings underscore the robustness of sequentially trained models</span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a>for portfolio selection, even in parallel execution environments.</span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a>Importantly, the results suggest that collecting parallel data may not</span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a>be necessary for effective portfolio selection. Sequential data models</span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a>are just as effective, if not superior, for predicting solver</span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a>performance and guiding efficient portfolio selection. Although parallel</span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>data offers insight into runtime overheads, sequential data models</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a>remain more effective in predicting solver performance and ranking which</span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a>resulted in efficient portfolio selection.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="https://haniyeka.github.io">Website</a> | <a href="https://github.com/haniyeka">GitHub</a> | <a href="https://github.com/uwyo-mallet">UWYO-Mallet</a></p>
</div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>