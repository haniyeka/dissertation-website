<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; Revisiting Parallel Portfolio Selection with KL Divergence – Dynamic Selection of Parallel Portfolio of Algorithms for Solving Combinatorial Problems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter6/ParallelPortfolioSelectionwithParallelDataTraining.html" rel="next">
<link href="../../chapters/chapter4/AutomaticParallelPortfolioSelection.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-8eef5ae80df721a84869b784b4d5419f.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-812d013f591176c02f613616752f8d70.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Revisiting Parallel Portfolio Selection with KL Divergence</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Dynamic Selection of Parallel Portfolio of Algorithms for Solving Combinatorial Problems</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/haniyeka/dissertation-website" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../Dynamic-Selection-of-Parallel-Portfolio-of-Algorithms-for-Solving-Combinatorial-Problems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Abstract</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/Background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Background</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/IsAlgorithmSelectionWorthItComparingSelectingSingleAlgorithmsandParallelExecution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter4/AutomaticParallelPortfolioSelection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic Parallel Portfolio Selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter5/RevisitingParallelPortfolioSelectionwithKLDivergence.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Revisiting Parallel Portfolio Selection with KL Divergence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter6/ParallelPortfolioSelectionwithParallelDataTraining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Parallel Portfolio Selection with Parallel Data Training</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter7/DiscussionandConclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Discussion and Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/appendixA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Appendix</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">6.1</span> Introduction</a></li>
  <li><a href="#revisit-parallel-portfolio-selection" id="toc-revisit-parallel-portfolio-selection" class="nav-link" data-scroll-target="#revisit-parallel-portfolio-selection"><span class="header-section-number">6.2</span> Revisit Parallel Portfolio Selection</a></li>
  <li><a href="#experimental-setup" id="toc-experimental-setup" class="nav-link" data-scroll-target="#experimental-setup"><span class="header-section-number">6.3</span> Experimental Setup</a>
  <ul class="collapse">
  <li><a href="#data-collection" id="toc-data-collection" class="nav-link" data-scroll-target="#data-collection"><span class="header-section-number">6.3.1</span> Data Collection</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training"><span class="header-section-number">6.3.2</span> Training</a></li>
  <li><a href="#tuning-kl-and-p_cap" id="toc-tuning-kl-and-p_cap" class="nav-link" data-scroll-target="#tuning-kl-and-p_cap"><span class="header-section-number">6.3.3</span> Tuning <span class="math inline">\(kl\)</span> and <span class="math inline">\(p_{\cap}\)</span></a></li>
  <li><a href="#baselines" id="toc-baselines" class="nav-link" data-scroll-target="#baselines"><span class="header-section-number">6.3.4</span> Baselines</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">6.4</span> Results</a>
  <ul class="collapse">
  <li><a href="#tuning-of-kl-and-p_cap" id="toc-tuning-of-kl-and-p_cap" class="nav-link" data-scroll-target="#tuning-of-kl-and-p_cap"><span class="header-section-number">6.4.1</span> Tuning of <span class="math inline">\(kl\)</span> and <span class="math inline">\(p_{\cap}\)</span></a></li>
  <li><a href="#as_p_cap-vs.-as_kl-comparison" id="toc-as_p_cap-vs.-as_kl-comparison" class="nav-link" data-scroll-target="#as_p_cap-vs.-as_kl-comparison"><span class="header-section-number">6.4.2</span> <span class="math inline">\(AS_{p_{\cap}}\)</span> vs.&nbsp;<span class="math inline">\(AS_{kl}\)</span> Comparison</a></li>
  </ul></li>
  <li><a href="#conclusions-and-future-work" id="toc-conclusions-and-future-work" class="nav-link" data-scroll-target="#conclusions-and-future-work"><span class="header-section-number">6.5</span> Conclusions and Future Work</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Revisiting Parallel Portfolio Selection with KL Divergence</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">6.1</span> Introduction</h2>
<p>Algorithms designed to solve combinatorial problems often exhibit complementary performance across different problem instances. Therefore, using a portfolio of algorithms frequently demonstrates superior performance compared to selecting the single best solver (SBS) averaged across all instances <span class="citation" data-cites="Huberman1997 GOMES200143">(<a href="#ref-Huberman1997" role="doc-biblioref">Huberman, Lukose, and Hogg 1997</a>; <a href="#ref-GOMES200143" role="doc-biblioref">Gomes and Selman 2001</a>)</span>. Portfolios can either be run in parallel, or a single algorithm can be selected on an instance-by-instance basis by training performance models using machine learning algorithms. However, both methods have drawbacks.</p>
<p>Algorithm selection has proven to be effective in solving different problems such as SAT, constraint programming, and mixed integer programming, as demonstrated by systems such as SATzilla, Hydra, and AutoFolio <span class="citation" data-cites="satzilla lindauer2015autofolio cphydra XuEtAl11">(<a href="#ref-satzilla" role="doc-biblioref">Xu et al. 2008</a>, <a href="#ref-XuEtAl11" role="doc-biblioref">2011</a>; <a href="#ref-lindauer2015autofolio" role="doc-biblioref">Lindauer et al. 2015</a>; <a href="#ref-cphydra" role="doc-biblioref">O’Mahony et al. 2008</a>)</span>. In single algorithm selection, if machine learning models are not well generalized, they might not select the correct best algorithm for a given instance. Although executing the whole portfolio of algorithms seems to avoid this issue, the more solvers that perform computations in parallel, the more time-out computations we will encounter <span class="citation" data-cites="pmlr-v140-kashgarani21a LINDAUER2017272">(<a href="#ref-pmlr-v140-kashgarani21a" role="doc-biblioref">Kashgarani and Kotthoff 2021</a>; <a href="#ref-LINDAUER2017272" role="doc-biblioref">Lindauer et al. 2017</a>)</span>. However, the proposed parallel portfolio approaches often simulate parallel execution based on sequential data, which conceals the significant overhead and performance drop that occurs when many algorithms run parallel.</p>
<p>Based on the results presented in the third chapter, even with a small number of solvers, selecting a single algorithm using the imperfect regression random forest ML model can outperform parallel portfolios <span class="citation" data-cites="pmlr-v140-kashgarani21a">(<a href="#ref-pmlr-v140-kashgarani21a" role="doc-biblioref">Kashgarani and Kotthoff 2021</a>)</span>. In Chapter 4, we proposed a hybrid approach that leverages both algorithm selection and parallel execution. We introduced a middle-path strategy that identifies the most promising subset of algorithms to run simultaneously on a single non-distributed computer <span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>. This innovative method demonstrated improved performance by utilizing three regression random forest algorithm selectors with different implementations and uncertainty estimation methods.</p>
<p>Using the method proposed in the previous chapter, it is possible to select an instance-based subportfolio of solvers to run in parallel, avoiding the drawbacks of algorithm selection and reducing the overhead associated with running too many solvers simultaneously. This method can achieve optimal or near-optimal performance, provided the virtual best solver is included in the selected subset of algorithms. We used the estimated uncertainty of the predictions while considering the impact of overhead from running the portfolio in parallel.</p>
<p>However, this strategy still has some limitations. Specifically, the threshold value <span class="math inline">\(p_{\cap}\)</span>–which is defined as the threshold for the joint probability between the prediction distributions of the minimum predicted algorithm and other algorithms, and serving as a measure of the likelihood that an algorithm is predicted to perform very closely to the minimum predicted algorithm—could not be generalized across all scenarios and algorithm performance models, as the tuned values varied significantly. Here, we aim to provide an alternative formulation for subportfolio selection that overcomes this limitation.</p>
<p>In this chapter, we revisit the method of selecting the optimal parallel subportfolio of algorithms to run on a single computing machine. Similar to the main proposed method, we incorporate the uncertainty of the performance predictions. Here, rather than using the threshold <span class="math inline">\(p_\cap\)</span> in Equation&nbsp;<a href="#eq:7" data-reference-type="ref" data-reference="eq:7">[eq:7]</a> as an estimate of the probability that the algorithm is as good as the best predicted algorithm, we investigated the use of the Kullback–Leibler (KL) divergence method, which measures the difference between the probability distributions of the predicted algorithms. This method provides an understanding of the differences between algorithm predictions, in contrast to the joint probability approach, which focused on the similarity of predictions. This enables a redefined selection criterion based on the divergence from the best-predicted performance distribution.</p>
</section>
<section id="revisit-parallel-portfolio-selection" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="revisit-parallel-portfolio-selection"><span class="header-section-number">6.2</span> Revisit Parallel Portfolio Selection</h2>
<p>We aim to select a subset of solvers $ P_i S $ for a given instance <span class="math inline">\(i \in I\)</span>, prioritizing algorithms predicted to perform best (<span class="math inline">\(A \in S\)</span> and <span class="math inline">\(A \in P_i\)</span>) based on their predicted performance <span class="math inline">\(\hat{m}\)</span>. For each instance, a total ranking of algorithms in the portfolio <span class="math inline">\(S\)</span> is established using their predicted performance:</p>
<p><span class="math display">\[A &lt; B \quad \text{if} \quad \hat{m}(A, i) &lt; \hat{m}(B, i); A, B \in S\]</span></p>
<p>From this ranking, the rank <span class="math inline">\(r_{A, i}\)</span> is assigned to each algorithm <span class="math inline">\(A\)</span>, representing the number of algorithms predicted to outperform <span class="math inline">\(A\)</span> on instance <span class="math inline">\(i\)</span>. A portfolio of size <span class="math inline">\(n\)</span> is then defined by the top <span class="math inline">\(n\)</span> ranked algorithms:</p>
<p><span class="math display">\[P_i = \{A \in S \: | \: r_{A,i} \leq n\}\]</span></p>
<p>This method allows the selection of a subset of solvers for parallel execution, balancing the likelihood of including the best-performing solver with the overhead of running multiple solvers. However, the critical challenge in parallel portfolios is determining the appropriate portfolio size <span class="math inline">\(n\)</span> for each problem instance. To address this balance, we incorporate the predicted performance distribution of algorithms and their associated uncertainty.</p>
<p>Similar to the proposed method in Chapter 4, instead of considering only a point prediction, we consider the predicted distribution of performance metric values, characterized by its mean and standard deviation. Formally, we denote the standard deviation of the prediction <span class="math inline">\(\hat{m}(A, i)\)</span> as <span class="math inline">\(\sigma_{A, i}\)</span> for each solver <span class="math inline">\(A\)</span> and instance <span class="math inline">\(i\)</span>. We assume that the predictions of our performance models follow a normal distribution, i.e.&nbsp;the predicted value is the mean of that distribution, and allow us to characterize it completely together with the standard deviation. In the previous approach, we assess the likelihood that two algorithms perform equally well by calculating the overlap area between their prediction distributions. If two algorithms are predicted to perform very similarly, then the overlap area between the distributions will be very large. Here, we replace this method by considering the Kullback–Leibler (KL) divergence between the two univariate Gaussian distributions. KL divergence captures the divergence in shape and spread between the distributions.</p>
<p>We are in particular interested in the predicted performance distribution of the best-predicted algorithm <span class="math inline">\(A_{1,i}\)</span> (no algorithms are predicted to perform better than it), and how the predictions for the other algorithms compare to it. Formally, for the best predicted solver <span class="math inline">\(A_{1,i}\)</span> on instance <span class="math inline">\(i\)</span> the distribution of predictions is $ (A_{1,i}, i) (<em>{A</em>{1,i},i}, ^2_{A_{1,i},i}) $ with probability density function $ f_{A_{1,i},i}$ and cumulative distribution function $ F_{A_{1,i},i}$. The performance distributions for other algorithms are defined similarly.</p>
<p>The Kullback–Leibler (KL) divergence is a statistical metric used to quantify the difference between two probability distributions <span class="citation" data-cites="KL">(<a href="#ref-KL" role="doc-biblioref">Kullback and Leibler 1951</a>)</span>. According to the formulation in <span class="citation" data-cites="bishop2006pattern">(<a href="#ref-bishop2006pattern" role="doc-biblioref">Bishop and Nasrabadi 2006</a>)</span>, given two distributions <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> with probability density functions <span class="math inline">\(p(x)\)</span> and <span class="math inline">\(q(x)\)</span>, the KL divergence is calculated as:</p>
<p><span class="math display">\[\label{eq:5.4}
    KL(p \| q) = - \int p(x) \log q(x) \, dx + \int p(x) \log p(x) \, dx\]</span></p>
<p>In our context, we are interested in comparing the predicted performance distributions of two algorithms, <span class="math inline">\(A_{x}\)</span> and <span class="math inline">\(A_{y}\)</span>, on a specific instance <span class="math inline">\(i\)</span>. Let <span class="math inline">\(f_{A_{x},i}\)</span> and <span class="math inline">\(f_{A_{y},i}\)</span> denote the probability density functions of the predicted performance of algorithms <span class="math inline">\(A_{x}\)</span> and <span class="math inline">\(A_{y}\)</span> on instance <span class="math inline">\(i\)</span>, respectively. By substituting <span class="math inline">\(p(x)\)</span> with <span class="math inline">\(f_{A_{x},i}\)</span> and <span class="math inline">\(q(x)\)</span> with <span class="math inline">\(f_{A_{y},i}\)</span>, we adapt the KL divergence to quantify the difference in predicted performance between the two algorithms. Thus, the KL divergence between the performance distributions of <span class="math inline">\(A_{x}\)</span> and <span class="math inline">\(A_{y}\)</span> in instance <span class="math inline">\(i\)</span> is computed as follows:</p>
<p><span class="math display">\[\label{eq:5.5} KL(f_{A_{x},i} \| f_{A_{y},i}) = - \int f_{A_{x},i}(x) \log f_{A_{y},i}(x) dx + \int f_{A_{x},i}(x) \log f_{A_{x},i}(x) dx\]</span></p>
<p>This formulation indicates to what extent the probability distributions differ. Since the two distributions are univariate Gaussians, the exact formula for KL divergence is as follows (we omit the index <span class="math inline">\(i\)</span> for the sake of brevity here):</p>
<p><span class="math display">\[\label{eq:5.6}
    KL(f_{A_x} \| f_{A_y}) = \log \frac{\sigma_{A_y}}{\sigma_{A_x}} + \frac{\sigma_{A_x}^2 + (\mu_{A_x} - \mu_{A_y})^2}{2 \sigma_{A_y}^2} - \frac{1}{2}\]</span></p>
<p>We define <span class="math inline">\(kl \in [0, \infty)\)</span> as a threshold for the computed KL divergence to include a given algorithm:</p>
<p><span class="math display">\[\label{eq:5.7}
P_i = \{A \:| \:  KL(f_{A_{1,i},i} \| f_{A_{x,i},i}) \leq \\kl\:\}\]</span></p>
<p><span class="math inline">\(kl\)</span> is 0 for the best predicted algorithm. In contrast to <span class="math inline">\(p_{\cap}\)</span>, which could only be in the range of [0,1], the value of <span class="math inline">\(kl\)</span> can be greater than 1. A very large value of <span class="math inline">\(kl\)</span> corresponds to algorithms whose distributions diverge the most from that of the best predicted algorithm, that is, algorithms with performance predictions that are markedly different from those of the best predicted algorithm.</p>
<p>We can adjust the size of the parallel portfolio by modifying the <span class="math inline">\(kl\)</span> threshold. When <span class="math inline">\(kl\)</span> is set to 0, only the best predicted algorithm and those expected to perform identically are included. Setting <span class="math inline">\(kl\)</span> to a very large positive value allows all algorithms to be included. Finding the optimal <span class="math inline">\(kl\)</span> is necessary to determine how many solvers to include in the portfolio. This flexibility enables us to tailor the approach to specific algorithm selection scenarios, allowing the selection of algorithms to run in parallel and accommodating any potential inaccuracies in performance predictions.</p>
</section>
<section id="experimental-setup" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="experimental-setup"><span class="header-section-number">6.3</span> Experimental Setup</h2>
<section id="data-collection" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="data-collection"><span class="header-section-number">6.3.1</span> Data Collection</h3>
<p>We used the same five scenarios as in the previous chapter <span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>, now included in the ASlib benchmark repository <span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>: MAXSAT19-UCMS, SAT11-INDU, SAT18-EXP, SAT16-MAIN, and IPC2018. These datasets include algorithm performance data from single and parallel runs, with parallel run measurements conducted on individual machines as described in <span class="citation" data-cites="kashgarani2023automatic">(<a href="#ref-kashgarani2023automatic" role="doc-biblioref">Kashgarani and Kotthoff 2023</a>)</span>. Feature extraction was performed using the SATZilla feature extraction code for MAXSAT19-UCMS, SAT11-INDU, SAT16-MAIN, and SAT18-EXP, producing 54 features, while IPC2018 features were extracted using the code from <span class="citation" data-cites="Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014">(<a href="#ref-Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014" role="doc-biblioref">Fawcett et al. 2014</a>)</span>, resulting in 305 features.</p>
</section>
<section id="training" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="training"><span class="header-section-number">6.3.2</span> Training</h3>
<p>We used the same random forest regression models from Chapter 4. The random forest regression models are trained in three ways: one using the randomForest package in R and two using the Ranger package, to predict algorithm performance on specific instances. Random forests are generally recognized for their strong performance in algorithm selection and performance prediction <span class="citation" data-cites="BISCHL201641 HUTTER201479">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>; <a href="#ref-HUTTER201479" role="doc-biblioref">Hutter et al. 2014</a>)</span>. Given the existence of two distinct implementations, we trained the models using both <em>randomForest</em> and <em>Ranger</em> implementations.</p>
<p>Our regression random forest models are built using the MLR package with the randomForest package as dependency, and the Ranger models are trained using the MLR3 and Ranger implementations. These models predict the runtime for each solver as the mean of the underlying distribution and estimate the standard deviation. The initial random forest model and one of the Ranger models use the Jackknife method <span class="citation" data-cites="wager2014confidence mlr">(<a href="#ref-wager2014confidence" role="doc-biblioref">Wager, Hastie, and Efron 2014</a>; <a href="#ref-mlr" role="doc-biblioref">Bischl, Lang, et al. 2016</a>)</span>. The Jackknife method estimates the standard deviation of the mean predictions in all observations used to train the random forest. This technique involves training the random forest model on <span class="math inline">\(n-1\)</span> observations, leaving one out each time to make a prediction, and repeating this for each observation. The mean prediction for each tree is calculated by averaging its predictions on the left-out data points. The Jackknife method assumes that predictions follow a normal distribution, with the standard deviation indicating the uncertainty of the overall prediction. The infinitesimal jackknife method assesses the impact of each observation by slightly down-weighting it, unlike the traditional jackknife, which removes one observation at a time.</p>
<p>Our setup closely follows the approach in <span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span> for all three models: we excluded instance features with constant values and imputed missing feature values by using the mean of all nonmissing values for each feature. The random forest hyperparameters were tuned through random search with 250 iterations, where <span class="math inline">\(ntree\)</span> was varied from 10 to 200 and <span class="math inline">\(mtry\)</span> from 1 to 30, using nested cross-validation with three inner folds and 10 outer folds <span class="citation" data-cites="BISCHL201641">(<a href="#ref-BISCHL201641" role="doc-biblioref">Bischl, Kerschke, et al. 2016</a>)</span>.</p>
</section>
<section id="tuning-kl-and-p_cap" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3" class="anchored" data-anchor-id="tuning-kl-and-p_cap"><span class="header-section-number">6.3.3</span> Tuning <span class="math inline">\(kl\)</span> and <span class="math inline">\(p_{\cap}\)</span></h3>
<div id="tab:kl">
<table class="caption-top table">
<caption>Optimum value of <span class="math inline">\(kl\)</span> for each benchmark and model.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Scenario</th>
<th style="text-align: center;">RandomForest_Jackknife</th>
<th style="text-align: center;">Ranger_Jackknife</th>
<th style="text-align: center;">Ranger_Inifinitesimal</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">IPC2018</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">2.35</td>
<td style="text-align: center;">2.39</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">MAXSAT19-UCMS</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">2.7</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT11-INDU</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">1.62</td>
<td style="text-align: center;">1.94</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">SAT16-MAIN</td>
<td style="text-align: center;">2.66</td>
<td style="text-align: center;">2.06</td>
<td style="text-align: center;">2.96</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SAT18-EXP</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">1.81</td>
<td style="text-align: center;">1.35</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: left;">Generic best</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">2.65</td>
<td style="text-align: center;">2.82</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>The tuned <span class="math inline">\(p_{\cap}\)</span> value for each benchmark and each random forest model is listed in Table <a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">[tab:pcap]</a> and we are using the same values in this chapter. These values were individually optimized for each scenario to ensure that the selected portfolio provided the best balance between performance and computational efficiency. For tuning <span class="math inline">\(kl\)</span>, we perform a grid search to determine the optimal value in Equation&nbsp;<a href="#eq:5.7" data-reference-type="ref" data-reference="eq:5.7">[eq:5.7]</a> for each scenario. The search is carried out over the interval <span class="math inline">\([0, 3)\)</span> with a resolution <span class="math inline">\(0.01\)</span>, resulting in 300 possible values.</p>
<p>The tuned <span class="math inline">\(p_{\cap}\)</span> value for each benchmark and each random forest model is listed in Table <a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">[tab:pcap]</a>, and we use the same values in this chapter. These values were individually optimized for each scenario to ensure that the selected portfolio provided the best balance between performance and computational efficiency. For tuning <span class="math inline">\(kl\)</span>, we perform a grid search to determine the optimal value in Equation&nbsp;<a href="#eq:5.7" data-reference-type="ref" data-reference="eq:5.7">[eq:5.7]</a> for each scenario. The search is carried out over the interval <span class="math inline">\([0, 3)\)</span> with a resolution of 0.01, resulting in 300 possible values.</p>
</section>
<section id="baselines" class="level3" data-number="6.3.4">
<h3 data-number="6.3.4" class="anchored" data-anchor-id="baselines"><span class="header-section-number">6.3.4</span> Baselines</h3>
<p>For all the comparisons mentioned, we evaluate the performance of our approaches against several baseline methods. Specifically, we compare to the sequential virtual best solver (VBS), which picks the best solver for each problem instance with a cumulative misclassification penalty of zero, and to the sequential single best solver (SBS), which is the solver with the best average performance across all instances and a cumulative misclassification penalty of one. For parallel runs, the VBS is the best solver for each instance but includes the overhead for <span class="math inline">\(n\)</span> parallel runs. The parallel SBS is determined similarly, using the solvers with the best average performance instead of the best for each instance. We executed multiple solvers in parallel to capture the real run-time of the best solver in this setup, instead of assuming that it would run sequentially.</p>
<p>We have three algorithm selectors: RFJ (random forest with Jackknife), RJ (Ranger with Jackknife), and RI (Ranger with infinitesimal Jackknife). Each algorithm selector has five approaches for comparison. The first involves selecting algorithms on a per-instance basis, running the top <span class="math inline">\(n\)</span> predicted algorithms in parallel without accounting for any uncertainty the subportfolio selection approaches. Using the notation introduced in the previous chapter, we assign <span class="math inline">\(p_{\cap}=0\)</span> and limit the number of runs to match the available processors. Also, when we assign <span class="math inline">\(kl = \infty\)</span>, we are doing the same thing and limiting the number of runs to match the available processors. The second approach uses the associated tuned <span class="math inline">\(p_{\cap}\)</span> values mentioned in Table&nbsp;<a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">[tab:pcap]</a>. The third approach uses the average <span class="math inline">\(p_{\cap}\)</span> value, which was the best generic value across all scenarios. Other approach uses the associated tuned <span class="math inline">\(kl\)</span> values mentioned in Table&nbsp;<a href="#tab:kl" data-reference-type="ref" data-reference="tab:kl">1.1</a> for each scenario and performance model. The last approach uses the generic best <span class="math inline">\(kl\)</span> value across all scenarios for each performance model.</p>
<p>We evaluate the proposed method by measuring the penalized average runtime with a factor of 10 (PAR10), the misclassification penalty (MCP), and the runtime. The PAR10 metric equals the actual runtime if the algorithm successfully solves the instance within the timeout; otherwise, it is calculated as the timeout multiplied by 10. The MCP represents the difference between the performance of the selected algorithm and that of the optimal algorithm. The mean and standard deviation of these values are presented in Tables&nbsp;<a href="#tab:summary5-ipc-max" data-reference-type="ref" data-reference="tab:summary5-ipc-max">1.2</a>,<a href="#tab:summary5-sat11-sat16" data-reference-type="ref" data-reference="tab:summary5-sat11-sat16">1.3</a>, and<a href="#tab:summary5-sat18" data-reference-type="ref" data-reference="tab:summary5-sat18">1.4</a>. We normalize PAR10 values across scenarios using the performances of the VBS and SBS, reporting the proportion of the performance gap each approach bridges. On this normalized scale, 0 denotes the performance of the SBS, while 1 denotes the performance of the VBS.</p>
<p>In the tables, we report the mean and standard deviation of the normalized gap closed across the 10 folds of data used to train the performance models. In contrast to the reported runtime, MCP, and PAR10 scores, where we present the mean and standard deviation across the distribution of all instances. We use folds here to avoid zero denominators in cases where the single best solver is the actual best solver for an instance, based on the normalized gap closed formula <span class="math inline">\(\frac{\text{sbs} - \text{approach}}{\text{sbs} - \text{vbs}}\)</span>. The plots&nbsp;<a href="#fig:all_results" data-reference-type="ref" data-reference="fig:all_results">[fig:all_results]</a>, show the PAR10 score normalized gap closed over the entire distribution of instances.</p>
</section>
</section>
<section id="results" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="results"><span class="header-section-number">6.4</span> Results</h2>
<section id="tuning-of-kl-and-p_cap" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="tuning-of-kl-and-p_cap"><span class="header-section-number">6.4.1</span> Tuning of <span class="math inline">\(kl\)</span> and <span class="math inline">\(p_{\cap}\)</span></h3>
<p>Tuning <span class="math inline">\(p_{\cap}\)</span> and <span class="math inline">\(kl\)</span> reveals that the optimal values vary by scenario. Tables&nbsp;<a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">[tab:pcap]</a> and&nbsp;<a href="#tab:kl" data-reference-type="ref" data-reference="tab:kl">1.1</a> present the optimal values for each scenario and algorithm selector. We presented Figure&nbsp;<a href="#fig:kl_sensitivity" data-reference-type="ref" data-reference="fig:kl_sensitivity">1.1</a>, which shows the normalized gap closed for the mean, 25th percentile, 50th percentile, and 75th percentile across each scenario based on <span class="math inline">\(kl\)</span> value. Although optimal values vary significantly between scenarios and performance models, normalized gaps closed remain relatively small as long as <span class="math inline">\(kl\)</span> is not too low. For the most optimal performance, we recommend tuning <span class="math inline">\(kl\)</span> for each specific scenario.</p>
<p>The optimal value of <span class="math inline">\(kl\)</span>, similar to <span class="math inline">\(p_{\cap}\)</span>, provides insight into the predictive accuracy of the performance models. A large <span class="math inline">\(kl\)</span> value suggests that the models’ predictions may lack accuracy, as it requires including solvers whose predicted runtime distributions differ significantly from that of the best predicted solver in order to capture solvers that perform well. If the optimal value of <span class="math inline">\(kl\)</span> were 0, we would include only solvers that are exactly similar to the best-predicted solver. A very large optimal <span class="math inline">\(kl\)</span> requires us to include all solvers, even those whose predicted distributions differ entirely from the best predicted solver.</p>
<p>Here, the optimal values for <span class="math inline">\(kl\)</span> are relatively small, typically up to 2.5 in most cases. The further the <span class="math inline">\(kl\)</span> value deviates from 0, the lower the accuracy. Table&nbsp;<a href="#tab:kl" data-reference-type="ref" data-reference="tab:kl">1.1</a> also shows that the RFJ model, which uses randomForest with a Jackknife uncertainty estimate, has a significantly lower optimal <span class="math inline">\(kl\)</span> in most scenarios, suggesting that this model should outperform the other two when selecting single solver in 4 out of 5 scenarios in terms of prediction accuracy. This is confirmed by Tables&nbsp;<a href="#tab:summary5-ipc-max" data-reference-type="ref" data-reference="tab:summary5-ipc-max">1.2</a>, <a href="#tab:summary5-sat11-sat16" data-reference-type="ref" data-reference="tab:summary5-sat11-sat16">1.3</a> and&nbsp;<a href="#tab:summary5-sat18" data-reference-type="ref" data-reference="tab:summary5-sat18">1.4</a> which is denoted as <span class="math inline">\(AS (RFJ)\)</span>. The optimal <span class="math inline">\(kl\)</span> values are closer for all scenarios when we have a single model. This seems to contrast with <span class="math inline">\(p_{\cap}\)</span>, where different scenarios had significantly varying values per model. Here, the values are more consistent, suggesting that tuning this parameter per model should yield good performance.</p>
</section>
<section id="as_p_cap-vs.-as_kl-comparison" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="as_p_cap-vs.-as_kl-comparison"><span class="header-section-number">6.4.2</span> <span class="math inline">\(AS_{p_{\cap}}\)</span> vs.&nbsp;<span class="math inline">\(AS_{kl}\)</span> Comparison</h3>
<p>To evaluate the effectiveness of any of the approaches, we carried out a series of experiments using the optimum best value for <span class="math inline">\(p_{\cap}\)</span> and <span class="math inline">\(kl\)</span> and <span class="math inline">\(p_{\cap} = 0\)</span> for each scenario, where we varied the number of processors used for parallel execution from one to ten for the scenarios SAT18-EXP, SAT16-MAIN, SAT11-INDU and IPC2018. For the MAXSAT19-UCMS scenario, we used a maximum of seven processors, as there are only seven algorithms. Figure&nbsp;<a href="#fig:klvspcap" data-reference-type="ref" data-reference="fig:klvspcap">1.2</a> shows the PAR10 score results in terms of the normalized performance gap closed between the sequential single best solver and the sequential virtual best solver for all scenarios and number of processors. In addition, Tables&nbsp;<a href="#tab:summary5-ipc-max" data-reference-type="ref" data-reference="tab:summary5-ipc-max">1.2</a>,&nbsp;<a href="#tab:summary5-sat11-sat16" data-reference-type="ref" data-reference="tab:summary5-sat11-sat16">1.3</a> and&nbsp;<a href="#tab:summary5-sat18" data-reference-type="ref" data-reference="tab:summary5-sat18">1.4</a> show the mean and standard deviation values for runtime, MCP and PAR10 when limiting the maximum number of parallel runs to 10 or SAT18-EXP, SAT16-MAIN, SAT11-INDU and IPC2018, and to 7 for MAXSAT19-UCMS. In addition, we reported the mean and standard deviation of the normalized gap closed across folds in these tables. This differs from the plots, as the plots report values in terms of the mean of the problem distribution rather than across folds.</p>
<p>Here, we discuss the results of the comparison of <span class="math inline">\(AS_{p_{\cap}}\)</span> with the <span class="math inline">\(AS_{kl}\)</span> methods. For this comparison, we excluded the results of the RJ model in Figure&nbsp;<a href="#fig:klvspcap" data-reference-type="ref" data-reference="fig:klvspcap">1.2</a> because, as mentioned in the previous section comparing ranger and randomForest, the RJ model did not outperform the other two models in subportfolio selection, while RI and RFJ were competitive in portfolio selection. This is also evident in Tables&nbsp;<a href="#tab:summary5-ipc-max" data-reference-type="ref" data-reference="tab:summary5-ipc-max">1.2</a>, <a href="#tab:summary5-sat11-sat16" data-reference-type="ref" data-reference="tab:summary5-sat11-sat16">1.3</a>, and&nbsp;<a href="#tab:summary5-sat18" data-reference-type="ref" data-reference="tab:summary5-sat18">1.4</a> that the RJ model did not surpass the other two when using <span class="math inline">\(AS_{p_{\cap}}\)</span> and <span class="math inline">\(AS_{kl}\)</span>. Therefore, we discuss the results for the RI and RFJ models when selecting subportfolios using Equation&nbsp;<a href="#eq:7" data-reference-type="ref" data-reference="eq:7">[eq:7]</a>, denoted as <span class="math inline">\(AS_{p_{\cap}}\)</span>, and Equation&nbsp;<a href="#eq:5.7" data-reference-type="ref" data-reference="eq:5.7">[eq:5.7]</a>, denoted as <span class="math inline">\(AS_{kl}\)</span>.</p>
<p>When comparing <span class="math inline">\(AS_{p_{\cap}}\)</span> and <span class="math inline">\(AS_{kl}\)</span> with optimal threshold values, based on Tables&nbsp;<a href="#tab:summary5-ipc-max" data-reference-type="ref" data-reference="tab:summary5-ipc-max">1.2</a>, <a href="#tab:summary5-sat11-sat16" data-reference-type="ref" data-reference="tab:summary5-sat11-sat16">1.3</a>, and&nbsp;<a href="#tab:summary5-sat18" data-reference-type="ref" data-reference="tab:summary5-sat18">1.4</a>, <span class="math inline">\(AS_{kl}\)</span> outperforms <span class="math inline">\(AS_{p_{\cap}}\)</span> in three of four performance metrics for IPC2018 and the RFJ model. For the RI model, <span class="math inline">\(AS_{p_{\cap}}\)</span> is superior in three of the four metrics, while for the RJ model, <span class="math inline">\(AS_{kl}\)</span> performs worse in all performance metrics. Figure&nbsp;<a href="#fig:klvspcap" data-reference-type="ref" data-reference="fig:klvspcap">1.2</a> further illustrates that <span class="math inline">\(AS_{p_{\cap}}\)</span> consistently outperforms <span class="math inline">\(AS_{kl}\)</span> for both the RFJ and RI models when the cores are limited to different values. For the MAXSAT19-UCMS and SAT11-INDU scenarios, <span class="math inline">\(AS_{p_{\cap}}\)</span> performs better than <span class="math inline">\(AS_{kl}\)</span> in all performance metrics for the RJ, RFJ, and RI models, which is also reflected in the closed mean normalized gap in Figure&nbsp;<a href="#fig:klvspcap" data-reference-type="ref" data-reference="fig:klvspcap">1.2</a>. In the SAT16-MAIN scenario, <span class="math inline">\(AS_{p_{\cap}}\)</span> is overall superior, except for the RFJ model, where both methods perform equally, and the RJ model where the normalized gap closed for folds is slightly worse for <span class="math inline">\(AS_{p_{\cap}}\)</span>. In the SAT18-EXP scenario, <span class="math inline">\(AS_{p_{\cap}}\)</span> generally outperforms <span class="math inline">\(AS_{kl}\)</span>, except for the RFJ model where the two are highly competitive. In three of four performance metrics, <span class="math inline">\(AS_{kl}\)</span> is better, while <span class="math inline">\(AS_{p_{\cap}}\)</span> excels in the remaining metric.</p>
<p>When comparing the RFJ and RI models for portfolio selection using the <span class="math inline">\(AS_{kl}\)</span> method, the RFJ model performed consistently best in all scenarios. This contrasts with the <span class="math inline">\(AS_{p_{\cap}}\)</span> approach, where the RI model outperformed the RFJ model in two out of five scenarios. When comparing <span class="math inline">\(AS_{p_{\cap}}\)</span> and <span class="math inline">\(AS_{kl}\)</span> using the generic best values across the tuned scenarios for each model, <span class="math inline">\(AS_{p_{\cap}}\)</span> outperforms <span class="math inline">\(AS_{kl}\)</span> in two of the three models for IPC2018, MAXSAT19-UCMS and SAT16-MAIN. However, for the RFJ model in these scenarios, the trend is reversed, with <span class="math inline">\(AS_{kl}\)</span> performing slightly worse. For SAT11-INDU and SAT18-EXP, <span class="math inline">\(AS_{p_{\cap}}\)</span> is the consistently better approach across all models.</p>
<p>When comparing all the experimented methods in all scenarios with the number of parallel runs limited to 10, the <span class="math inline">\(AS_{p_{\cap}}\)</span> of the RI model delivered the best performance for IPC2018 and SAT11-INDU in terms of runtime, MCP, normalized gap, and PAR10. For these scenarios, <span class="math inline">\(AS_{kl}\)</span> of the RI model was the second-best method. For MAXSAT19-UCMS, the <span class="math inline">\(AS_{p_{\cap}}\)</span> of the RFJ model achieved the best performance, followed by the <span class="math inline">\(AS_{kl}\)</span> of the RFJ model as the second-best method. In SAT16-MAIN, <span class="math inline">\(AS_{p_{\cap}}\)</span> of the RI model, with <span class="math inline">\(p_{\cap}\)</span> set to zero and selecting the top 10 predicted algorithms, emerged as the best method. The second-best method in this scenario was the <span class="math inline">\(AS_{p_{\cap}}\)</span> of the RI model, using the generic best value for <span class="math inline">\(p_{\cap}\)</span>. Finally, for SAT18-EXP, the <span class="math inline">\(AS_{p_{\cap}}\)</span> and <span class="math inline">\(AS_{kl}\)</span> methods of the RFJ model performed very competitively, both achieving the best performance.</p>
<p>Although the <span class="math inline">\(AS_{p_\cap}\)</span> method appears to be in general superior to <span class="math inline">\(AS_{kl}\)</span>, its performance is very close, making <span class="math inline">\(AS_{kl}\)</span> the best alternative in the absence of <span class="math inline">\(AS_{p_\cap}\)</span>. One significant advantage of <span class="math inline">\(AS_{kl}\)</span> is that the tuned values of <span class="math inline">\(kl\)</span> for different scenarios are highly consistent, and this suggests that tuning of <span class="math inline">\(kl\)</span> globally across all scenarios can still produce good performance. This consistency reduces the cost of scenario-specific tuning. In contrast, the <span class="math inline">\(p_{\cap}\)</span> values vary significantly between different models, and it makes tuning more challenging and model-dependent. On the other hand, <span class="math inline">\(kl\)</span> demonstrates greater consistency, with its best generic values for the RI and RJ models being close, which further highlights its practicality for streamlined optimization.</p>
<figure id="fig:kl_sensitivity" class="figure">
<p>
<embed src="plots/kl_div_rfj_sensitivity_x_theta_y_runtime_facet.svg" style="width:49.0%">
<embed src="plots/kl_ri_div_sensitivity_x_theta_y_runtime_facet.svg" style="width:49.0%">
<embed src="plots/kl_div_rj_sensitivity_x_theta_y_runtime_facet.svg" style="width:49.0%">
</p>
<figcaption>
Sensitivity of Portfolio Performance to <span class="math inline">(kl)</span>. The top left plot corresponds to the RFJ model, and the top right plot corresponds to the RI model, and the bottom plot is for RJ model. The plot displays the mean, first quartile (Q1, 25th percentile), median (Q2, 50th percentile), and third quartile (Q3, 75th percentile) runtime performance for each scenario across different <span class="math inline">(kl)</span> values, as defined in Equation&nbsp;<a href="#eq:5.7" data-reference-type="ref" data-reference="eq:5.7">[eq:5.7]</a>. The y-axis uses a log scale to represent the normalized gap closed, highlighting variations in performance sensitivity relative to <span class="math inline">(kl)</span> adjustments.
</figcaption>
</figure>
<figure id="fig:klvspcap" class="figure">
<embed src="plots/kl_pcap_comparison_line_chart_parallel_NormalizedGap.svg" style="width:95%">
<figcaption>
Results Overview. The plot illustrates the extent to which each method narrows the gap between the PAR10 scores of the Single Best Solver (SBS) and the Virtual Best Solver (VBS). For VBS and SBS, the top <span class="math inline">(n)</span> solvers are selected, where <span class="math inline">(n)</span> matches the number of processors available for each problem instance and across all instances, respectively. <span class="math inline">(AS_{p_{}})</span> and <span class="math inline">(AS_{kl})</span> follow the approaches proposed in <span class="citation" data-cites="kashgarani2023automatic"></span> and Equation&nbsp;<a href="#eq:5.7" data-reference-type="ref" data-reference="eq:5.7">[eq:5.7]</a>, respectively, with the number of processors capped at the specific value on the x-axis — fewer solvers than this maximum may be selected based on the overlap and divergence in runtime predictions. The RFJ model is trained with the randomForest and Jackknife method, RI uses the Ranger model with the Infinitesimal Jackknife method. The optimal <span class="math inline">(p_{})</span> and <span class="math inline">(kl)</span> values for each scenario and each model are listed in Tables&nbsp;<a href="#tab:pcap" data-reference-type="ref" data-reference="tab:pcap">[tab:pcap]</a> and&nbsp;<a href="#tab:kl" data-reference-type="ref" data-reference="tab:kl">1.1</a>.
</figcaption>
</figure>
<div class="center">
<div id="tab:summary5-ipc-max">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for IPC2018, and 7 for MAXSAT19-UCMS) for our approaches and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">508<span class="math inline">\(\pm\)</span><!-- -->697</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3478<span class="math inline">\(\pm\)</span><!-- -->6903</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">607<span class="math inline">\(\pm\)</span><!-- -->751</td>
<td style="text-align: center;">99<span class="math inline">\(\pm\)</span><!-- -->301</td>
<td style="text-align: center;">4657<span class="math inline">\(\pm\)</span><!-- -->7725</td>
<td style="text-align: center;">-0.44<span class="math inline">\(\pm\)</span><!-- -->2.84</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">608<span class="math inline">\(\pm\)</span><!-- -->751</td>
<td style="text-align: center;">100<span class="math inline">\(\pm\)</span><!-- -->293</td>
<td style="text-align: center;">4456<span class="math inline">\(\pm\)</span><!-- -->7583</td>
<td style="text-align: center;">-0.35<span class="math inline">\(\pm\)</span><!-- -->2.85</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">604<span class="math inline">\(\pm\)</span><!-- -->752</td>
<td style="text-align: center;">96<span class="math inline">\(\pm\)</span><!-- -->293</td>
<td style="text-align: center;">4519<span class="math inline">\(\pm\)</span><!-- -->7633</td>
<td style="text-align: center;">-0.39<span class="math inline">\(\pm\)</span><!-- -->2.84</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">734<span class="math inline">\(\pm\)</span><!-- -->770</td>
<td style="text-align: center;">226<span class="math inline">\(\pm\)</span><!-- -->414</td>
<td style="text-align: center;">5459<span class="math inline">\(\pm\)</span><!-- -->8072</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RFJ)</td>
<td style="text-align: center;">612<span class="math inline">\(\pm\)</span><!-- -->779</td>
<td style="text-align: center;">104<span class="math inline">\(\pm\)</span><!-- -->307</td>
<td style="text-align: center;">5134<span class="math inline">\(\pm\)</span><!-- -->8027</td>
<td style="text-align: center;">-0.66<span class="math inline">\(\pm\)</span><!-- -->2.56</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;">616<span class="math inline">\(\pm\)</span><!-- -->783</td>
<td style="text-align: center;">107<span class="math inline">\(\pm\)</span><!-- -->312</td>
<td style="text-align: center;">5206<span class="math inline">\(\pm\)</span><!-- -->8065</td>
<td style="text-align: center;">-0.69<span class="math inline">\(\pm\)</span><!-- -->2.54</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RJ)</td>
<td style="text-align: center;">616<span class="math inline">\(\pm\)</span><!-- -->783</td>
<td style="text-align: center;">107<span class="math inline">\(\pm\)</span><!-- -->312</td>
<td style="text-align: center;">5206<span class="math inline">\(\pm\)</span><!-- -->8065</td>
<td style="text-align: center;">-0.69<span class="math inline">\(\pm\)</span><!-- -->2.54</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.59}\)</span> (RFJ)</td>
<td style="text-align: center;">569<span class="math inline">\(\pm\)</span><!-- -->745</td>
<td style="text-align: center;">61<span class="math inline">\(\pm\)</span><!-- -->223</td>
<td style="text-align: center;">4484<span class="math inline">\(\pm\)</span><!-- -->7651</td>
<td style="text-align: center;"><strong>-0.18<span class="math inline">\(\pm\)</span><!-- -->2.74</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.44}\)</span> (RI)</td>
<td style="text-align: center;"><strong>557<span class="math inline">\(\pm\)</span><!-- -->728</strong></td>
<td style="text-align: center;"><strong>49<span class="math inline">\(\pm\)</span><!-- -->190</strong></td>
<td style="text-align: center;"><strong>4135<span class="math inline">\(\pm\)</span><!-- -->7403</strong></td>
<td style="text-align: center;"><em>-0.19<span class="math inline">\(\pm\)</span><!-- -->2.89</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.27}\)</span> (RJ)</td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->744</td>
<td style="text-align: center;">62<span class="math inline">\(\pm\)</span><!-- -->229</td>
<td style="text-align: center;">4350<span class="math inline">\(\pm\)</span><!-- -->7552</td>
<td style="text-align: center;">-0.21<span class="math inline">\(\pm\)</span><!-- -->2.72</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">579<span class="math inline">\(\pm\)</span><!-- -->742</td>
<td style="text-align: center;">70<span class="math inline">\(\pm\)</span><!-- -->233</td>
<td style="text-align: center;">4359<span class="math inline">\(\pm\)</span><!-- -->7548</td>
<td style="text-align: center;">-0.26<span class="math inline">\(\pm\)</span><!-- -->2.88</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->739</td>
<td style="text-align: center;">62<span class="math inline">\(\pm\)</span><!-- -->230</td>
<td style="text-align: center;">4283<span class="math inline">\(\pm\)</span><!-- -->7501</td>
<td style="text-align: center;">-0.24<span class="math inline">\(\pm\)</span><!-- -->2.87</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->743</td>
<td style="text-align: center;">62<span class="math inline">\(\pm\)</span><!-- -->229</td>
<td style="text-align: center;">4350<span class="math inline">\(\pm\)</span><!-- -->7552</td>
<td style="text-align: center;">-0.21<span class="math inline">\(\pm\)</span><!-- -->2.72</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.71} (RFJ)\)</span></td>
<td style="text-align: center;"><em>560<span class="math inline">\(\pm\)</span><!-- -->735</em></td>
<td style="text-align: center;"><em>52<span class="math inline">\(\pm\)</span><!-- -->193</em></td>
<td style="text-align: center;"><em>4272<span class="math inline">\(\pm\)</span><!-- -->7506</em></td>
<td style="text-align: center;">-0.19<span class="math inline">\(\pm\)</span><!-- -->2.71</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.39} (RI)\)</span></td>
<td style="text-align: center;">570<span class="math inline">\(\pm\)</span><!-- -->740</td>
<td style="text-align: center;">62<span class="math inline">\(\pm\)</span><!-- -->224</td>
<td style="text-align: center;">4350<span class="math inline">\(\pm\)</span><!-- -->7552</td>
<td style="text-align: center;">-0.3<span class="math inline">\(\pm\)</span><!-- -->2.86</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.35} (RJ)\)</span></td>
<td style="text-align: center;">577<span class="math inline">\(\pm\)</span><!-- -->750</td>
<td style="text-align: center;">70<span class="math inline">\(\pm\)</span><!-- -->243</td>
<td style="text-align: center;">4492<span class="math inline">\(\pm\)</span><!-- -->7647</td>
<td style="text-align: center;">-0.31<span class="math inline">\(\pm\)</span><!-- -->2.67</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.41} (RFJ)\)</span></td>
<td style="text-align: center;">571<span class="math inline">\(\pm\)</span><!-- -->738</td>
<td style="text-align: center;">63<span class="math inline">\(\pm\)</span><!-- -->220</td>
<td style="text-align: center;">4351<span class="math inline">\(\pm\)</span><!-- -->7551</td>
<td style="text-align: center;">-0.23<span class="math inline">\(\pm\)</span><!-- -->2.73</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.82} (RI)\)</span></td>
<td style="text-align: center;">575<span class="math inline">\(\pm\)</span><!-- -->746</td>
<td style="text-align: center;">67<span class="math inline">\(\pm\)</span><!-- -->244</td>
<td style="text-align: center;">4423<span class="math inline">\(\pm\)</span><!-- -->7599</td>
<td style="text-align: center;">-0.32<span class="math inline">\(\pm\)</span><!-- -->2.85</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.65} (RJ)\)</span></td>
<td style="text-align: center;">577<span class="math inline">\(\pm\)</span><!-- -->750</td>
<td style="text-align: center;">70<span class="math inline">\(\pm\)</span><!-- -->243</td>
<td style="text-align: center;">4492<span class="math inline">\(\pm\)</span><!-- -->7647</td>
<td style="text-align: center;">-0.31<span class="math inline">\(\pm\)</span><!-- -->2.67</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">858<span class="math inline">\(\pm\)</span><!-- -->1476</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">7768<span class="math inline">\(\pm\)</span><!-- -->14717</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">1037<span class="math inline">\(\pm\)</span><!-- -->1555</td>
<td style="text-align: center;">179<span class="math inline">\(\pm\)</span><!-- -->641</td>
<td style="text-align: center;">9363<span class="math inline">\(\pm\)</span><!-- -->15684</td>
<td style="text-align: center;">0.55<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1076<span class="math inline">\(\pm\)</span><!-- -->1575</td>
<td style="text-align: center;">218<span class="math inline">\(\pm\)</span><!-- -->729</td>
<td style="text-align: center;">9686<span class="math inline">\(\pm\)</span><!-- -->15850</td>
<td style="text-align: center;">0.45<span class="math inline">\(\pm\)</span><!-- -->0.34</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1044<span class="math inline">\(\pm\)</span><!-- -->1565</td>
<td style="text-align: center;">186<span class="math inline">\(\pm\)</span><!-- -->666</td>
<td style="text-align: center;">9540<span class="math inline">\(\pm\)</span><!-- -->15793</td>
<td style="text-align: center;">0.49<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">1190<span class="math inline">\(\pm\)</span><!-- -->1657</td>
<td style="text-align: center;">332<span class="math inline">\(\pm\)</span><!-- -->940</td>
<td style="text-align: center;">11386<span class="math inline">\(\pm\)</span><!-- -->16696</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>7 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RFJ)</td>
<td style="text-align: center;">894<span class="math inline">\(\pm\)</span><!-- -->1506</td>
<td style="text-align: center;">37<span class="math inline">\(\pm\)</span><!-- -->247</td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;">894<span class="math inline">\(\pm\)</span><!-- -->1506</td>
<td style="text-align: center;">37<span class="math inline">\(\pm\)</span><!-- -->247</td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RJ)</td>
<td style="text-align: center;">894<span class="math inline">\(\pm\)</span><!-- -->1506</td>
<td style="text-align: center;">37<span class="math inline">\(\pm\)</span><!-- -->247</td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = {0.55}}\)</span> (RFJ)</td>
<td style="text-align: center;"><strong>891<span class="math inline">\(\pm\)</span><!-- -->1496</strong></td>
<td style="text-align: center;"><strong>33<span class="math inline">\(\pm\)</span><!-- -->215</strong></td>
<td style="text-align: center;"><strong>8141<span class="math inline">\(\pm\)</span><!-- -->14975</strong></td>
<td style="text-align: center;"><strong>0.88<span class="math inline">\(\pm\)</span><!-- -->0.17</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.03}\)</span> (RI)</td>
<td style="text-align: center;">894<span class="math inline">\(\pm\)</span><!-- -->1506</td>
<td style="text-align: center;">37<span class="math inline">\(\pm\)</span><!-- -->247</td>
<td style="text-align: center;">8258<span class="math inline">\(\pm\)</span><!-- -->15062</td>
<td style="text-align: center;">0.85<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.14}\)</span> (RJ)</td>
<td style="text-align: center;">921<span class="math inline">\(\pm\)</span><!-- -->1521</td>
<td style="text-align: center;">63<span class="math inline">\(\pm\)</span><!-- -->369</td>
<td style="text-align: center;">8568<span class="math inline">\(\pm\)</span><!-- -->15263</td>
<td style="text-align: center;">0.76<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">928<span class="math inline">\(\pm\)</span><!-- -->1513</td>
<td style="text-align: center;">70<span class="math inline">\(\pm\)</span><!-- -->364</td>
<td style="text-align: center;">8461<span class="math inline">\(\pm\)</span><!-- -->15175</td>
<td style="text-align: center;">0.81<span class="math inline">\(\pm\)</span><!-- -->0.18</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">901<span class="math inline">\(\pm\)</span><!-- -->1502</td>
<td style="text-align: center;">43<span class="math inline">\(\pm\)</span><!-- -->275</td>
<td style="text-align: center;">8208<span class="math inline">\(\pm\)</span><!-- -->15015</td>
<td style="text-align: center;"><em>0.88<span class="math inline">\(\pm\)</span><!-- -->0.16</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">931<span class="math inline">\(\pm\)</span><!-- -->1525</td>
<td style="text-align: center;">73<span class="math inline">\(\pm\)</span><!-- -->402</td>
<td style="text-align: center;">8578<span class="math inline">\(\pm\)</span><!-- -->15259</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.21</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.63} (RFJ)\)</span></td>
<td style="text-align: center;"><em>892<span class="math inline">\(\pm\)</span><!-- -->1495</em></td>
<td style="text-align: center;"><em>35<span class="math inline">\(\pm\)</span><!-- -->216</em></td>
<td style="text-align: center;"><em>8143<span class="math inline">\(\pm\)</span><!-- -->14974</em></td>
<td style="text-align: center;"><strong>0.88<span class="math inline">\(\pm\)</span><!-- -->0.17</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.7} (RI)\)</span></td>
<td style="text-align: center;">920<span class="math inline">\(\pm\)</span><!-- -->1517</td>
<td style="text-align: center;">63<span class="math inline">\(\pm\)</span><!-- -->349</td>
<td style="text-align: center;">8454<span class="math inline">\(\pm\)</span><!-- -->15179</td>
<td style="text-align: center;">0.82<span class="math inline">\(\pm\)</span><!-- -->0.17</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.7} (RJ)\)</span></td>
<td style="text-align: center;">931<span class="math inline">\(\pm\)</span><!-- -->1530</td>
<td style="text-align: center;">74<span class="math inline">\(\pm\)</span><!-- -->409</td>
<td style="text-align: center;">8691<span class="math inline">\(\pm\)</span><!-- -->15342</td>
<td style="text-align: center;">0.74<span class="math inline">\(\pm\)</span><!-- -->0.25</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.41} (RFJ)\)</span></td>
<td style="text-align: center;">915<span class="math inline">\(\pm\)</span><!-- -->1513</td>
<td style="text-align: center;">57<span class="math inline">\(\pm\)</span><!-- -->335</td>
<td style="text-align: center;">8448<span class="math inline">\(\pm\)</span><!-- -->15182</td>
<td style="text-align: center;">0.8<span class="math inline">\(\pm\)</span><!-- -->0.19</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.82} (RI)\)</span></td>
<td style="text-align: center;">921<span class="math inline">\(\pm\)</span><!-- -->1517</td>
<td style="text-align: center;">63<span class="math inline">\(\pm\)</span><!-- -->349</td>
<td style="text-align: center;">8454<span class="math inline">\(\pm\)</span><!-- -->15179</td>
<td style="text-align: center;">0.82<span class="math inline">\(\pm\)</span><!-- -->0.17</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.65} (RJ)\)</span></td>
<td style="text-align: center;">931<span class="math inline">\(\pm\)</span><!-- -->1530</td>
<td style="text-align: center;">74<span class="math inline">\(\pm\)</span><!-- -->409</td>
<td style="text-align: center;">8691<span class="math inline">\(\pm\)</span><!-- -->15342</td>
<td style="text-align: center;">0.74<span class="math inline">\(\pm\)</span><!-- -->0.25</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="center">
<div id="tab:summary5-sat11-sat16">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for SAT16-MAIN and SAT11-INDU) for our approaches and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1140<span class="math inline">\(\pm\)</span><!-- -->1836</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">8040<span class="math inline">\(\pm\)</span><!-- -->17905</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">1535<span class="math inline">\(\pm\)</span><!-- -->2058</td>
<td style="text-align: center;">395<span class="math inline">\(\pm\)</span><!-- -->1037</td>
<td style="text-align: center;">11735<span class="math inline">\(\pm\)</span><!-- -->20768</td>
<td style="text-align: center;">0.16<span class="math inline">\(\pm\)</span><!-- -->0.79</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1610<span class="math inline">\(\pm\)</span><!-- -->2108</td>
<td style="text-align: center;">470<span class="math inline">\(\pm\)</span><!-- -->1145</td>
<td style="text-align: center;">12710<span class="math inline">\(\pm\)</span><!-- -->21389</td>
<td style="text-align: center;">-0.06<span class="math inline">\(\pm\)</span><!-- -->0.9</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1565<span class="math inline">\(\pm\)</span><!-- -->2049</td>
<td style="text-align: center;">425<span class="math inline">\(\pm\)</span><!-- -->1017</td>
<td style="text-align: center;">11315<span class="math inline">\(\pm\)</span><!-- -->20402</td>
<td style="text-align: center;">0.34<span class="math inline">\(\pm\)</span><!-- -->0.49</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">1818<span class="math inline">\(\pm\)</span><!-- -->2168</td>
<td style="text-align: center;">678<span class="math inline">\(\pm\)</span><!-- -->1340</td>
<td style="text-align: center;">14268<span class="math inline">\(\pm\)</span><!-- -->22154</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RFJ)</td>
<td style="text-align: center;">1272<span class="math inline">\(\pm\)</span><!-- -->1927</td>
<td style="text-align: center;">161<span class="math inline">\(\pm\)</span><!-- -->548</td>
<td style="text-align: center;">8922<span class="math inline">\(\pm\)</span><!-- -->18645</td>
<td style="text-align: center;"><em>0.89<span class="math inline">\(\pm\)</span><!-- -->0.12</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;"><em>1238<span class="math inline">\(\pm\)</span><!-- -->1892</em></td>
<td style="text-align: center;">127<span class="math inline">\(\pm\)</span><!-- -->385</td>
<td style="text-align: center;"><em>8588<span class="math inline">\(\pm\)</span><!-- -->18350</em></td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RJ)</td>
<td style="text-align: center;">1262<span class="math inline">\(\pm\)</span><!-- -->1910</td>
<td style="text-align: center;">151<span class="math inline">\(\pm\)</span><!-- -->480</td>
<td style="text-align: center;">8612<span class="math inline">\(\pm\)</span><!-- -->18342</td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.63}\)</span> (RFJ)</td>
<td style="text-align: center;">1241<span class="math inline">\(\pm\)</span><!-- -->1901</td>
<td style="text-align: center;">131<span class="math inline">\(\pm\)</span><!-- -->451</td>
<td style="text-align: center;">8591<span class="math inline">\(\pm\)</span><!-- -->18349</td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.01}\)</span> (RI)</td>
<td style="text-align: center;"><strong>1236<span class="math inline">\(\pm\)</span><!-- -->1890</strong></td>
<td style="text-align: center;"><strong>121<span class="math inline">\(\pm\)</span><!-- -->379</strong></td>
<td style="text-align: center;"><strong>8586<span class="math inline">\(\pm\)</span><!-- -->18351</strong></td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">1289<span class="math inline">\(\pm\)</span><!-- -->1934</td>
<td style="text-align: center;">178<span class="math inline">\(\pm\)</span><!-- -->595</td>
<td style="text-align: center;">9089<span class="math inline">\(\pm\)</span><!-- -->18787</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">1247<span class="math inline">\(\pm\)</span><!-- -->1900</td>
<td style="text-align: center;"><em>123<span class="math inline">\(\pm\)</span><!-- -->431</em></td>
<td style="text-align: center;">8747<span class="math inline">\(\pm\)</span><!-- -->18501</td>
<td style="text-align: center;">0.83<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">1259<span class="math inline">\(\pm\)</span><!-- -->1912</td>
<td style="text-align: center;">139<span class="math inline">\(\pm\)</span><!-- -->477</td>
<td style="text-align: center;">8909<span class="math inline">\(\pm\)</span><!-- -->18649</td>
<td style="text-align: center;">0.74<span class="math inline">\(\pm\)</span><!-- -->0.36</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">1289<span class="math inline">\(\pm\)</span><!-- -->1934</td>
<td style="text-align: center;">178<span class="math inline">\(\pm\)</span><!-- -->595</td>
<td style="text-align: center;">9089<span class="math inline">\(\pm\)</span><!-- -->18787</td>
<td style="text-align: center;">0.78<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.55} (RFJ)\)</span></td>
<td style="text-align: center;">1243<span class="math inline">\(\pm\)</span><!-- -->1902</td>
<td style="text-align: center;">132<span class="math inline">\(\pm\)</span><!-- -->450</td>
<td style="text-align: center;">8593<span class="math inline">\(\pm\)</span><!-- -->18349</td>
<td style="text-align: center;"><strong>0.92<span class="math inline">\(\pm\)</span><!-- -->0.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 1.62} (RI)\)</span></td>
<td style="text-align: center;">1283<span class="math inline">\(\pm\)</span><!-- -->1931</td>
<td style="text-align: center;">158<span class="math inline">\(\pm\)</span><!-- -->539</td>
<td style="text-align: center;">9233<span class="math inline">\(\pm\)</span><!-- -->18936</td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.34</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 1.94} (RJ)\)</span></td>
<td style="text-align: center;">1307<span class="math inline">\(\pm\)</span><!-- -->1950</td>
<td style="text-align: center;">194<span class="math inline">\(\pm\)</span><!-- -->622</td>
<td style="text-align: center;">9407<span class="math inline">\(\pm\)</span><!-- -->19072</td>
<td style="text-align: center;">0.73<span class="math inline">\(\pm\)</span><!-- -->0.26</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.41} (RFJ)\)</span></td>
<td style="text-align: center;">1250<span class="math inline">\(\pm\)</span><!-- -->1910</td>
<td style="text-align: center;">137<span class="math inline">\(\pm\)</span><!-- -->465</td>
<td style="text-align: center;">8750<span class="math inline">\(\pm\)</span><!-- -->18501</td>
<td style="text-align: center;"><em>0.89<span class="math inline">\(\pm\)</span><!-- -->0.12</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.82} (RI)\)</span></td>
<td style="text-align: center;">1288<span class="math inline">\(\pm\)</span><!-- -->1939</td>
<td style="text-align: center;">166<span class="math inline">\(\pm\)</span><!-- -->550</td>
<td style="text-align: center;">9238<span class="math inline">\(\pm\)</span><!-- -->18934</td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.34</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.65} (RJ)\)</span></td>
<td style="text-align: center;">1310<span class="math inline">\(\pm\)</span><!-- -->1953</td>
<td style="text-align: center;">198<span class="math inline">\(\pm\)</span><!-- -->626</td>
<td style="text-align: center;">9410<span class="math inline">\(\pm\)</span><!-- -->19071</td>
<td style="text-align: center;">0.73<span class="math inline">\(\pm\)</span><!-- -->0.26</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">2-6</td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1867<span class="math inline">\(\pm\)</span><!-- -->2193</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">15005<span class="math inline">\(\pm\)</span><!-- -->22530</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">2315<span class="math inline">\(\pm\)</span><!-- -->2273</td>
<td style="text-align: center;">448<span class="math inline">\(\pm\)</span><!-- -->1109</td>
<td style="text-align: center;">19066<span class="math inline">\(\pm\)</span><!-- -->23883</td>
<td style="text-align: center;">0.33<span class="math inline">\(\pm\)</span><!-- -->0.56</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">2383<span class="math inline">\(\pm\)</span><!-- -->2294</td>
<td style="text-align: center;">516<span class="math inline">\(\pm\)</span><!-- -->1151</td>
<td style="text-align: center;">19956<span class="math inline">\(\pm\)</span><!-- -->24111</td>
<td style="text-align: center;">0.05<span class="math inline">\(\pm\)</span><!-- -->0.66</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">2400<span class="math inline">\(\pm\)</span><!-- -->2269</td>
<td style="text-align: center;">533<span class="math inline">\(\pm\)</span><!-- -->1177</td>
<td style="text-align: center;">19316<span class="math inline">\(\pm\)</span><!-- -->23880</td>
<td style="text-align: center;">0.3<span class="math inline">\(\pm\)</span><!-- -->0.24</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">2560<span class="math inline">\(\pm\)</span><!-- -->2294</td>
<td style="text-align: center;">693<span class="math inline">\(\pm\)</span><!-- -->1415</td>
<td style="text-align: center;">21940<span class="math inline">\(\pm\)</span><!-- -->24464</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2-6</td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">2-6</td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RFJ)</td>
<td style="text-align: center;">2065<span class="math inline">\(\pm\)</span><!-- -->2221</td>
<td style="text-align: center;">198<span class="math inline">\(\pm\)</span><!-- -->652</td>
<td style="text-align: center;"><strong>16189<span class="math inline">\(\pm\)</span><!-- -->22931</strong></td>
<td style="text-align: center;"><em>0.7<span class="math inline">\(\pm\)</span><!-- -->0.39</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;"><strong>2016<span class="math inline">\(\pm\)</span><!-- -->2225</strong></td>
<td style="text-align: center;"><strong>150<span class="math inline">\(\pm\)</span><!-- -->503</strong></td>
<td style="text-align: center;">16469<span class="math inline">\(\pm\)</span><!-- -->23122</td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.6</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RJ)</td>
<td style="text-align: center;">2048<span class="math inline">\(\pm\)</span><!-- -->2228</td>
<td style="text-align: center;">181<span class="math inline">\(\pm\)</span><!-- -->597</td>
<td style="text-align: center;">16336<span class="math inline">\(\pm\)</span><!-- -->23023</td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.59</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.33}\)</span> (RFJ)</td>
<td style="text-align: center;">2065<span class="math inline">\(\pm\)</span><!-- -->2221</td>
<td style="text-align: center;">198<span class="math inline">\(\pm\)</span><!-- -->652</td>
<td style="text-align: center;"><strong>16189<span class="math inline">\(\pm\)</span><!-- -->22931</strong></td>
<td style="text-align: center;"><em>0.7<span class="math inline">\(\pm\)</span><!-- -->0.39</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;"><strong>2016<span class="math inline">\(\pm\)</span><!-- -->2225</strong></td>
<td style="text-align: center;"><strong>150<span class="math inline">\(\pm\)</span><!-- -->503</strong></td>
<td style="text-align: center;">16469<span class="math inline">\(\pm\)</span><!-- -->23122</td>
<td style="text-align: center;">0.68<span class="math inline">\(\pm\)</span><!-- -->0.6</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.33}\)</span> (RJ)</td>
<td style="text-align: center;">2088<span class="math inline">\(\pm\)</span><!-- -->2239</td>
<td style="text-align: center;">222<span class="math inline">\(\pm\)</span><!-- -->704</td>
<td style="text-align: center;">16705<span class="math inline">\(\pm\)</span><!-- -->23156</td>
<td style="text-align: center;">0.64<span class="math inline">\(\pm\)</span><!-- -->0.37</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">2094<span class="math inline">\(\pm\)</span><!-- -->2222</td>
<td style="text-align: center;">228<span class="math inline">\(\pm\)</span><!-- -->730</td>
<td style="text-align: center;">16383<span class="math inline">\(\pm\)</span><!-- -->22993</td>
<td style="text-align: center;">0.69<span class="math inline">\(\pm\)</span><!-- -->0.41</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;"><em>2041<span class="math inline">\(\pm\)</span><!-- -->2230</em></td>
<td style="text-align: center;"><em>174<span class="math inline">\(\pm\)</span><!-- -->591</em></td>
<td style="text-align: center;">16822<span class="math inline">\(\pm\)</span><!-- -->23261</td>
<td style="text-align: center;">0.57<span class="math inline">\(\pm\)</span><!-- -->0.63</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">2096<span class="math inline">\(\pm\)</span><!-- -->2240</td>
<td style="text-align: center;">229<span class="math inline">\(\pm\)</span><!-- -->713</td>
<td style="text-align: center;">16877<span class="math inline">\(\pm\)</span><!-- -->23227</td>
<td style="text-align: center;">0.63<span class="math inline">\(\pm\)</span><!-- -->0.36</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.66} (RFJ)\)</span></td>
<td style="text-align: center;">2065<span class="math inline">\(\pm\)</span><!-- -->2221</td>
<td style="text-align: center;">198<span class="math inline">\(\pm\)</span><!-- -->652</td>
<td style="text-align: center;"><strong>16189<span class="math inline">\(\pm\)</span><!-- -->22931</strong></td>
<td style="text-align: center;"><em>0.7<span class="math inline">\(\pm\)</span><!-- -->0.39</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.96} (RI)\)</span></td>
<td style="text-align: center;">2070<span class="math inline">\(\pm\)</span><!-- -->2236</td>
<td style="text-align: center;">204<span class="math inline">\(\pm\)</span><!-- -->647</td>
<td style="text-align: center;">17016<span class="math inline">\(\pm\)</span><!-- -->23318</td>
<td style="text-align: center;">0.64<span class="math inline">\(\pm\)</span><!-- -->0.59</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.06} (RJ)\)</span></td>
<td style="text-align: center;">2104<span class="math inline">\(\pm\)</span><!-- -->2245</td>
<td style="text-align: center;">237<span class="math inline">\(\pm\)</span><!-- -->736</td>
<td style="text-align: center;">17049<span class="math inline">\(\pm\)</span><!-- -->23297</td>
<td style="text-align: center;">0.69<span class="math inline">\(\pm\)</span><!-- -->0.35</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.41} (RFJ)\)</span></td>
<td style="text-align: center;">2089<span class="math inline">\(\pm\)</span><!-- -->2223</td>
<td style="text-align: center;">223<span class="math inline">\(\pm\)</span><!-- -->698</td>
<td style="text-align: center;"><em>16213<span class="math inline">\(\pm\)</span><!-- -->22916</em></td>
<td style="text-align: center;"><strong>0.71<span class="math inline">\(\pm\)</span><!-- -->0.4</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.82} (RI)\)</span></td>
<td style="text-align: center;">2093<span class="math inline">\(\pm\)</span><!-- -->2238</td>
<td style="text-align: center;">227<span class="math inline">\(\pm\)</span><!-- -->704</td>
<td style="text-align: center;">17203<span class="math inline">\(\pm\)</span><!-- -->23376</td>
<td style="text-align: center;">0.59<span class="math inline">\(\pm\)</span><!-- -->0.39</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.65} (RJ)\)</span></td>
<td style="text-align: center;">2104<span class="math inline">\(\pm\)</span><!-- -->2245</td>
<td style="text-align: center;">237<span class="math inline">\(\pm\)</span><!-- -->735</td>
<td style="text-align: center;">17049<span class="math inline">\(\pm\)</span><!-- -->23297</td>
<td style="text-align: center;">0.62<span class="math inline">\(\pm\)</span><!-- -->0.36</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="center">
<div id="tab:summary5-sat18">
<table class="caption-top table">
<caption>Detailed results. Mean and standard deviation of values for runtime, MCP, and PAR10 across all problem instances in a scenario for the sequential virtual best solver, sequential single best solver, and single top predicted algorithm in the initial three rows. The second set of rows for each scenario shows the results for the maximum number of processors (10 for SAT18-EXP) for our approaches and the baselines we compare to. All numbers were rounded to integers. The best value for each scenario and measure is shown in <strong>bold</strong> (excepting the sequential VBS, which is by definition always the best), the second best in <em>italics</em>. The normalized gap closed represents the mean and standard deviation of the normalized gap closed across the folds.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Scenario</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: center;">Runtime [s]</th>
<th style="text-align: center;">MCP</th>
<th style="text-align: center;">PAR10</th>
<th style="text-align: center;">NormalizedGap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>1 Processor</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">VBS</td>
<td style="text-align: center;">1146<span class="math inline">\(\pm\)</span><!-- -->1945</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">9687<span class="math inline">\(\pm\)</span><!-- -->19547</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RFJ)</td>
<td style="text-align: center;">1615<span class="math inline">\(\pm\)</span><!-- -->2138</td>
<td style="text-align: center;">468<span class="math inline">\(\pm\)</span><!-- -->1192</td>
<td style="text-align: center;">13470<span class="math inline">\(\pm\)</span><!-- -->21889</td>
<td style="text-align: center;">0.64<span class="math inline">\(\pm\)</span><!-- -->0.18</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RI)</td>
<td style="text-align: center;">1648<span class="math inline">\(\pm\)</span><!-- -->2151</td>
<td style="text-align: center;">502<span class="math inline">\(\pm\)</span><!-- -->1256</td>
<td style="text-align: center;">13758<span class="math inline">\(\pm\)</span><!-- -->22034</td>
<td style="text-align: center;">0.59<span class="math inline">\(\pm\)</span><!-- -->0.18</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">AS (RJ)</td>
<td style="text-align: center;">1690<span class="math inline">\(\pm\)</span><!-- -->2170</td>
<td style="text-align: center;">543<span class="math inline">\(\pm\)</span><!-- -->1302</td>
<td style="text-align: center;">14183<span class="math inline">\(\pm\)</span><!-- -->22247</td>
<td style="text-align: center;">0.57<span class="math inline">\(\pm\)</span><!-- -->0.16</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">SBS</td>
<td style="text-align: center;">2400<span class="math inline">\(\pm\)</span><!-- -->2249</td>
<td style="text-align: center;">1254<span class="math inline">\(\pm\)</span><!-- -->1832</td>
<td style="text-align: center;">20629<span class="math inline">\(\pm\)</span><!-- -->24280</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><strong>10 Processors</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RFJ)</td>
<td style="text-align: center;">1702<span class="math inline">\(\pm\)</span><!-- -->2301</td>
<td style="text-align: center;">559<span class="math inline">\(\pm\)</span><!-- -->1389</td>
<td style="text-align: center;">16235<span class="math inline">\(\pm\)</span><!-- -->23355</td>
<td style="text-align: center;">0.39<span class="math inline">\(\pm\)</span><!-- -->0.27</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RI)</td>
<td style="text-align: center;">1654<span class="math inline">\(\pm\)</span><!-- -->2285</td>
<td style="text-align: center;">511<span class="math inline">\(\pm\)</span><!-- -->1324</td>
<td style="text-align: center;">15804<span class="math inline">\(\pm\)</span><!-- -->23194</td>
<td style="text-align: center;">0.42<span class="math inline">\(\pm\)</span><!-- -->0.29</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0}\)</span> (RJ)</td>
<td style="text-align: center;">1678<span class="math inline">\(\pm\)</span><!-- -->2288</td>
<td style="text-align: center;">535<span class="math inline">\(\pm\)</span><!-- -->1351</td>
<td style="text-align: center;">15956<span class="math inline">\(\pm\)</span><!-- -->23243</td>
<td style="text-align: center;">0.4<span class="math inline">\(\pm\)</span><!-- -->0.3</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.81}\)</span> (RFJ)</td>
<td style="text-align: center;"><em>1518<span class="math inline">\(\pm\)</span><!-- -->2172</em></td>
<td style="text-align: center;"><strong>372<span class="math inline">\(\pm\)</span><!-- -->1124</strong></td>
<td style="text-align: center;"><em>13884<span class="math inline">\(\pm\)</span><!-- -->22265</em></td>
<td style="text-align: center;"><em>0.62<span class="math inline">\(\pm\)</span><!-- -->0.22</em></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.55}\)</span> (RI)</td>
<td style="text-align: center;">1541<span class="math inline">\(\pm\)</span><!-- -->2191</td>
<td style="text-align: center;">397<span class="math inline">\(\pm\)</span><!-- -->1177</td>
<td style="text-align: center;">14034<span class="math inline">\(\pm\)</span><!-- -->22332</td>
<td style="text-align: center;"><em>0.6<span class="math inline">\(\pm\)</span><!-- -->0.21</em></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.58}\)</span> (RJ)</td>
<td style="text-align: center;">1622<span class="math inline">\(\pm\)</span><!-- -->2237</td>
<td style="text-align: center;">477<span class="math inline">\(\pm\)</span><!-- -->1268</td>
<td style="text-align: center;">15008<span class="math inline">\(\pm\)</span><!-- -->22805</td>
<td style="text-align: center;">0.5<span class="math inline">\(\pm\)</span><!-- -->0.25</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.82}\)</span> (RFJ)</td>
<td style="text-align: center;">1532<span class="math inline">\(\pm\)</span><!-- -->2178</td>
<td style="text-align: center;">386<span class="math inline">\(\pm\)</span><!-- -->1146</td>
<td style="text-align: center;">14025<span class="math inline">\(\pm\)</span><!-- -->22336</td>
<td style="text-align: center;">0.6<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.17}\)</span> (RI)</td>
<td style="text-align: center;">1555<span class="math inline">\(\pm\)</span><!-- -->2221</td>
<td style="text-align: center;">410<span class="math inline">\(\pm\)</span><!-- -->1191</td>
<td style="text-align: center;">14558<span class="math inline">\(\pm\)</span><!-- -->22628</td>
<td style="text-align: center;">0.57<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{p_{\cap} = 0.31}\)</span> (RJ)</td>
<td style="text-align: center;">1649<span class="math inline">\(\pm\)</span><!-- -->2265</td>
<td style="text-align: center;">505<span class="math inline">\(\pm\)</span><!-- -->1319</td>
<td style="text-align: center;">15544<span class="math inline">\(\pm\)</span><!-- -->23064</td>
<td style="text-align: center;">0.46<span class="math inline">\(\pm\)</span><!-- -->0.26</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.12} (RFJ)\)</span></td>
<td style="text-align: center;"><strong>1518<span class="math inline">\(\pm\)</span><!-- -->2169</strong></td>
<td style="text-align: center;"><em>373<span class="math inline">\(\pm\)</span><!-- -->1129</em></td>
<td style="text-align: center;"><strong>13756<span class="math inline">\(\pm\)</span><!-- -->22187</strong></td>
<td style="text-align: center;"><strong>0.62<span class="math inline">\(\pm\)</span><!-- -->0.23</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 1.81} (RI)\)</span></td>
<td style="text-align: center;">1567<span class="math inline">\(\pm\)</span><!-- -->2213</td>
<td style="text-align: center;">422<span class="math inline">\(\pm\)</span><!-- -->1211</td>
<td style="text-align: center;">14442<span class="math inline">\(\pm\)</span><!-- -->22547</td>
<td style="text-align: center;">0.58<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 1.35} (RJ)\)</span></td>
<td style="text-align: center;">1656<span class="math inline">\(\pm\)</span><!-- -->2268</td>
<td style="text-align: center;">512<span class="math inline">\(\pm\)</span><!-- -->1316</td>
<td style="text-align: center;">15551<span class="math inline">\(\pm\)</span><!-- -->23060</td>
<td style="text-align: center;">0.45<span class="math inline">\(\pm\)</span><!-- -->0.23</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 0.41} (RFJ)\)</span></td>
<td style="text-align: center;">1585<span class="math inline">\(\pm\)</span><!-- -->2230</td>
<td style="text-align: center;">440<span class="math inline">\(\pm\)</span><!-- -->1236</td>
<td style="text-align: center;">14843<span class="math inline">\(\pm\)</span><!-- -->22755</td>
<td style="text-align: center;">0.53<span class="math inline">\(\pm\)</span><!-- -->0.28</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.82} (RI)\)</span></td>
<td style="text-align: center;">1569<span class="math inline">\(\pm\)</span><!-- -->2227</td>
<td style="text-align: center;">424<span class="math inline">\(\pm\)</span><!-- -->1219</td>
<td style="text-align: center;">14699<span class="math inline">\(\pm\)</span><!-- -->22693</td>
<td style="text-align: center;">0.55<span class="math inline">\(\pm\)</span><!-- -->0.22</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;"><span class="math inline">\(AS_{kl = 2.65} (RJ)\)</span></td>
<td style="text-align: center;">1669<span class="math inline">\(\pm\)</span><!-- -->2274</td>
<td style="text-align: center;">525<span class="math inline">\(\pm\)</span><!-- -->1335</td>
<td style="text-align: center;">15691<span class="math inline">\(\pm\)</span><!-- -->23119</td>
<td style="text-align: center;">0.43<span class="math inline">\(\pm\)</span><!-- -->0.22</td>
</tr>
</tbody>
</table>
</div>
</div>
<figure id="fig:numberofsolvers_kl" class="figure">
<p>
<embed src="plots/number_of_solvers_rf_kl.svg" style="width:50.0%">
<embed src="plots/number_of_solvers_infjack_kl.svg" style="width:50.0%">
<embed src="plots/number_of_solvers_jack_kl.svg" style="width:50.0%">
</p>
<figcaption>
Violin plot of the distribution of the number of selected solvers to run in parallel across all problem instances for each scenario for the respective optimal <span class="math inline">(kl)</span> and the maximum level of parallelism (seven processors for MAXSAT19-UCMS and 10 for all other scenarios). The diamond denotes the mean value. The top-left plot refers to the RFJ model, the top-right plot to the RI model, and the bottom plot to the RJ model.
</figcaption>
</figure>
</section>
</section>
<section id="conclusions-and-future-work" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="conclusions-and-future-work"><span class="header-section-number">6.5</span> Conclusions and Future Work</h2>
<p>In this study, we proposed a variation of the method introduced in Chapter 4 and expanded our experiments to incorporate these adaptations. We developed an alternative general approach for selecting solvers from a portfolio and scheduling them in parallel. This method leverages the predicted runtime distribution to make informed decisions about which solvers and how many to run in parallel. Specifically, in contrast to the method introduced in Chapter 4, where the joint probability of the prediction distribution is used as a measure of the likelihood that an algorithm performs, as well as the best-predicted solver, the new approach utilizes the KL divergence formula. This allows us to evaluate how much an algorithm’s prediction diverges from the best-predicted solver, excluding solvers whose predictions differ the most. Moreover, similar to previous chapter, we measured the actual runtime when operating multiple algorithms in parallel, instead of relying on assumed sequential runtimes.</p>
<p>Our results showed that while the previous method outperforms the new approach, in the absence of the old method, the new approach proves to be superior. Additionally, tuning the threshold for the joint probability in the method of the previous chapter varies significantly between different benchmarks and performance models. In contrast, the tuned threshold for divergence in the new approach is more consistent and this consistency can reduce the computational effort required for tuning.</p>
<p>For future work, we plan to explore replacing the performance models with models trained on parallel data instead of sequential data. Currently, the training data does not reflect the actual runtimes when algorithms are executed in parallel, and running algorithms in parallel can introduce overhead. We aim to evaluate whether this replacement improves portfolio selection performance.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BISCHL201641" class="csl-entry" role="listitem">
Bischl, Bernd, Pascal Kerschke, Lars Kotthoff, Marius Lindauer, Yuri Malitsky, Alexandre Fréchette, Holger Hoos, et al. 2016. <span>“<span>ASlib</span>: A Benchmark Library for Algorithm Selection.”</span> <em>Artificial Intelligence</em> 237: 41–58.
</div>
<div id="ref-mlr" class="csl-entry" role="listitem">
Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2016. <span>“<span class="nocase">mlr: Machine Learning in R</span>.”</span> <em>Journal of Machine Learning Research</em> 17 (170): 1–5. <a href="https://jmlr.org/papers/v17/15-066.html">https://jmlr.org/papers/v17/15-066.html</a>.
</div>
<div id="ref-bishop2006pattern" class="csl-entry" role="listitem">
Bishop, Christopher M, and Nasser M Nasrabadi. 2006. <em>Pattern Recognition and Machine Learning</em>. Vol. 4. 4. Springer.
</div>
<div id="ref-Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014" class="csl-entry" role="listitem">
Fawcett, Chris, Mauro Vallati, Frank Hutter, Jörg Hoffmann, Holger Hoos, and Kevin Leyton-Brown. 2014. <span>“<span class="nocase">Improved Features for Runtime Prediction of Domain-Independent Planners</span>.”</span> <em>Proceedings of the International Conference on Automated Planning and Scheduling</em> 24 (1): 355–59. <a href="https://doi.org/10.1609/icaps.v24i1.13680">https://doi.org/10.1609/icaps.v24i1.13680</a>.
</div>
<div id="ref-GOMES200143" class="csl-entry" role="listitem">
Gomes, Carla, and Bart Selman. 2001. <span>“Algorithm Portfolios.”</span> <em>Artificial Intelligence</em> 126: 43–62.
</div>
<div id="ref-Huberman1997" class="csl-entry" role="listitem">
Huberman, Bernardo A., Rajan M. Lukose, and Tad Hogg. 1997. <span>“<span class="nocase">An economics approach to hard computational problems</span>.”</span> <em>Science</em> 275 (5296): 51–54. <a href="https://doi.org/10.1126/science.275.5296.51">https://doi.org/10.1126/science.275.5296.51</a>.
</div>
<div id="ref-HUTTER201479" class="csl-entry" role="listitem">
Hutter, Frank, Lin Xu, Holger H. Hoos, and Kevin Leyton-Brown. 2014. <span>“Algorithm Runtime Prediction: Methods &amp; Evaluation.”</span> <em>Artificial Intelligence</em> 206: 79–111. https://doi.org/<a href="https://doi.org/10.1016/j.artint.2013.10.003">https://doi.org/10.1016/j.artint.2013.10.003</a>.
</div>
<div id="ref-pmlr-v140-kashgarani21a" class="csl-entry" role="listitem">
Kashgarani, Haniye, and Lars Kotthoff. 2021. <span>“<span class="nocase">Is Algorithm Selection Worth It? Comparing Selecting Single Algorithms and Parallel Execution</span>.”</span> In <em>AAAI Workshop on Meta-Learning and MetaDL Challenge</em>, 140:58–64. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v140/kashgarani21a.html">https://proceedings.mlr.press/v140/kashgarani21a.html</a>.
</div>
<div id="ref-kashgarani2023automatic" class="csl-entry" role="listitem">
———. 2023. <span>“<span>Automatic Parallel Portfolio Selection</span>.”</span> In <em>ECAI 2023</em>, 1215–22. IOS Press.
</div>
<div id="ref-KL" class="csl-entry" role="listitem">
Kullback, S., and R. A. Leibler. 1951. <span>“<span class="nocase">On Information and Sufficiency</span>.”</span> <em>The Annals of Mathematical Statistics</em> 22 (1): 79–86. <a href="http://www.jstor.org/stable/2236703">http://www.jstor.org/stable/2236703</a>.
</div>
<div id="ref-lindauer2015autofolio" class="csl-entry" role="listitem">
Lindauer, Marius, Holger H Hoos, Frank Hutter, and Torsten Schaub. 2015. <span>“Autofolio: An Automatically Configured Algorithm Selector.”</span> <em>Journal of Artificial Intelligence Research</em> 53: 745–78.
</div>
<div id="ref-LINDAUER2017272" class="csl-entry" role="listitem">
Lindauer, Marius, Holger Hoos, Kevin Leyton-Brown, and Torsten Schaub. 2017. <span>“Automatic Construction of Parallel Portfolios via Algorithm Configuration.”</span> <em>Artificial Intelligence</em> 244: 272–90. https://doi.org/<a href="https://doi.org/10.1016/j.artint.2016.05.004">https://doi.org/10.1016/j.artint.2016.05.004</a>.
</div>
<div id="ref-cphydra" class="csl-entry" role="listitem">
O’Mahony, Eoin, Emmanuel Hebrard, Alan Holland, Conor Nugent, and Barry O’Sullivan. 2008. <span>“Using Case-Based Reasoning in an Algorithm Portfolio for Constraint Solving.”</span> In <em>Irish Conference on Artificial Intelligence and Cognitive Science</em>, 210–16. Proceedings of the 19th Irish Conference on Artificial Intelligence; Cognitive Science.
</div>
<div id="ref-wager2014confidence" class="csl-entry" role="listitem">
Wager, Stefan, Trevor Hastie, and Bradley Efron. 2014. <span>“<span class="nocase">Confidence intervals for random forests: The jackknife and the infinitesimal jackknife</span>.”</span> <em>The Journal of Machine Learning Research</em> 15 (1): 1625–51.
</div>
<div id="ref-satzilla" class="csl-entry" role="listitem">
Xu, Lin, Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. 2008. <span>“<span>SATzilla</span>: Portfolio-Based Algorithm Selection for <span>SAT</span>.”</span> <em>J. Artif. Int. Res.</em> 32 (1): 565–606.
</div>
<div id="ref-XuEtAl11" class="csl-entry" role="listitem">
Xu, Lin, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. 2011. <span>“<span class="nocase">Hydra-MIP: Automated algorithm configuration and selection for mixed integer programming</span>.”</span> In <em>Proceedings of the 18th RCRA Workshop</em>, 16–30.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter4/AutomaticParallelPortfolioSelection.html" class="pagination-link" aria-label="Automatic Parallel Portfolio Selection">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Automatic Parallel Portfolio Selection</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter6/ParallelPortfolioSelectionwithParallelDataTraining.html" class="pagination-link" aria-label="Parallel Portfolio Selection with Parallel Data Training">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Parallel Portfolio Selection with Parallel Data Training</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Revisiting Parallel Portfolio Selection with KL Divergence</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>Algorithms designed to solve combinatorial problems often exhibit</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>complementary performance across different problem instances. Therefore,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>using a portfolio of algorithms frequently demonstrates superior</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>performance compared to selecting the single best solver (SBS) averaged</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>across all instances <span class="co">[</span><span class="ot">@Huberman1997; @GOMES200143</span><span class="co">]</span>. Portfolios can</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>either be run in parallel, or a single algorithm can be selected on an</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>instance-by-instance basis by training performance models using machine</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>learning algorithms. However, both methods have drawbacks.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>Algorithm selection has proven to be effective in solving different</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>problems such as SAT, constraint programming, and mixed integer</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>programming, as demonstrated by systems such as SATzilla, Hydra, and</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>AutoFolio <span class="co">[</span><span class="ot">@satzilla; @lindauer2015autofolio; @cphydra; @XuEtAl11</span><span class="co">]</span>. In</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>single algorithm selection, if machine learning models are not well</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>generalized, they might not select the correct best algorithm for a</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>given instance. Although executing the whole portfolio of algorithms</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>seems to avoid this issue, the more solvers that perform computations in</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>parallel, the more time-out computations we will encounter</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@pmlr-v140-kashgarani21a; @LINDAUER2017272</span><span class="co">]</span>. However, the proposed</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>parallel portfolio approaches often simulate parallel execution based on</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>sequential data, which conceals the significant overhead and performance</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>drop that occurs when many algorithms run parallel.</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>Based on the results presented in the third chapter, even with a small</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>number of solvers, selecting a single algorithm using the imperfect</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>regression random forest ML model can outperform parallel portfolios</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@pmlr-v140-kashgarani21a</span><span class="co">]</span>. In Chapter 4, we proposed a hybrid approach</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>that leverages both algorithm selection and parallel execution. We</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>introduced a middle-path strategy that identifies the most promising</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>subset of algorithms to run simultaneously on a single non-distributed</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>computer <span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>. This innovative method demonstrated</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>improved performance by utilizing three regression random forest</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>algorithm selectors with different implementations and uncertainty</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>estimation methods.</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>Using the method proposed in the previous chapter, it is possible to</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>select an instance-based subportfolio of solvers to run in parallel,</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>avoiding the drawbacks of algorithm selection and reducing the overhead</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>associated with running too many solvers simultaneously. This method can</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>achieve optimal or near-optimal performance, provided the virtual best</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>solver is included in the selected subset of algorithms. We used the</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>estimated uncertainty of the predictions while considering the impact of</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>overhead from running the portfolio in parallel.</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>However, this strategy still has some limitations. Specifically, the</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>threshold value $p_{\cap}$--which is defined as the threshold for the</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>joint probability between the prediction distributions of the minimum</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>predicted algorithm and other algorithms, and serving as a measure of</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>the likelihood that an algorithm is predicted to perform very closely to</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>the minimum predicted algorithm---could not be generalized across all</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>scenarios and algorithm performance models, as the tuned values varied</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>significantly. Here, we aim to provide an alternative formulation for</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>subportfolio selection that overcomes this limitation.</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>In this chapter, we revisit the method of selecting the optimal parallel</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>subportfolio of algorithms to run on a single computing machine. Similar</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>to the main proposed method, we incorporate the uncertainty of the</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>performance predictions. Here, rather than using the threshold $p_\cap$</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>in Equation&nbsp;<span class="co">[</span><span class="ot">\[eq:7\]</span><span class="co">](#eq:7)</span>{reference-type="ref" reference="eq:7"} as</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>an estimate of the probability that the algorithm is as good as the best</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>predicted algorithm, we investigated the use of the Kullback--Leibler</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>(KL) divergence method, which measures the difference between the</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>probability distributions of the predicted algorithms. This method</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>provides an understanding of the differences between algorithm</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>predictions, in contrast to the joint probability approach, which</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>focused on the similarity of predictions. This enables a redefined</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>selection criterion based on the divergence from the best-predicted</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>performance distribution.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="fu">## Revisit Parallel Portfolio Selection</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>We aim to select a subset of solvers $ P_i \subseteq S $ for a given</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>instance $i \in I$, prioritizing algorithms predicted to perform best</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>($A \in S$ and $A \in P_i$) based on their predicted performance</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>$\hat{m}$. For each instance, a total ranking of algorithms in the</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>portfolio $S$ is established using their predicted performance:</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>$$A &lt; B \quad \text{if} \quad \hat{m}(A, i) &lt; \hat{m}(B, i); A, B \in S$$</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>From this ranking, the rank $r_{A, i}$ is assigned to each algorithm</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>$A$, representing the number of algorithms predicted to outperform $A$</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>on instance $i$. A portfolio of size $n$ is then defined by the top $n$</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>ranked algorithms:</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>$$P_i = <span class="sc">\{</span>A \in S \: | \: r_{A,i} \leq n<span class="sc">\}</span>$$</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>This method allows the selection of a subset of solvers for parallel</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>execution, balancing the likelihood of including the best-performing</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>solver with the overhead of running multiple solvers. However, the</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>critical challenge in parallel portfolios is determining the appropriate</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>portfolio size $n$ for each problem instance. To address this balance,</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>we incorporate the predicted performance distribution of algorithms and</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>their associated uncertainty.</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>Similar to the proposed method in Chapter 4, instead of considering only</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>a point prediction, we consider the predicted distribution of</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>performance metric values, characterized by its mean and standard</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>deviation. Formally, we denote the standard deviation of the prediction</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>$\hat{m}(A, i)$ as $\sigma_{A, i}$ for each solver $A$ and instance $i$.</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>We assume that the predictions of our performance models follow a normal</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>distribution, i.e. the predicted value is the mean of that distribution,</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>and allow us to characterize it completely together with the standard</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>deviation. In the previous approach, we assess the likelihood that two</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>algorithms perform equally well by calculating the overlap area between</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>their prediction distributions. If two algorithms are predicted to</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>perform very similarly, then the overlap area between the distributions</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>will be very large. Here, we replace this method by considering the</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>Kullback--Leibler (KL) divergence between the two univariate Gaussian</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>distributions. KL divergence captures the divergence in shape and spread</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>between the distributions.</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>We are in particular interested in the predicted performance</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>distribution of the best-predicted algorithm $A_{1,i}$ (no algorithms</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>are predicted to perform better than it), and how the predictions for</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>the other algorithms compare to it. Formally, for the best predicted</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>solver $A_{1,i}$ on instance $i$ the distribution of predictions is</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>$ \hat{m}(A_{1,i}, i) \sim \hat{M}(\mu_{A_{1,i},i}, \sigma^2_{A_{1,i},i}) $</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>with probability density function $ f_{A_{1,i},i}$ and cumulative</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>distribution function $ F_{A_{1,i},i}$. The performance distributions</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>for other algorithms are defined similarly.</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>The Kullback--Leibler (KL) divergence is a statistical metric used to</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>quantify the difference between two probability distributions <span class="co">[</span><span class="ot">@KL</span><span class="co">]</span>.</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>According to the formulation in <span class="co">[</span><span class="ot">@bishop2006pattern</span><span class="co">]</span>, given two</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>distributions $p$ and $q$ with probability density functions $p(x)$ and</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>$q(x)$, the KL divergence is calculated as:</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>$$\label{eq:5.4}</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>    KL(p \| q) = - \int p(x) \log q(x) \, dx + \int p(x) \log p(x) \, dx$$</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>In our context, we are interested in comparing the predicted performance</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>distributions of two algorithms, $A_{x}$ and $A_{y}$, on a specific</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>instance $i$. Let $f_{A_{x},i}$ and $f_{A_{y},i}$ denote the probability</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>density functions of the predicted performance of algorithms $A_{x}$ and</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>$A_{y}$ on instance $i$, respectively. By substituting $p(x)$ with</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>$f_{A_{x},i}$ and $q(x)$ with $f_{A_{y},i}$, we adapt the KL divergence</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>to quantify the difference in predicted performance between the two</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>algorithms. Thus, the KL divergence between the performance</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>distributions of $A_{x}$ and $A_{y}$ in instance $i$ is computed as</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>follows:</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>$$\label{eq:5.5} KL(f_{A_{x},i} \| f_{A_{y},i}) = - \int f_{A_{x},i}(x) \log f_{A_{y},i}(x) dx + \int f_{A_{x},i}(x) \log f_{A_{x},i}(x) dx$$</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>This formulation indicates to what extent the probability distributions</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>differ. Since the two distributions are univariate Gaussians, the exact</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>formula for KL divergence is as follows (we omit the index $i$ for the</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>sake of brevity here):</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>$$\label{eq:5.6}</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>    KL(f_{A_x} \| f_{A_y}) = \log \frac{\sigma_{A_y}}{\sigma_{A_x}} + \frac{\sigma_{A_x}^2 + (\mu_{A_x} - \mu_{A_y})^2}{2 \sigma_{A_y}^2} - \frac{1}{2}$$</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>We define $kl \in [0, \infty)$ as a threshold for the computed KL</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>divergence to include a given algorithm:</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>$$\label{eq:5.7}</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a> P_i = <span class="sc">\{</span>A \:| \:  KL(f_{A_{1,i},i} \| f_{A_{x,i},i}) \leq <span class="sc">\\</span>kl\:<span class="sc">\}</span>$$</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>$kl$ is 0 for the best predicted algorithm. In contrast to $p_{\cap}$,</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>which could only be in the range of <span class="sc">\[</span>0,1<span class="sc">\]</span>, the value of $kl$ can be</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>greater than 1. A very large value of $kl$ corresponds to algorithms</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>whose distributions diverge the most from that of the best predicted</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>algorithm, that is, algorithms with performance predictions that are</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>markedly different from those of the best predicted algorithm.</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>We can adjust the size of the parallel portfolio by modifying the $kl$</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>threshold. When $kl$ is set to 0, only the best predicted algorithm and</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>those expected to perform identically are included. Setting $kl$ to a</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>very large positive value allows all algorithms to be included. Finding</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>the optimal $kl$ is necessary to determine how many solvers to include</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>in the portfolio. This flexibility enables us to tailor the approach to</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>specific algorithm selection scenarios, allowing the selection of</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>algorithms to run in parallel and accommodating any potential</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>inaccuracies in performance predictions.</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experimental Setup</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Collection</span></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>We used the same five scenarios as in the previous chapter</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>, now included in the ASlib benchmark</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>repository <span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>: MAXSAT19-UCMS, SAT11-INDU, SAT18-EXP,</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN, and IPC2018. These datasets include algorithm performance</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>data from single and parallel runs, with parallel run measurements</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>conducted on individual machines as described in</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@kashgarani2023automatic</span><span class="co">]</span>. Feature extraction was performed using the</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>SATZilla feature extraction code for MAXSAT19-UCMS, SAT11-INDU,</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN, and SAT18-EXP, producing 54 features, while IPC2018 features</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>were extracted using the code from</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@Fawcett_Vallati_Hutter_Hoffmann_Hoos_Leyton-Brown_2014</span><span class="co">]</span>, resulting in</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>305 features.</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training</span></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>We used the same random forest regression models from Chapter 4. The</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>random forest regression models are trained in three ways: one using the</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>randomForest package in R and two using the Ranger package, to predict</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>algorithm performance on specific instances. Random forests are</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>generally recognized for their strong performance in algorithm selection</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>and performance prediction <span class="co">[</span><span class="ot">@BISCHL201641; @HUTTER201479</span><span class="co">]</span>. Given the</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>existence of two distinct implementations, we trained the models using</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>both *randomForest* and *Ranger* implementations.</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>Our regression random forest models are built using the MLR package with</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>the randomForest package as dependency, and the Ranger models are</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>trained using the MLR3 and Ranger implementations. These models predict</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>the runtime for each solver as the mean of the underlying distribution</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>and estimate the standard deviation. The initial random forest model and</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>one of the Ranger models use the Jackknife method</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@wager2014confidence; @mlr</span><span class="co">]</span>. The Jackknife method estimates the</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>standard deviation of the mean predictions in all observations used to</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>train the random forest. This technique involves training the random</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>forest model on $n-1$ observations, leaving one out each time to make a</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>prediction, and repeating this for each observation. The mean prediction</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>for each tree is calculated by averaging its predictions on the left-out</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>data points. The Jackknife method assumes that predictions follow a</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>normal distribution, with the standard deviation indicating the</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>uncertainty of the overall prediction. The infinitesimal jackknife</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>method assesses the impact of each observation by slightly</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>down-weighting it, unlike the traditional jackknife, which removes one</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>observation at a time.</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>Our setup closely follows the approach in <span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span> for all three</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>models: we excluded instance features with constant values and imputed</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>missing feature values by using the mean of all nonmissing values for</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>each feature. The random forest hyperparameters were tuned through</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>random search with 250 iterations, where $ntree$ was varied from 10 to</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>200 and $mtry$ from 1 to 30, using nested cross-validation with three</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>inner folds and 10 outer folds <span class="co">[</span><span class="ot">@BISCHL201641</span><span class="co">]</span>.</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning $kl$ and $p_{\cap}$</span></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>::: {#tab:kl}</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>  Scenario         RandomForest_Jackknife   Ranger_Jackknife   Ranger_Inifinitesimal  </span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>  --------------- ------------------------ ------------------ ----------------------- --</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>  IPC2018                   0.71                  2.35                 2.39           </span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>  MAXSAT19-UCMS             0.63                  2.7                   2.7           </span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>  SAT11-INDU                0.55                  1.62                 1.94           </span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>  SAT16-MAIN                2.66                  2.06                 2.96           </span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>  SAT18-EXP                 0.12                  1.81                 1.35           </span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>  Generic best              0.41                  2.65                 2.82           </span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>  : Optimum value of $kl$ for each benchmark and model.</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>The tuned $p_{\cap}$ value for each benchmark and each random forest</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>model is listed in Table <span class="co">[</span><span class="ot">\[tab:pcap\]</span><span class="co">](#tab:pcap)</span>{reference-type="ref"</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>reference="tab:pcap"} and we are using the same values in this chapter.</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>These values were individually optimized for each scenario to ensure</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>that the selected portfolio provided the best balance between</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>performance and computational efficiency. For tuning $kl$, we perform a</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>grid search to determine the optimal value in</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>Equation&nbsp;<span class="co">[</span><span class="ot">\[eq:5.7\]</span><span class="co">](#eq:5.7)</span>{reference-type="ref" reference="eq:5.7"}</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>for each scenario. The search is carried out over the interval $[0, 3)$</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>with a resolution $0.01$, resulting in 300 possible values.</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>The tuned $p_{\cap}$ value for each benchmark and each random forest</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>model is listed in Table <span class="co">[</span><span class="ot">\[tab:pcap\]</span><span class="co">](#tab:pcap)</span>{reference-type="ref"</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>reference="tab:pcap"}, and we use the same values in this chapter. These</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>values were individually optimized for each scenario to ensure that the</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>selected portfolio provided the best balance between performance and</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>computational efficiency. For tuning $kl$, we perform a grid search to</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>determine the optimal value in</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>Equation&nbsp;<span class="co">[</span><span class="ot">\[eq:5.7\]</span><span class="co">](#eq:5.7)</span>{reference-type="ref" reference="eq:5.7"}</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>for each scenario. The search is carried out over the interval $[0, 3)$</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>with a resolution of 0.01, resulting in 300 possible values.</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="fu">### Baselines</span></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>For all the comparisons mentioned, we evaluate the performance of our</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>approaches against several baseline methods. Specifically, we compare to</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>the sequential virtual best solver (VBS), which picks the best solver</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>for each problem instance with a cumulative misclassification penalty of</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>zero, and to the sequential single best solver (SBS), which is the</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>solver with the best average performance across all instances and a</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>cumulative misclassification penalty of one. For parallel runs, the VBS</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>is the best solver for each instance but includes the overhead for $n$</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>parallel runs. The parallel SBS is determined similarly, using the</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>solvers with the best average performance instead of the best for each</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>instance. We executed multiple solvers in parallel to capture the real</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>run-time of the best solver in this setup, instead of assuming that it</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>would run sequentially.</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>We have three algorithm selectors: RFJ (random forest with Jackknife),</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a>RJ (Ranger with Jackknife), and RI (Ranger with infinitesimal</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>Jackknife). Each algorithm selector has five approaches for comparison.</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>The first involves selecting algorithms on a per-instance basis, running</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>the top $n$ predicted algorithms in parallel without accounting for any</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>uncertainty the subportfolio selection approaches. Using the notation</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>introduced in the previous chapter, we assign $p_{\cap}=0$ and limit the</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>number of runs to match the available processors. Also, when we assign</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>$kl = \infty$, we are doing the same thing and limiting the number of</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>runs to match the available processors. The second approach uses the</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>associated tuned $p_{\cap}$ values mentioned in</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">\[tab:pcap\]</span><span class="co">](#tab:pcap)</span>{reference-type="ref"</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>reference="tab:pcap"}. The third approach uses the average $p_{\cap}$</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>value, which was the best generic value across all scenarios. Other</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>approach uses the associated tuned $kl$ values mentioned in</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>Table&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#tab:kl)</span>{reference-type="ref" reference="tab:kl"} for each</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>scenario and performance model. The last approach uses the generic best</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>$kl$ value across all scenarios for each performance model.</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>We evaluate the proposed method by measuring the penalized average</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>runtime with a factor of 10 (PAR10), the misclassification penalty</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>(MCP), and the runtime. The PAR10 metric equals the actual runtime if</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>the algorithm successfully solves the instance within the timeout;</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>otherwise, it is calculated as the timeout multiplied by 10. The MCP</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>represents the difference between the performance of the selected</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>algorithm and that of the optimal algorithm. The mean and standard</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>deviation of these values are presented in</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#tab:summary5-ipc-max)</span>{reference-type="ref"</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-ipc-max"},<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary5-sat11-sat16)</span>{reference-type="ref"</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat11-sat16"},</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>and<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary5-sat18)</span>{reference-type="ref"</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat18"}. We normalize PAR10 values across</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>scenarios using the performances of the VBS and SBS, reporting the</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>proportion of the performance gap each approach bridges. On this</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>normalized scale, 0 denotes the performance of the SBS, while 1 denotes</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>the performance of the VBS.</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>In the tables, we report the mean and standard deviation of the</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>normalized gap closed across the 10 folds of data used to train the</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>performance models. In contrast to the reported runtime, MCP, and PAR10</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a>scores, where we present the mean and standard deviation across the</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a>distribution of all instances. We use folds here to avoid zero</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a>denominators in cases where the single best solver is the actual best</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>solver for an instance, based on the normalized gap closed formula</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>$\frac{\text{sbs} - \text{approach}}{\text{sbs} - \text{vbs}}$. The</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>plots&nbsp;<span class="co">[</span><span class="ot">\[fig:all_results\]</span><span class="co">](#fig:all_results)</span>{reference-type="ref"</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a>reference="fig:all_results"}, show the PAR10 score normalized gap closed</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>over the entire distribution of instances.</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a><span class="fu">## Results</span></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning of $kl$ and $p_{\cap}$</span></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a>Tuning $p_{\cap}$ and $kl$ reveals that the optimal values vary by</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>scenario. Tables&nbsp;<span class="co">[</span><span class="ot">\[tab:pcap\]</span><span class="co">](#tab:pcap)</span>{reference-type="ref"</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>reference="tab:pcap"} and&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#tab:kl)</span>{reference-type="ref"</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>reference="tab:kl"} present the optimal values for each scenario and</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>algorithm selector. We presented</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#fig:kl_sensitivity)</span>{reference-type="ref"</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>reference="fig:kl_sensitivity"}, which shows the normalized gap closed</span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>for the mean, 25th percentile, 50th percentile, and 75th percentile</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>across each scenario based on $kl$ value. Although optimal values vary</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>significantly between scenarios and performance models, normalized gaps</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>closed remain relatively small as long as $kl$ is not too low. For the</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>most optimal performance, we recommend tuning $kl$ for each specific</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>scenario.</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>The optimal value of $kl$, similar to $p_{\cap}$, provides insight into</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>the predictive accuracy of the performance models. A large $kl$ value</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>suggests that the models' predictions may lack accuracy, as it requires</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>including solvers whose predicted runtime distributions differ</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a>significantly from that of the best predicted solver in order to capture</span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a>solvers that perform well. If the optimal value of $kl$ were 0, we would</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a>include only solvers that are exactly similar to the best-predicted</span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a>solver. A very large optimal $kl$ requires us to include all solvers,</span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>even those whose predicted distributions differ entirely from the best</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>predicted solver.</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a>Here, the optimal values for $kl$ are relatively small, typically up to</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>2.5 in most cases. The further the $kl$ value deviates from 0, the lower</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>the accuracy. Table&nbsp;<span class="co">[</span><span class="ot">1.1</span><span class="co">](#tab:kl)</span>{reference-type="ref"</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>reference="tab:kl"} also shows that the RFJ model, which uses</span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>randomForest with a Jackknife uncertainty estimate, has a significantly</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>lower optimal $kl$ in most scenarios, suggesting that this model should</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>outperform the other two when selecting single solver in 4 out of 5</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a>scenarios in terms of prediction accuracy. This is confirmed by</span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#tab:summary5-ipc-max)</span>{reference-type="ref"</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-ipc-max"},</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary5-sat11-sat16)</span>{reference-type="ref"</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat11-sat16"}</span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>and&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary5-sat18)</span>{reference-type="ref"</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat18"} which is denoted as $AS (RFJ)$. The</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a>optimal $kl$ values are closer for all scenarios when we have a single</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a>model. This seems to contrast with $p_{\cap}$, where different scenarios</span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>had significantly varying values per model. Here, the values are more</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a>consistent, suggesting that tuning this parameter per model should yield</span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a>good performance.</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a><span class="fu">### $AS_{p_{\cap}}$ vs. $AS_{kl}$ Comparison</span></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a>To evaluate the effectiveness of any of the approaches, we carried out a</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a>series of experiments using the optimum best value for $p_{\cap}$ and</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>$kl$ and $p_{\cap} = 0$ for each scenario, where we varied the number of</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a>processors used for parallel execution from one to ten for the scenarios</span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>SAT18-EXP, SAT16-MAIN, SAT11-INDU and IPC2018. For the MAXSAT19-UCMS</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a>scenario, we used a maximum of seven processors, as there are only seven</span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>algorithms. Figure&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#fig:klvspcap)</span>{reference-type="ref"</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>reference="fig:klvspcap"} shows the PAR10 score results in terms of the</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a>normalized performance gap closed between the sequential single best</span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>solver and the sequential virtual best solver for all scenarios and</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a>number of processors. In addition,</span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#tab:summary5-ipc-max)</span>{reference-type="ref"</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-ipc-max"},&nbsp;<span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary5-sat11-sat16)</span>{reference-type="ref"</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat11-sat16"}</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>and&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary5-sat18)</span>{reference-type="ref"</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat18"} show the mean and standard deviation</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a>values for runtime, MCP and PAR10 when limiting the maximum number of</span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a>parallel runs to 10 or SAT18-EXP, SAT16-MAIN, SAT11-INDU and IPC2018,</span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a>and to 7 for MAXSAT19-UCMS. In addition, we reported the mean and</span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>standard deviation of the normalized gap closed across folds in these</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>tables. This differs from the plots, as the plots report values in terms</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a>of the mean of the problem distribution rather than across folds.</span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a>Here, we discuss the results of the comparison of $AS_{p_{\cap}}$ with</span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a>the $AS_{kl}$ methods. For this comparison, we excluded the results of</span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>the RJ model in Figure&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#fig:klvspcap)</span>{reference-type="ref"</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a>reference="fig:klvspcap"} because, as mentioned in the previous section</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a>comparing ranger and randomForest, the RJ model did not outperform the</span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a>other two models in subportfolio selection, while RI and RFJ were</span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>competitive in portfolio selection. This is also evident in</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#tab:summary5-ipc-max)</span>{reference-type="ref"</span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-ipc-max"},</span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary5-sat11-sat16)</span>{reference-type="ref"</span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat11-sat16"},</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a>and&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary5-sat18)</span>{reference-type="ref"</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat18"} that the RJ model did not surpass the</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a>other two when using $AS_{p_{\cap}}$ and $AS_{kl}$. Therefore, we</span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>discuss the results for the RI and RFJ models when selecting</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a>subportfolios using Equation&nbsp;<span class="co">[</span><span class="ot">\[eq:7\]</span><span class="co">](#eq:7)</span>{reference-type="ref"</span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>reference="eq:7"}, denoted as $AS_{p_{\cap}}$, and</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a>Equation&nbsp;<span class="co">[</span><span class="ot">\[eq:5.7\]</span><span class="co">](#eq:5.7)</span>{reference-type="ref" reference="eq:5.7"},</span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a>denoted as $AS_{kl}$.</span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>When comparing $AS_{p_{\cap}}$ and $AS_{kl}$ with optimal threshold</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>values, based on</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a>Tables&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#tab:summary5-ipc-max)</span>{reference-type="ref"</span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-ipc-max"},</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">1.3</span><span class="co">](#tab:summary5-sat11-sat16)</span>{reference-type="ref"</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat11-sat16"},</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>and&nbsp;<span class="co">[</span><span class="ot">1.4</span><span class="co">](#tab:summary5-sat18)</span>{reference-type="ref"</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a>reference="tab:summary5-sat18"}, $AS_{kl}$ outperforms $AS_{p_{\cap}}$</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a>in three of four performance metrics for IPC2018 and the RFJ model. For</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a>the RI model, $AS_{p_{\cap}}$ is superior in three of the four metrics,</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a>while for the RJ model, $AS_{kl}$ performs worse in all performance</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a>metrics. Figure&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#fig:klvspcap)</span>{reference-type="ref"</span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>reference="fig:klvspcap"} further illustrates that $AS_{p_{\cap}}$</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a>consistently outperforms $AS_{kl}$ for both the RFJ and RI models when</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a>the cores are limited to different values. For the MAXSAT19-UCMS and</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a>SAT11-INDU scenarios, $AS_{p_{\cap}}$ performs better than $AS_{kl}$ in</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a>all performance metrics for the RJ, RFJ, and RI models, which is also</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>reflected in the closed mean normalized gap in</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a>Figure&nbsp;<span class="co">[</span><span class="ot">1.2</span><span class="co">](#fig:klvspcap)</span>{reference-type="ref"</span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>reference="fig:klvspcap"}. In the SAT16-MAIN scenario, $AS_{p_{\cap}}$</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a>is overall superior, except for the RFJ model, where both methods</span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>perform equally, and the RJ model where the normalized gap closed for</span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>folds is slightly worse for $AS_{p_{\cap}}$. In the SAT18-EXP scenario,</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>$AS_{p_{\cap}}$ generally outperforms $AS_{kl}$, except for the RFJ</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a>model where the two are highly competitive. In three of four performance</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>metrics, $AS_{kl}$ is better, while $AS_{p_{\cap}}$ excels in the</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a>remaining metric.</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a>When comparing the RFJ and RI models for portfolio selection using the</span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a>$AS_{kl}$ method, the RFJ model performed consistently best in all</span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a>scenarios. This contrasts with the $AS_{p_{\cap}}$ approach, where the</span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a>RI model outperformed the RFJ model in two out of five scenarios. When</span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a>comparing $AS_{p_{\cap}}$ and $AS_{kl}$ using the generic best values</span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>across the tuned scenarios for each model, $AS_{p_{\cap}}$ outperforms</span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a>$AS_{kl}$ in two of the three models for IPC2018, MAXSAT19-UCMS and</span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN. However, for the RFJ model in these scenarios, the trend is</span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a>reversed, with $AS_{kl}$ performing slightly worse. For SAT11-INDU and</span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>SAT18-EXP, $AS_{p_{\cap}}$ is the consistently better approach across</span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>all models.</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>When comparing all the experimented methods in all scenarios with the</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>number of parallel runs limited to 10, the $AS_{p_{\cap}}$ of the RI</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>model delivered the best performance for IPC2018 and SAT11-INDU in terms</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>of runtime, MCP, normalized gap, and PAR10. For these scenarios,</span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a>$AS_{kl}$ of the RI model was the second-best method. For MAXSAT19-UCMS,</span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>the $AS_{p_{\cap}}$ of the RFJ model achieved the best performance,</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a>followed by the $AS_{kl}$ of the RFJ model as the second-best method. In</span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>SAT16-MAIN, $AS_{p_{\cap}}$ of the RI model, with $p_{\cap}$ set to zero</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>and selecting the top 10 predicted algorithms, emerged as the best</span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>method. The second-best method in this scenario was the $AS_{p_{\cap}}$</span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>of the RI model, using the generic best value for $p_{\cap}$. Finally,</span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a>for SAT18-EXP, the $AS_{p_{\cap}}$ and $AS_{kl}$ methods of the RFJ</span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>model performed very competitively, both achieving the best performance.</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a>Although the $AS_{p_\cap}$ method appears to be in general superior to</span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>$AS_{kl}$, its performance is very close, making $AS_{kl}$ the best</span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a>alternative in the absence of $AS_{p_\cap}$. One significant advantage</span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>of $AS_{kl}$ is that the tuned values of $kl$ for different scenarios</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a>are highly consistent, and this suggests that tuning of $kl$ globally</span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a>across all scenarios can still produce good performance. This</span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>consistency reduces the cost of scenario-specific tuning. In contrast,</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>the $p_{\cap}$ values vary significantly between different models, and</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a>it makes tuning more challenging and model-dependent. On the other hand,</span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>$kl$ demonstrates greater consistency, with its best generic values for</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>the RI and RJ models being close, which further highlights its</span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>practicality for streamlined optimization.</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:kl_sensitivity"&gt;</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;embed src="plots/kl_div_rfj_sensitivity_x_theta_y_runtime_facet.svg"</span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>style="width:49.0%" /&gt; &lt;embed</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>src="plots/kl_ri_div_sensitivity_x_theta_y_runtime_facet.svg"</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>style="width:49.0%" /&gt; &lt;embed</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>src="plots/kl_div_rj_sensitivity_x_theta_y_runtime_facet.svg"</span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>style="width:49.0%" /&gt;&lt;/p&gt;</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt;Sensitivity of Portfolio Performance to &lt;span</span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>kl<span class="sc">\)</span>&lt;/span&gt;. The top left plot corresponds to the</span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a>RFJ model, and the top right plot corresponds to the RI model, and the</span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>bottom plot is for RJ model. The plot displays the mean, first quartile</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a>(Q1, 25th percentile), median (Q2, 50th percentile), and third quartile</span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>(Q3, 75th percentile) runtime performance for each scenario across</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a>different &lt;span class="math inline"&gt;<span class="sc">\(</span>kl<span class="sc">\)</span>&lt;/span&gt; values, as defined in</span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>Equation&nbsp;&lt;a href="#eq:5.7" data-reference-type="ref"</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a>data-reference="eq:5.7"&gt;<span class="co">[</span><span class="ot">eq:5.7</span><span class="co">]</span>&lt;/a&gt;. The y-axis uses a log scale to</span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a>represent the normalized gap closed, highlighting variations in</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>performance sensitivity relative to &lt;span</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>kl<span class="sc">\)</span>&lt;/span&gt; adjustments.&lt;/figcaption&gt;</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:klvspcap"&gt;</span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>&lt;embed</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>src="plots/kl_pcap_comparison_line_chart_parallel_NormalizedGap.svg" style="width:95%"&gt;</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt; Results Overview. The plot illustrates the extent to which</span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>each method narrows the gap between the PAR10 scores of the Single Best</span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>Solver (SBS) and the Virtual Best Solver (VBS). For VBS and SBS, the top</span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a>&lt;span class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; solvers are selected, where &lt;span</span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>n<span class="sc">\)</span>&lt;/span&gt; matches the number of processors</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a>available for each problem instance and across all instances,</span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>respectively. &lt;span class="math inline"&gt;<span class="sc">\(</span>AS_{p_{\cap}}<span class="sc">\)</span>&lt;/span&gt; and</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a>&lt;span class="math inline"&gt;<span class="sc">\(</span>AS_{kl}<span class="sc">\)</span>&lt;/span&gt; follow the approaches</span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>proposed in &lt;span class="citation"</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a>data-cites="kashgarani2023automatic"&gt;&lt;/span&gt; and Equation&nbsp;&lt;a</span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>href="#eq:5.7" data-reference-type="ref"</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a>data-reference="eq:5.7"&gt;<span class="co">[</span><span class="ot">eq:5.7</span><span class="co">]</span>&lt;/a&gt;, respectively, with the number of</span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a>processors capped at the specific value on the x-axis — fewer solvers</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a>than this maximum may be selected based on the overlap and divergence in</span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a>runtime predictions. The RFJ model is trained with the randomForest and</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a>Jackknife method, RI uses the Ranger model with the Infinitesimal</span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>Jackknife method. The optimal &lt;span</span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>p_{\cap}<span class="sc">\)</span>&lt;/span&gt; and &lt;span</span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>kl<span class="sc">\)</span>&lt;/span&gt; values for each scenario and each</span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a>model are listed in Tables&nbsp;&lt;a href="#tab:pcap" data-reference-type="ref"</span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a>data-reference="tab:pcap"&gt;<span class="co">[</span><span class="ot">tab:pcap</span><span class="co">]</span>&lt;/a&gt; and&nbsp;&lt;a href="#tab:kl"</span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a>data-reference-type="ref" data-reference="tab:kl"&gt;1.1&lt;/a&gt;. &lt;/figcaption&gt;</span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary5-ipc-max}</span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                    Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                           MCP                                PAR10                             NormalizedGap</span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a>  ---------- -------------------------------- ----------------------------------- --------------------------------- ------------------------------------- -------------------------------------</span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                              </span></span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                 508$\pm$`&lt;!-- --&gt;`{=html}697                     0                    3478$\pm$`&lt;!-- --&gt;`{=html}6903                       1</span></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                            607$\pm$`&lt;!-- --&gt;`{=html}751        99$\pm$`&lt;!-- --&gt;`{=html}301       4657$\pm$`&lt;!-- --&gt;`{=html}7725        -0.44$\pm$`&lt;!-- --&gt;`{=html}2.84</span></span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                             608$\pm$`&lt;!-- --&gt;`{=html}751       100$\pm$`&lt;!-- --&gt;`{=html}293       4456$\pm$`&lt;!-- --&gt;`{=html}7583        -0.35$\pm$`&lt;!-- --&gt;`{=html}2.85</span></span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                             604$\pm$`&lt;!-- --&gt;`{=html}752        96$\pm$`&lt;!-- --&gt;`{=html}293       4519$\pm$`&lt;!-- --&gt;`{=html}7633        -0.39$\pm$`&lt;!-- --&gt;`{=html}2.84</span></span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                 734$\pm$`&lt;!-- --&gt;`{=html}770       226$\pm$`&lt;!-- --&gt;`{=html}414       5459$\pm$`&lt;!-- --&gt;`{=html}8072                       0</span></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                            </span></span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RFJ)           612$\pm$`&lt;!-- --&gt;`{=html}779       104$\pm$`&lt;!-- --&gt;`{=html}307       5134$\pm$`&lt;!-- --&gt;`{=html}8027        -0.66$\pm$`&lt;!-- --&gt;`{=html}2.56</span></span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)            616$\pm$`&lt;!-- --&gt;`{=html}783       107$\pm$`&lt;!-- --&gt;`{=html}312       5206$\pm$`&lt;!-- --&gt;`{=html}8065        -0.69$\pm$`&lt;!-- --&gt;`{=html}2.54</span></span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RJ)            616$\pm$`&lt;!-- --&gt;`{=html}783       107$\pm$`&lt;!-- --&gt;`{=html}312       5206$\pm$`&lt;!-- --&gt;`{=html}8065        -0.69$\pm$`&lt;!-- --&gt;`{=html}2.54</span></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.59}$ (RFJ)        569$\pm$`&lt;!-- --&gt;`{=html}745        61$\pm$`&lt;!-- --&gt;`{=html}223       4484$\pm$`&lt;!-- --&gt;`{=html}7651      **-0.18$\pm$`&lt;!-- --&gt;`{=html}2.74**</span></span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.44}$ (RI)       **557$\pm$`&lt;!-- --&gt;`{=html}728**    **49$\pm$`&lt;!-- --&gt;`{=html}190**   **4135$\pm$`&lt;!-- --&gt;`{=html}7403**     *-0.19$\pm$`&lt;!-- --&gt;`{=html}2.89*</span></span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.27}$ (RJ)         570$\pm$`&lt;!-- --&gt;`{=html}744        62$\pm$`&lt;!-- --&gt;`{=html}229       4350$\pm$`&lt;!-- --&gt;`{=html}7552        -0.21$\pm$`&lt;!-- --&gt;`{=html}2.72</span></span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)        579$\pm$`&lt;!-- --&gt;`{=html}742        70$\pm$`&lt;!-- --&gt;`{=html}233       4359$\pm$`&lt;!-- --&gt;`{=html}7548        -0.26$\pm$`&lt;!-- --&gt;`{=html}2.88</span></span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)         570$\pm$`&lt;!-- --&gt;`{=html}739        62$\pm$`&lt;!-- --&gt;`{=html}230       4283$\pm$`&lt;!-- --&gt;`{=html}7501        -0.24$\pm$`&lt;!-- --&gt;`{=html}2.87</span></span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)         570$\pm$`&lt;!-- --&gt;`{=html}743        62$\pm$`&lt;!-- --&gt;`{=html}229       4350$\pm$`&lt;!-- --&gt;`{=html}7552        -0.21$\pm$`&lt;!-- --&gt;`{=html}2.72</span></span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.71} (RFJ)$             *560$\pm$`&lt;!-- --&gt;`{=html}735*      *52$\pm$`&lt;!-- --&gt;`{=html}193*     *4272$\pm$`&lt;!-- --&gt;`{=html}7506*       -0.19$\pm$`&lt;!-- --&gt;`{=html}2.71</span></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.39} (RI)$               570$\pm$`&lt;!-- --&gt;`{=html}740        62$\pm$`&lt;!-- --&gt;`{=html}224       4350$\pm$`&lt;!-- --&gt;`{=html}7552        -0.3$\pm$`&lt;!-- --&gt;`{=html}2.86</span></span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.35} (RJ)$               577$\pm$`&lt;!-- --&gt;`{=html}750        70$\pm$`&lt;!-- --&gt;`{=html}243       4492$\pm$`&lt;!-- --&gt;`{=html}7647        -0.31$\pm$`&lt;!-- --&gt;`{=html}2.67</span></span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.41} (RFJ)$              571$\pm$`&lt;!-- --&gt;`{=html}738        63$\pm$`&lt;!-- --&gt;`{=html}220       4351$\pm$`&lt;!-- --&gt;`{=html}7551        -0.23$\pm$`&lt;!-- --&gt;`{=html}2.73</span></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.82} (RI)$               575$\pm$`&lt;!-- --&gt;`{=html}746        67$\pm$`&lt;!-- --&gt;`{=html}244       4423$\pm$`&lt;!-- --&gt;`{=html}7599        -0.32$\pm$`&lt;!-- --&gt;`{=html}2.85</span></span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.65} (RJ)$               577$\pm$`&lt;!-- --&gt;`{=html}750        70$\pm$`&lt;!-- --&gt;`{=html}243       4492$\pm$`&lt;!-- --&gt;`{=html}7647        -0.31$\pm$`&lt;!-- --&gt;`{=html}2.67</span></span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                              </span></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                                 858$\pm$`&lt;!-- --&gt;`{=html}1476                    0                    7768$\pm$`&lt;!-- --&gt;`{=html}14717                      1</span></span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                           1037$\pm$`&lt;!-- --&gt;`{=html}1555      179$\pm$`&lt;!-- --&gt;`{=html}641       9363$\pm$`&lt;!-- --&gt;`{=html}15684       0.55$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                            1076$\pm$`&lt;!-- --&gt;`{=html}1575      218$\pm$`&lt;!-- --&gt;`{=html}729       9686$\pm$`&lt;!-- --&gt;`{=html}15850       0.45$\pm$`&lt;!-- --&gt;`{=html}0.34</span></span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                            1044$\pm$`&lt;!-- --&gt;`{=html}1565      186$\pm$`&lt;!-- --&gt;`{=html}666       9540$\pm$`&lt;!-- --&gt;`{=html}15793       0.49$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                                1190$\pm$`&lt;!-- --&gt;`{=html}1657      332$\pm$`&lt;!-- --&gt;`{=html}940      11386$\pm$`&lt;!-- --&gt;`{=html}16696                      0</span></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a><span class="in">             **7 Processors**                                                                                                                             </span></span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RFJ)           894$\pm$`&lt;!-- --&gt;`{=html}1506       37$\pm$`&lt;!-- --&gt;`{=html}247       8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)            894$\pm$`&lt;!-- --&gt;`{=html}1506       37$\pm$`&lt;!-- --&gt;`{=html}247       8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RJ)            894$\pm$`&lt;!-- --&gt;`{=html}1506       37$\pm$`&lt;!-- --&gt;`{=html}247       8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = {0.55}}$ (RFJ)    **891$\pm$`&lt;!-- --&gt;`{=html}1496**   **33$\pm$`&lt;!-- --&gt;`{=html}215**   **8141$\pm$`&lt;!-- --&gt;`{=html}14975**   **0.88$\pm$`&lt;!-- --&gt;`{=html}0.17**</span></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.03}$ (RI)         894$\pm$`&lt;!-- --&gt;`{=html}1506       37$\pm$`&lt;!-- --&gt;`{=html}247       8258$\pm$`&lt;!-- --&gt;`{=html}15062       0.85$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.14}$ (RJ)         921$\pm$`&lt;!-- --&gt;`{=html}1521       63$\pm$`&lt;!-- --&gt;`{=html}369       8568$\pm$`&lt;!-- --&gt;`{=html}15263       0.76$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)        928$\pm$`&lt;!-- --&gt;`{=html}1513       70$\pm$`&lt;!-- --&gt;`{=html}364       8461$\pm$`&lt;!-- --&gt;`{=html}15175       0.81$\pm$`&lt;!-- --&gt;`{=html}0.18</span></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)         901$\pm$`&lt;!-- --&gt;`{=html}1502       43$\pm$`&lt;!-- --&gt;`{=html}275       8208$\pm$`&lt;!-- --&gt;`{=html}15015      *0.88$\pm$`&lt;!-- --&gt;`{=html}0.16*</span></span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)         931$\pm$`&lt;!-- --&gt;`{=html}1525       73$\pm$`&lt;!-- --&gt;`{=html}402       8578$\pm$`&lt;!-- --&gt;`{=html}15259       0.78$\pm$`&lt;!-- --&gt;`{=html}0.21</span></span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.63} (RFJ)$             *892$\pm$`&lt;!-- --&gt;`{=html}1495*     *35$\pm$`&lt;!-- --&gt;`{=html}216*     *8143$\pm$`&lt;!-- --&gt;`{=html}14974*    **0.88$\pm$`&lt;!-- --&gt;`{=html}0.17**</span></span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.7} (RI)$                920$\pm$`&lt;!-- --&gt;`{=html}1517       63$\pm$`&lt;!-- --&gt;`{=html}349       8454$\pm$`&lt;!-- --&gt;`{=html}15179       0.82$\pm$`&lt;!-- --&gt;`{=html}0.17</span></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.7} (RJ)$                931$\pm$`&lt;!-- --&gt;`{=html}1530       74$\pm$`&lt;!-- --&gt;`{=html}409       8691$\pm$`&lt;!-- --&gt;`{=html}15342       0.74$\pm$`&lt;!-- --&gt;`{=html}0.25</span></span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.41} (RFJ)$              915$\pm$`&lt;!-- --&gt;`{=html}1513       57$\pm$`&lt;!-- --&gt;`{=html}335       8448$\pm$`&lt;!-- --&gt;`{=html}15182        0.8$\pm$`&lt;!-- --&gt;`{=html}0.19</span></span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.82} (RI)$               921$\pm$`&lt;!-- --&gt;`{=html}1517       63$\pm$`&lt;!-- --&gt;`{=html}349       8454$\pm$`&lt;!-- --&gt;`{=html}15179       0.82$\pm$`&lt;!-- --&gt;`{=html}0.17</span></span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.65} (RJ)$               931$\pm$`&lt;!-- --&gt;`{=html}1530       74$\pm$`&lt;!-- --&gt;`{=html}409       8691$\pm$`&lt;!-- --&gt;`{=html}15342       0.74$\pm$`&lt;!-- --&gt;`{=html}0.25</span></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a>  of processors (10 for IPC2018, and 7 for MAXSAT19-UCMS) for our</span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a>  approaches and the baselines we compare to. All numbers were rounded</span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a>  to integers. The best value for each scenario and measure is shown in</span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a>  **bold** (excepting the sequential VBS, which is by definition always</span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a>  the best), the second best in *italics*. The normalized gap closed</span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a>  represents the mean and standard deviation of the normalized gap</span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a>  closed across the folds.</span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary5-sat11-sat16}</span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                  Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                            MCP                                 PAR10                             NormalizedGap</span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a>  ---------- ------------------------------ ------------------------------------ ---------------------------------- -------------------------------------- -----------------------------------</span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                               </span></span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                               1140$\pm$`&lt;!-- --&gt;`{=html}1836                    0                     8040$\pm$`&lt;!-- --&gt;`{=html}17905                      1</span></span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                          1535$\pm$`&lt;!-- --&gt;`{=html}2058      395$\pm$`&lt;!-- --&gt;`{=html}1037       11735$\pm$`&lt;!-- --&gt;`{=html}20768      0.16$\pm$`&lt;!-- --&gt;`{=html}0.79</span></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                           1610$\pm$`&lt;!-- --&gt;`{=html}2108      470$\pm$`&lt;!-- --&gt;`{=html}1145       12710$\pm$`&lt;!-- --&gt;`{=html}21389      -0.06$\pm$`&lt;!-- --&gt;`{=html}0.9</span></span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                           1565$\pm$`&lt;!-- --&gt;`{=html}2049      425$\pm$`&lt;!-- --&gt;`{=html}1017       11315$\pm$`&lt;!-- --&gt;`{=html}20402      0.34$\pm$`&lt;!-- --&gt;`{=html}0.49</span></span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                               1818$\pm$`&lt;!-- --&gt;`{=html}2168      678$\pm$`&lt;!-- --&gt;`{=html}1340       14268$\pm$`&lt;!-- --&gt;`{=html}22154                     0</span></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                             </span></span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RFJ)         1272$\pm$`&lt;!-- --&gt;`{=html}1927       161$\pm$`&lt;!-- --&gt;`{=html}548       8922$\pm$`&lt;!-- --&gt;`{=html}18645      *0.89$\pm$`&lt;!-- --&gt;`{=html}0.12*</span></span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)         *1238$\pm$`&lt;!-- --&gt;`{=html}1892*      127$\pm$`&lt;!-- --&gt;`{=html}385      *8588$\pm$`&lt;!-- --&gt;`{=html}18350*     **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RJ)          1262$\pm$`&lt;!-- --&gt;`{=html}1910       151$\pm$`&lt;!-- --&gt;`{=html}480       8612$\pm$`&lt;!-- --&gt;`{=html}18342      **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.63}$ (RFJ)      1241$\pm$`&lt;!-- --&gt;`{=html}1901       131$\pm$`&lt;!-- --&gt;`{=html}451       8591$\pm$`&lt;!-- --&gt;`{=html}18349      **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.01}$ (RI)     **1236$\pm$`&lt;!-- --&gt;`{=html}1890**   **121$\pm$`&lt;!-- --&gt;`{=html}379**   **8586$\pm$`&lt;!-- --&gt;`{=html}18351**    **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       1289$\pm$`&lt;!-- --&gt;`{=html}1934       178$\pm$`&lt;!-- --&gt;`{=html}595       9089$\pm$`&lt;!-- --&gt;`{=html}18787       0.78$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)      1247$\pm$`&lt;!-- --&gt;`{=html}1900      *123$\pm$`&lt;!-- --&gt;`{=html}431*      8747$\pm$`&lt;!-- --&gt;`{=html}18501       0.83$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)       1259$\pm$`&lt;!-- --&gt;`{=html}1912       139$\pm$`&lt;!-- --&gt;`{=html}477       8909$\pm$`&lt;!-- --&gt;`{=html}18649       0.74$\pm$`&lt;!-- --&gt;`{=html}0.36</span></span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       1289$\pm$`&lt;!-- --&gt;`{=html}1934       178$\pm$`&lt;!-- --&gt;`{=html}595       9089$\pm$`&lt;!-- --&gt;`{=html}18787       0.78$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.55} (RFJ)$            1243$\pm$`&lt;!-- --&gt;`{=html}1902       132$\pm$`&lt;!-- --&gt;`{=html}450       8593$\pm$`&lt;!-- --&gt;`{=html}18349      **0.92$\pm$`&lt;!-- --&gt;`{=html}0.1**</span></span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 1.62} (RI)$             1283$\pm$`&lt;!-- --&gt;`{=html}1931       158$\pm$`&lt;!-- --&gt;`{=html}539       9233$\pm$`&lt;!-- --&gt;`{=html}18936       0.68$\pm$`&lt;!-- --&gt;`{=html}0.34</span></span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 1.94} (RJ)$             1307$\pm$`&lt;!-- --&gt;`{=html}1950       194$\pm$`&lt;!-- --&gt;`{=html}622       9407$\pm$`&lt;!-- --&gt;`{=html}19072       0.73$\pm$`&lt;!-- --&gt;`{=html}0.26</span></span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.41} (RFJ)$            1250$\pm$`&lt;!-- --&gt;`{=html}1910       137$\pm$`&lt;!-- --&gt;`{=html}465       8750$\pm$`&lt;!-- --&gt;`{=html}18501      *0.89$\pm$`&lt;!-- --&gt;`{=html}0.12*</span></span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.82} (RI)$             1288$\pm$`&lt;!-- --&gt;`{=html}1939       166$\pm$`&lt;!-- --&gt;`{=html}550       9238$\pm$`&lt;!-- --&gt;`{=html}18934       0.68$\pm$`&lt;!-- --&gt;`{=html}0.34</span></span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.65} (RJ)$             1310$\pm$`&lt;!-- --&gt;`{=html}1953       198$\pm$`&lt;!-- --&gt;`{=html}626       9410$\pm$`&lt;!-- --&gt;`{=html}19071       0.73$\pm$`&lt;!-- --&gt;`{=html}0.26</span></span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                               </span></span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a><span class="in">     2-6     VBS                               1867$\pm$`&lt;!-- --&gt;`{=html}2193                    0                     15005$\pm$`&lt;!-- --&gt;`{=html}22530                     1</span></span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                          2315$\pm$`&lt;!-- --&gt;`{=html}2273      448$\pm$`&lt;!-- --&gt;`{=html}1109       19066$\pm$`&lt;!-- --&gt;`{=html}23883      0.33$\pm$`&lt;!-- --&gt;`{=html}0.56</span></span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                           2383$\pm$`&lt;!-- --&gt;`{=html}2294      516$\pm$`&lt;!-- --&gt;`{=html}1151       19956$\pm$`&lt;!-- --&gt;`{=html}24111      0.05$\pm$`&lt;!-- --&gt;`{=html}0.66</span></span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                           2400$\pm$`&lt;!-- --&gt;`{=html}2269      533$\pm$`&lt;!-- --&gt;`{=html}1177       19316$\pm$`&lt;!-- --&gt;`{=html}23880       0.3$\pm$`&lt;!-- --&gt;`{=html}0.24</span></span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                               2560$\pm$`&lt;!-- --&gt;`{=html}2294      693$\pm$`&lt;!-- --&gt;`{=html}1415       21940$\pm$`&lt;!-- --&gt;`{=html}24464                     0</span></span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a><span class="in">     2-6     **10 Processors**                                                                                                                             </span></span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a><span class="in">     2-6     $AS_{p_{\cap} = 0}$ (RFJ)         2065$\pm$`&lt;!-- --&gt;`{=html}2221       198$\pm$`&lt;!-- --&gt;`{=html}652     **16189$\pm$`&lt;!-- --&gt;`{=html}22931**    *0.7$\pm$`&lt;!-- --&gt;`{=html}0.39*</span></span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)        **2016$\pm$`&lt;!-- --&gt;`{=html}2225**   **150$\pm$`&lt;!-- --&gt;`{=html}503**     16469$\pm$`&lt;!-- --&gt;`{=html}23122       0.68$\pm$`&lt;!-- --&gt;`{=html}0.6</span></span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RJ)          2048$\pm$`&lt;!-- --&gt;`{=html}2228       181$\pm$`&lt;!-- --&gt;`{=html}597       16336$\pm$`&lt;!-- --&gt;`{=html}23023      0.68$\pm$`&lt;!-- --&gt;`{=html}0.59</span></span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.33}$ (RFJ)      2065$\pm$`&lt;!-- --&gt;`{=html}2221       198$\pm$`&lt;!-- --&gt;`{=html}652     **16189$\pm$`&lt;!-- --&gt;`{=html}22931**    *0.7$\pm$`&lt;!-- --&gt;`{=html}0.39*</span></span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)        **2016$\pm$`&lt;!-- --&gt;`{=html}2225**   **150$\pm$`&lt;!-- --&gt;`{=html}503**     16469$\pm$`&lt;!-- --&gt;`{=html}23122       0.68$\pm$`&lt;!-- --&gt;`{=html}0.6</span></span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.33}$ (RJ)       2088$\pm$`&lt;!-- --&gt;`{=html}2239       222$\pm$`&lt;!-- --&gt;`{=html}704       16705$\pm$`&lt;!-- --&gt;`{=html}23156      0.64$\pm$`&lt;!-- --&gt;`{=html}0.37</span></span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)      2094$\pm$`&lt;!-- --&gt;`{=html}2222       228$\pm$`&lt;!-- --&gt;`{=html}730       16383$\pm$`&lt;!-- --&gt;`{=html}22993      0.69$\pm$`&lt;!-- --&gt;`{=html}0.41</span></span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)      *2041$\pm$`&lt;!-- --&gt;`{=html}2230*     *174$\pm$`&lt;!-- --&gt;`{=html}591*      16822$\pm$`&lt;!-- --&gt;`{=html}23261      0.57$\pm$`&lt;!-- --&gt;`{=html}0.63</span></span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       2096$\pm$`&lt;!-- --&gt;`{=html}2240       229$\pm$`&lt;!-- --&gt;`{=html}713       16877$\pm$`&lt;!-- --&gt;`{=html}23227      0.63$\pm$`&lt;!-- --&gt;`{=html}0.36</span></span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.66} (RFJ)$            2065$\pm$`&lt;!-- --&gt;`{=html}2221       198$\pm$`&lt;!-- --&gt;`{=html}652     **16189$\pm$`&lt;!-- --&gt;`{=html}22931**    *0.7$\pm$`&lt;!-- --&gt;`{=html}0.39*</span></span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.96} (RI)$             2070$\pm$`&lt;!-- --&gt;`{=html}2236       204$\pm$`&lt;!-- --&gt;`{=html}647       17016$\pm$`&lt;!-- --&gt;`{=html}23318      0.64$\pm$`&lt;!-- --&gt;`{=html}0.59</span></span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.06} (RJ)$             2104$\pm$`&lt;!-- --&gt;`{=html}2245       237$\pm$`&lt;!-- --&gt;`{=html}736       17049$\pm$`&lt;!-- --&gt;`{=html}23297      0.69$\pm$`&lt;!-- --&gt;`{=html}0.35</span></span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.41} (RFJ)$            2089$\pm$`&lt;!-- --&gt;`{=html}2223       223$\pm$`&lt;!-- --&gt;`{=html}698      *16213$\pm$`&lt;!-- --&gt;`{=html}22916*    **0.71$\pm$`&lt;!-- --&gt;`{=html}0.4**</span></span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.82} (RI)$             2093$\pm$`&lt;!-- --&gt;`{=html}2238       227$\pm$`&lt;!-- --&gt;`{=html}704       17203$\pm$`&lt;!-- --&gt;`{=html}23376      0.59$\pm$`&lt;!-- --&gt;`{=html}0.39</span></span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.65} (RJ)$             2104$\pm$`&lt;!-- --&gt;`{=html}2245       237$\pm$`&lt;!-- --&gt;`{=html}735       17049$\pm$`&lt;!-- --&gt;`{=html}23297      0.62$\pm$`&lt;!-- --&gt;`{=html}0.36</span></span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a>  of processors (10 for SAT16-MAIN and SAT11-INDU) for our approaches</span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a>  and the baselines we compare to. All numbers were rounded to integers.</span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a>  The best value for each scenario and measure is shown in **bold**</span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a>  (excepting the sequential VBS, which is by definition always the</span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a>  best), the second best in *italics*. The normalized gap closed</span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a>  represents the mean and standard deviation of the normalized gap</span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a>  closed across the folds.</span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a>:::: center</span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a>::: {#tab:summary5-sat18}</span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a>   Scenario  Approach                                  Runtime <span class="sc">\[</span>s<span class="sc">\]</span>                             MCP                                 PAR10                             NormalizedGap</span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a>  ---------- ------------------------------ ------------------------------------ ----------------------------------- -------------------------------------- ------------------------------------</span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a><span class="in">             **1 Processor**                                                                                                                                </span></span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a><span class="in">             VBS                               1146$\pm$`&lt;!-- --&gt;`{=html}1945                     0                     9687$\pm$`&lt;!-- --&gt;`{=html}19547                      1</span></span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RFJ)                          1615$\pm$`&lt;!-- --&gt;`{=html}2138       468$\pm$`&lt;!-- --&gt;`{=html}1192       13470$\pm$`&lt;!-- --&gt;`{=html}21889       0.64$\pm$`&lt;!-- --&gt;`{=html}0.18</span></span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RI)                           1648$\pm$`&lt;!-- --&gt;`{=html}2151       502$\pm$`&lt;!-- --&gt;`{=html}1256       13758$\pm$`&lt;!-- --&gt;`{=html}22034       0.59$\pm$`&lt;!-- --&gt;`{=html}0.18</span></span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a><span class="in">             AS (RJ)                           1690$\pm$`&lt;!-- --&gt;`{=html}2170       543$\pm$`&lt;!-- --&gt;`{=html}1302       14183$\pm$`&lt;!-- --&gt;`{=html}22247       0.57$\pm$`&lt;!-- --&gt;`{=html}0.16</span></span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a><span class="in">             SBS                               2400$\pm$`&lt;!-- --&gt;`{=html}2249      1254$\pm$`&lt;!-- --&gt;`{=html}1832       20629$\pm$`&lt;!-- --&gt;`{=html}24280                     0</span></span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a><span class="in">             **10 Processors**                                                                                                                              </span></span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RFJ)         1702$\pm$`&lt;!-- --&gt;`{=html}2301       559$\pm$`&lt;!-- --&gt;`{=html}1389       16235$\pm$`&lt;!-- --&gt;`{=html}23355       0.39$\pm$`&lt;!-- --&gt;`{=html}0.27</span></span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RI)          1654$\pm$`&lt;!-- --&gt;`{=html}2285       511$\pm$`&lt;!-- --&gt;`{=html}1324       15804$\pm$`&lt;!-- --&gt;`{=html}23194       0.42$\pm$`&lt;!-- --&gt;`{=html}0.29</span></span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0}$ (RJ)          1678$\pm$`&lt;!-- --&gt;`{=html}2288       535$\pm$`&lt;!-- --&gt;`{=html}1351       15956$\pm$`&lt;!-- --&gt;`{=html}23243        0.4$\pm$`&lt;!-- --&gt;`{=html}0.3</span></span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.81}$ (RFJ)     *1518$\pm$`&lt;!-- --&gt;`{=html}2172*    **372$\pm$`&lt;!-- --&gt;`{=html}1124**    *13884$\pm$`&lt;!-- --&gt;`{=html}22265*     *0.62$\pm$`&lt;!-- --&gt;`{=html}0.22*</span></span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.55}$ (RI)       1541$\pm$`&lt;!-- --&gt;`{=html}2191       397$\pm$`&lt;!-- --&gt;`{=html}1177       14034$\pm$`&lt;!-- --&gt;`{=html}22332      *0.6$\pm$`&lt;!-- --&gt;`{=html}0.21*</span></span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.58}$ (RJ)       1622$\pm$`&lt;!-- --&gt;`{=html}2237       477$\pm$`&lt;!-- --&gt;`{=html}1268       15008$\pm$`&lt;!-- --&gt;`{=html}22805       0.5$\pm$`&lt;!-- --&gt;`{=html}0.25</span></span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.82}$ (RFJ)      1532$\pm$`&lt;!-- --&gt;`{=html}2178       386$\pm$`&lt;!-- --&gt;`{=html}1146       14025$\pm$`&lt;!-- --&gt;`{=html}22336       0.6$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.17}$ (RI)       1555$\pm$`&lt;!-- --&gt;`{=html}2221       410$\pm$`&lt;!-- --&gt;`{=html}1191       14558$\pm$`&lt;!-- --&gt;`{=html}22628       0.57$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{p_{\cap} = 0.31}$ (RJ)       1649$\pm$`&lt;!-- --&gt;`{=html}2265       505$\pm$`&lt;!-- --&gt;`{=html}1319       15544$\pm$`&lt;!-- --&gt;`{=html}23064       0.46$\pm$`&lt;!-- --&gt;`{=html}0.26</span></span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.12} (RFJ)$          **1518$\pm$`&lt;!-- --&gt;`{=html}2169**    *373$\pm$`&lt;!-- --&gt;`{=html}1129*    **13756$\pm$`&lt;!-- --&gt;`{=html}22187**   **0.62$\pm$`&lt;!-- --&gt;`{=html}0.23**</span></span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 1.81} (RI)$             1567$\pm$`&lt;!-- --&gt;`{=html}2213       422$\pm$`&lt;!-- --&gt;`{=html}1211       14442$\pm$`&lt;!-- --&gt;`{=html}22547       0.58$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 1.35} (RJ)$             1656$\pm$`&lt;!-- --&gt;`{=html}2268       512$\pm$`&lt;!-- --&gt;`{=html}1316       15551$\pm$`&lt;!-- --&gt;`{=html}23060       0.45$\pm$`&lt;!-- --&gt;`{=html}0.23</span></span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 0.41} (RFJ)$            1585$\pm$`&lt;!-- --&gt;`{=html}2230       440$\pm$`&lt;!-- --&gt;`{=html}1236       14843$\pm$`&lt;!-- --&gt;`{=html}22755       0.53$\pm$`&lt;!-- --&gt;`{=html}0.28</span></span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.82} (RI)$             1569$\pm$`&lt;!-- --&gt;`{=html}2227       424$\pm$`&lt;!-- --&gt;`{=html}1219       14699$\pm$`&lt;!-- --&gt;`{=html}22693       0.55$\pm$`&lt;!-- --&gt;`{=html}0.22</span></span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a><span class="in">             $AS_{kl = 2.65} (RJ)$             1669$\pm$`&lt;!-- --&gt;`{=html}2274       525$\pm$`&lt;!-- --&gt;`{=html}1335       15691$\pm$`&lt;!-- --&gt;`{=html}23119       0.43$\pm$`&lt;!-- --&gt;`{=html}0.22</span></span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a>  : Detailed results. Mean and standard deviation of values for runtime,</span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a>  MCP, and PAR10 across all problem instances in a scenario for the</span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a>  sequential virtual best solver, sequential single best solver, and</span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a>  single top predicted algorithm in the initial three rows. The second</span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a>  set of rows for each scenario shows the results for the maximum number</span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a>  of processors (10 for SAT18-EXP) for our approaches and the baselines</span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a>  we compare to. All numbers were rounded to integers. The best value</span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a>  for each scenario and measure is shown in **bold** (excepting the</span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a>  sequential VBS, which is by definition always the best), the second</span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a>  best in *italics*. The normalized gap closed represents the mean and</span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a>  standard deviation of the normalized gap closed across the folds.</span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a>&lt;figure id="fig:numberofsolvers_kl"&gt;</span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;embed src="plots/number_of_solvers_rf_kl.svg" style="width:50.0%" /&gt;</span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a>&lt;embed src="plots/number_of_solvers_infjack_kl.svg"</span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a>style="width:50.0%" /&gt; &lt;embed src="plots/number_of_solvers_jack_kl.svg"</span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a>style="width:50.0%" /&gt;&lt;/p&gt;</span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a>&lt;figcaption&gt; Violin plot of the distribution of the number of selected</span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a>solvers to run in parallel across all problem instances for each</span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a>scenario for the respective optimal &lt;span</span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a>class="math inline"&gt;<span class="sc">\(</span>kl<span class="sc">\)</span>&lt;/span&gt; and the maximum level of parallelism</span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a>(seven processors for MAXSAT19-UCMS and 10 for all other scenarios). The</span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a>diamond denotes the mean value. The top-left plot refers to the RFJ</span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a>model, the top-right plot to the RI model, and the bottom plot to the RJ</span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a>model. &lt;/figcaption&gt;</span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a>&lt;/figure&gt;</span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusions and Future Work</span></span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a>In this study, we proposed a variation of the method introduced in</span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a>Chapter 4 and expanded our experiments to incorporate these adaptations.</span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a>We developed an alternative general approach for selecting solvers from</span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a>a portfolio and scheduling them in parallel. This method leverages the</span>
<span id="cb1-737"><a href="#cb1-737" aria-hidden="true" tabindex="-1"></a>predicted runtime distribution to make informed decisions about which</span>
<span id="cb1-738"><a href="#cb1-738" aria-hidden="true" tabindex="-1"></a>solvers and how many to run in parallel. Specifically, in contrast to</span>
<span id="cb1-739"><a href="#cb1-739" aria-hidden="true" tabindex="-1"></a>the method introduced in Chapter 4, where the joint probability of the</span>
<span id="cb1-740"><a href="#cb1-740" aria-hidden="true" tabindex="-1"></a>prediction distribution is used as a measure of the likelihood that an</span>
<span id="cb1-741"><a href="#cb1-741" aria-hidden="true" tabindex="-1"></a>algorithm performs, as well as the best-predicted solver, the new</span>
<span id="cb1-742"><a href="#cb1-742" aria-hidden="true" tabindex="-1"></a>approach utilizes the KL divergence formula. This allows us to evaluate</span>
<span id="cb1-743"><a href="#cb1-743" aria-hidden="true" tabindex="-1"></a>how much an algorithm's prediction diverges from the best-predicted</span>
<span id="cb1-744"><a href="#cb1-744" aria-hidden="true" tabindex="-1"></a>solver, excluding solvers whose predictions differ the most. Moreover,</span>
<span id="cb1-745"><a href="#cb1-745" aria-hidden="true" tabindex="-1"></a>similar to previous chapter, we measured the actual runtime when</span>
<span id="cb1-746"><a href="#cb1-746" aria-hidden="true" tabindex="-1"></a>operating multiple algorithms in parallel, instead of relying on assumed</span>
<span id="cb1-747"><a href="#cb1-747" aria-hidden="true" tabindex="-1"></a>sequential runtimes.</span>
<span id="cb1-748"><a href="#cb1-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-749"><a href="#cb1-749" aria-hidden="true" tabindex="-1"></a>Our results showed that while the previous method outperforms the new</span>
<span id="cb1-750"><a href="#cb1-750" aria-hidden="true" tabindex="-1"></a>approach, in the absence of the old method, the new approach proves to</span>
<span id="cb1-751"><a href="#cb1-751" aria-hidden="true" tabindex="-1"></a>be superior. Additionally, tuning the threshold for the joint</span>
<span id="cb1-752"><a href="#cb1-752" aria-hidden="true" tabindex="-1"></a>probability in the method of the previous chapter varies significantly</span>
<span id="cb1-753"><a href="#cb1-753" aria-hidden="true" tabindex="-1"></a>between different benchmarks and performance models. In contrast, the</span>
<span id="cb1-754"><a href="#cb1-754" aria-hidden="true" tabindex="-1"></a>tuned threshold for divergence in the new approach is more consistent</span>
<span id="cb1-755"><a href="#cb1-755" aria-hidden="true" tabindex="-1"></a>and this consistency can reduce the computational effort required for</span>
<span id="cb1-756"><a href="#cb1-756" aria-hidden="true" tabindex="-1"></a>tuning.</span>
<span id="cb1-757"><a href="#cb1-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-758"><a href="#cb1-758" aria-hidden="true" tabindex="-1"></a>For future work, we plan to explore replacing the performance models</span>
<span id="cb1-759"><a href="#cb1-759" aria-hidden="true" tabindex="-1"></a>with models trained on parallel data instead of sequential data.</span>
<span id="cb1-760"><a href="#cb1-760" aria-hidden="true" tabindex="-1"></a>Currently, the training data does not reflect the actual runtimes when</span>
<span id="cb1-761"><a href="#cb1-761" aria-hidden="true" tabindex="-1"></a>algorithms are executed in parallel, and running algorithms in parallel</span>
<span id="cb1-762"><a href="#cb1-762" aria-hidden="true" tabindex="-1"></a>can introduce overhead. We aim to evaluate whether this replacement</span>
<span id="cb1-763"><a href="#cb1-763" aria-hidden="true" tabindex="-1"></a>improves portfolio selection performance.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="https://haniyeka.github.io">Website</a> | <a href="https://github.com/haniyeka">GitHub</a> | <a href="https://github.com/uwyo-mallet">UWYO-Mallet</a></p>
</div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>